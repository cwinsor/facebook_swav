INFO - 12/14/22 15:34:10 - 0:00:00 - ============ Initialized logger ============
INFO - 12/14/22 15:34:10 - 0:00:00 - arch: resnet50
                                     batch_size: 32
                                     data_path: C:\Users\chris\Downloads\ILSVRC\Data\CLS-LOC
                                     decay_epochs: [60, 80]
                                     dist_url: env://
                                     dump_checkpoints: D:\code_cluster\me_swav\facebook_swav\experiments\015_investigate_accuracy\checkpoints
                                     dump_path: D:\code_cluster\me_swav\facebook_swav\experiments\015_investigate_accuracy
                                     epochs: 100
                                     final_lr: 0
                                     gamma: 0.1
                                     global_pooling: True
                                     gpu_to_work_on: 0
                                     is_slurm_job: False
                                     local_rank: 0
                                     lr: 0.3
                                     nesterov: False
                                     pretrained: D:\code_cluster\me_swav\pretrained\swav_800ep_pretrain.pth.tar
                                     rank: 0
                                     scheduler_type: cosine
                                     seed: 31
                                     use_bn: False
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 12/14/22 15:34:10 - 0:00:00 - The experiment will be stored in D:\code_cluster\me_swav\facebook_swav\experiments\015_investigate_accuracy
                                     

INFO - 12/14/22 15:34:10 - 0:00:00 - 0  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/14/22 15:34:10 - 0:00:00 - 1  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/14/22 15:34:10 - 0:00:00 - build training dataset (start)
INFO - 12/14/22 15:34:19 - 0:00:09 - build training dataset (end)
INFO - 12/14/22 15:34:19 - 0:00:09 - build validation dataset (start)
INFO - 12/14/22 15:34:20 - 0:00:09 - build validation dataset (end)
INFO - 12/14/22 15:34:20 - 0:00:09 - Building data done
INFO - 12/14/22 15:34:21 - 0:00:11 - Load pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['module.projection_head.0.weight', 'module.projection_head.0.bias', 'module.projection_head.1.weight', 'module.projection_head.1.bias', 'module.projection_head.1.running_mean', 'module.projection_head.1.running_var', 'module.projection_head.1.num_batches_tracked', 'module.projection_head.3.weight', 'module.projection_head.3.bias', 'module.prototypes.weight'])
INFO - 12/14/22 15:34:21 - 0:00:11 - ============ Starting epoch 0 ... ============
INFO - 12/14/22 15:35:06 - 0:00:55 - b'===============================================================================================\nLayer (type:depth-idx)                        Output Shape              Param #\n===============================================================================================\nDataParallel                                  [32, 2048, 7, 7]          --\n\xe2\x94\x9c\xe2\x94\x80ResNet: 1-1                                 [16, 2048, 7, 7]          23,508,032\n\xe2\x94\x9c\xe2\x94\x80ResNet: 1-2                                 [16, 2048, 7, 7]          --\n\xe2\x94\x9c\xe2\x94\x80ResNet: 1-3                                 --                        --\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80ConstantPad2d: 2-1                     [16, 3, 226, 226]         --\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Conv2d: 2-2                            [16, 64, 112, 112]        9,408\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80ConstantPad2d: 2-3                     [16, 3, 226, 226]         --\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Conv2d: 2-4                            [16, 64, 112, 112]        --\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80BatchNorm2d: 2-5                       [16, 64, 112, 112]        128\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80ReLU: 2-6                              [16, 64, 112, 112]        --\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80MaxPool2d: 2-7                         [16, 64, 56, 56]          --\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-8                        [16, 256, 56, 56]         215,808\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-24                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-1                   [16, 256, 56, 56]         75,008\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-22                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-3                   [16, 256, 56, 56]         70,400\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-26                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-5                   [16, 256, 56, 56]         70,400\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-28                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-10                       [16, 512, 28, 28]         1,219,584\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-40                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-7                   [16, 512, 28, 28]         379,392\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-52                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80BatchNorm2d: 2-12                      [16, 64, 112, 112]        --\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80ReLU: 2-13                             [16, 64, 112, 112]        --\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80MaxPool2d: 2-14                        [16, 64, 56, 56]          --\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-15                       [16, 256, 56, 56]         --\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-24                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-9                   [16, 256, 56, 56]         --\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-22                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-40                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-52                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-12                  [16, 512, 28, 28]         280,064\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-56                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-24                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-22                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-40                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-56                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-16                  [16, 512, 28, 28]         280,064\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-58                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-18                  [16, 512, 28, 28]         280,064\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-60                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-20                       [16, 1024, 14, 14]        7,098,368\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-48                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-20                  [16, 1024, 14, 14]        1,512,448\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-66                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-24                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-22                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-23                  [16, 256, 56, 56]         --\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-26                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-48                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-66                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-24                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-26                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-27                  [16, 256, 56, 56]         --\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-28                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-25                       [16, 512, 28, 28]         --\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-40                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-29                  [16, 512, 28, 28]         --\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-52                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-48                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-66                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-40                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-52                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-48                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-66                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-34                  [16, 1024, 14, 14]        1,117,184\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-72                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-40                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-52                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-48                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-72                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-38                  [16, 1024, 14, 14]        1,117,184\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-74                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-40                  [16, 1024, 14, 14]        1,117,184\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-76                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-42                  [16, 1024, 14, 14]        1,117,184\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-78                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-40                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-52                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-48                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-78                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-40                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-52                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-48                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-78                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-48                  [16, 1024, 14, 14]        1,117,184\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-80                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-36                       [16, 2048, 7, 7]          14,964,736\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-50                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-50                  [16, 2048, 7, 7]          6,039,552\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-88                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-40                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-52                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-53                  [16, 512, 28, 28]         --\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-56                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-50                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-88                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-40                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-56                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-57                  [16, 512, 28, 28]         --\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-58                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-59                  [16, 512, 28, 28]         --\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-60                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-41                       [16, 1024, 14, 14]        --\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-48                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-61                  [16, 1024, 14, 14]        --\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-66                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-50                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-88                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-48                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-66                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-50                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-88                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-48                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-66                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-67                  [16, 1024, 14, 14]        --\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-72                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-50                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-88                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-70                  [16, 2048, 7, 7]          4,462,592\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-90                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-48                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-72                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-73                  [16, 1024, 14, 14]        --\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-74                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-75                  [16, 1024, 14, 14]        --\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-76                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-77                  [16, 1024, 14, 14]        --\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-78                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-79                  [16, 1024, 14, 14]        --\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-80                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-49                       [16, 2048, 7, 7]          --\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Sequential: 2-50                       --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-81                  [16, 2048, 7, 7]          --\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-88                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-90                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-88                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-90                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-86                  [16, 2048, 7, 7]          4,462,592\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-92                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-88                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-89                  [16, 2048, 7, 7]          --\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-90                  --                        (recursive)\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-91                  [16, 2048, 7, 7]          --\n\xe2\x94\x82    \xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80Bottleneck: 3-92                  --                        (recursive)\n===============================================================================================\nTotal params: 23,508,032\nTrainable params: 23,508,032\nNon-trainable params: 0\nTotal mult-adds (G): 65.40\n===============================================================================================\nInput size (MB): 19.27\nForward/backward pass size (MB): 2845.18\nParams size (MB): 94.03\nEstimated Total Size (MB): 2958.48\n==============================================================================================='
INFO - 12/14/22 15:35:59 - 0:01:49 - zona
INFO - 12/14/22 15:56:25 - 0:00:00 - ============ Initialized logger ============
INFO - 12/14/22 15:56:25 - 0:00:00 - arch: resnet50
                                     batch_size: 32
                                     data_path: C:\Users\chris\Downloads\ILSVRC\Data\CLS-LOC
                                     decay_epochs: [60, 80]
                                     dist_url: env://
                                     dump_checkpoints: D:\code_cluster\me_swav\facebook_swav\experiments\015_investigate_accuracy\checkpoints
                                     dump_path: D:\code_cluster\me_swav\facebook_swav\experiments\015_investigate_accuracy
                                     epochs: 100
                                     final_lr: 0
                                     gamma: 0.1
                                     global_pooling: True
                                     gpu_to_work_on: 0
                                     is_slurm_job: False
                                     local_rank: 0
                                     lr: 0.3
                                     nesterov: False
                                     pretrained: D:\code_cluster\me_swav\pretrained\swav_800ep_pretrain.pth.tar
                                     rank: 0
                                     scheduler_type: cosine
                                     seed: 31
                                     use_bn: False
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 12/14/22 15:56:25 - 0:00:00 - The experiment will be stored in D:\code_cluster\me_swav\facebook_swav\experiments\015_investigate_accuracy
                                     

INFO - 12/14/22 15:56:25 - 0:00:00 - 0  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/14/22 15:56:25 - 0:00:00 - 1  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/14/22 15:56:25 - 0:00:00 - build training dataset (start)
INFO - 12/14/22 15:56:34 - 0:00:09 - build training dataset (end)
INFO - 12/14/22 15:56:34 - 0:00:09 - build validation dataset (start)
INFO - 12/14/22 15:56:34 - 0:00:09 - build validation dataset (end)
INFO - 12/14/22 15:56:34 - 0:00:09 - Building data done
INFO - 12/14/22 15:56:35 - 0:00:10 - Load pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['module.projection_head.0.weight', 'module.projection_head.0.bias', 'module.projection_head.1.weight', 'module.projection_head.1.bias', 'module.projection_head.1.running_mean', 'module.projection_head.1.running_var', 'module.projection_head.1.num_batches_tracked', 'module.projection_head.3.weight', 'module.projection_head.3.bias', 'module.prototypes.weight'])
INFO - 12/14/22 15:56:35 - 0:00:11 - ============ Starting epoch 0 ... ============
INFO - 12/14/22 16:00:08 - 0:00:00 - ============ Initialized logger ============
INFO - 12/14/22 16:00:08 - 0:00:00 - arch: resnet50
                                     batch_size: 32
                                     data_path: C:\Users\chris\Downloads\ILSVRC\Data\CLS-LOC
                                     decay_epochs: [60, 80]
                                     dist_url: env://
                                     dump_checkpoints: D:\code_cluster\me_swav\facebook_swav\experiments\015_investigate_accuracy\checkpoints
                                     dump_path: D:\code_cluster\me_swav\facebook_swav\experiments\015_investigate_accuracy
                                     epochs: 100
                                     final_lr: 0
                                     gamma: 0.1
                                     global_pooling: True
                                     gpu_to_work_on: 0
                                     is_slurm_job: False
                                     local_rank: 0
                                     lr: 0.3
                                     nesterov: False
                                     pretrained: D:\code_cluster\me_swav\pretrained\swav_800ep_pretrain.pth.tar
                                     rank: 0
                                     scheduler_type: cosine
                                     seed: 31
                                     use_bn: False
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 12/14/22 16:00:08 - 0:00:00 - The experiment will be stored in D:\code_cluster\me_swav\facebook_swav\experiments\015_investigate_accuracy
                                     

INFO - 12/14/22 16:00:08 - 0:00:00 - 0  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/14/22 16:00:08 - 0:00:00 - 1  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/14/22 16:00:08 - 0:00:00 - build training dataset (start)
INFO - 12/14/22 16:21:04 - 0:00:00 - ============ Initialized logger ============
INFO - 12/14/22 16:21:04 - 0:00:00 - arch: resnet50
                                     batch_size: 32
                                     data_path: C:\Users\chris\Downloads\ILSVRC\Data\CLS-LOC
                                     decay_epochs: [60, 80]
                                     dist_url: env://
                                     dump_checkpoints: D:\code_cluster\me_swav\facebook_swav\experiments\015_investigate_accuracy\checkpoints
                                     dump_path: D:\code_cluster\me_swav\facebook_swav\experiments\015_investigate_accuracy
                                     epochs: 100
                                     final_lr: 0
                                     gamma: 0.1
                                     global_pooling: True
                                     gpu_to_work_on: 0
                                     is_slurm_job: False
                                     local_rank: 0
                                     lr: 0.3
                                     nesterov: False
                                     pretrained: D:\code_cluster\me_swav\pretrained\swav_800ep_pretrain.pth.tar
                                     rank: 0
                                     scheduler_type: cosine
                                     seed: 31
                                     use_bn: False
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 12/14/22 16:21:04 - 0:00:00 - The experiment will be stored in D:\code_cluster\me_swav\facebook_swav\experiments\015_investigate_accuracy
                                     

INFO - 12/14/22 16:21:04 - 0:00:00 - 0  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/14/22 16:21:04 - 0:00:00 - 1  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/14/22 16:21:04 - 0:00:00 - build training dataset (start)
INFO - 12/14/22 16:21:13 - 0:00:09 - build training dataset (end)
INFO - 12/14/22 16:21:13 - 0:00:09 - build validation dataset (start)
INFO - 12/14/22 16:21:13 - 0:00:10 - build validation dataset (end)
INFO - 12/14/22 16:21:13 - 0:00:10 - Building data done
INFO - 12/14/22 16:21:14 - 0:00:11 - Load pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['module.projection_head.0.weight', 'module.projection_head.0.bias', 'module.projection_head.1.weight', 'module.projection_head.1.bias', 'module.projection_head.1.running_mean', 'module.projection_head.1.running_var', 'module.projection_head.1.num_batches_tracked', 'module.projection_head.3.weight', 'module.projection_head.3.bias', 'module.prototypes.weight'])
INFO - 12/14/22 16:21:14 - 0:00:11 - ============ Starting epoch 0 ... ============
INFO - 12/14/22 16:24:02 - 0:00:00 - ============ Initialized logger ============
INFO - 12/14/22 16:24:02 - 0:00:00 - arch: resnet50
                                     batch_size: 32
                                     data_path: C:\Users\chris\Downloads\ILSVRC\Data\CLS-LOC
                                     decay_epochs: [60, 80]
                                     dist_url: env://
                                     dump_checkpoints: D:\code_cluster\me_swav\facebook_swav\experiments\015_investigate_accuracy\checkpoints
                                     dump_path: D:\code_cluster\me_swav\facebook_swav\experiments\015_investigate_accuracy
                                     epochs: 100
                                     final_lr: 0
                                     gamma: 0.1
                                     global_pooling: True
                                     gpu_to_work_on: 0
                                     is_slurm_job: False
                                     local_rank: 0
                                     lr: 0.3
                                     nesterov: False
                                     pretrained: D:\code_cluster\me_swav\pretrained\swav_800ep_pretrain.pth.tar
                                     rank: 0
                                     scheduler_type: cosine
                                     seed: 31
                                     use_bn: False
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 12/14/22 16:24:02 - 0:00:00 - The experiment will be stored in D:\code_cluster\me_swav\facebook_swav\experiments\015_investigate_accuracy
                                     

INFO - 12/14/22 16:24:02 - 0:00:00 - 0  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/14/22 16:24:02 - 0:00:00 - 1  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/14/22 16:24:02 - 0:00:00 - build training dataset (start)
INFO - 12/14/22 16:24:11 - 0:00:09 - build training dataset (end)
INFO - 12/14/22 16:24:11 - 0:00:09 - build validation dataset (start)
INFO - 12/14/22 16:24:11 - 0:00:09 - build validation dataset (end)
INFO - 12/14/22 16:24:11 - 0:00:09 - Building data done
INFO - 12/14/22 16:24:12 - 0:00:10 - Load pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['module.projection_head.0.weight', 'module.projection_head.0.bias', 'module.projection_head.1.weight', 'module.projection_head.1.bias', 'module.projection_head.1.running_mean', 'module.projection_head.1.running_var', 'module.projection_head.1.num_batches_tracked', 'module.projection_head.3.weight', 'module.projection_head.3.bias', 'module.prototypes.weight'])
INFO - 12/14/22 16:24:12 - 0:00:10 - ============ Starting epoch 0 ... ============
INFO - 12/14/22 16:28:34 - 0:00:00 - ============ Initialized logger ============
INFO - 12/14/22 16:28:34 - 0:00:00 - arch: resnet50
                                     batch_size: 32
                                     data_path: C:\Users\chris\Downloads\ILSVRC\Data\CLS-LOC
                                     decay_epochs: [60, 80]
                                     dist_url: env://
                                     dump_checkpoints: D:\code_cluster\me_swav\facebook_swav\experiments\015_investigate_accuracy\checkpoints
                                     dump_path: D:\code_cluster\me_swav\facebook_swav\experiments\015_investigate_accuracy
                                     epochs: 100
                                     final_lr: 0
                                     gamma: 0.1
                                     global_pooling: True
                                     gpu_to_work_on: 0
                                     is_slurm_job: False
                                     local_rank: 0
                                     lr: 0.3
                                     nesterov: False
                                     pretrained: D:\code_cluster\me_swav\pretrained\swav_800ep_pretrain.pth.tar
                                     rank: 0
                                     scheduler_type: cosine
                                     seed: 31
                                     use_bn: False
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 12/14/22 16:28:34 - 0:00:00 - The experiment will be stored in D:\code_cluster\me_swav\facebook_swav\experiments\015_investigate_accuracy
                                     

INFO - 12/14/22 16:28:34 - 0:00:00 - 0  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/14/22 16:28:34 - 0:00:00 - 1  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/14/22 16:28:34 - 0:00:00 - build training dataset (start)
INFO - 12/14/22 16:28:43 - 0:00:09 - build training dataset (end)
INFO - 12/14/22 16:28:43 - 0:00:09 - build validation dataset (start)
INFO - 12/14/22 16:28:44 - 0:00:10 - build validation dataset (end)
INFO - 12/14/22 16:28:44 - 0:00:10 - Building data done
INFO - 12/14/22 16:28:45 - 0:00:11 - Load pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['module.projection_head.0.weight', 'module.projection_head.0.bias', 'module.projection_head.1.weight', 'module.projection_head.1.bias', 'module.projection_head.1.running_mean', 'module.projection_head.1.running_var', 'module.projection_head.1.num_batches_tracked', 'module.projection_head.3.weight', 'module.projection_head.3.bias', 'module.prototypes.weight'])
INFO - 12/14/22 16:28:45 - 0:00:11 - ============ Starting epoch 0 ... ============
INFO - 12/14/22 16:30:23 - 0:00:00 - ============ Initialized logger ============
INFO - 12/14/22 16:30:23 - 0:00:00 - arch: resnet50
                                     batch_size: 32
                                     data_path: C:\Users\chris\Downloads\ILSVRC\Data\CLS-LOC
                                     decay_epochs: [60, 80]
                                     dist_url: env://
                                     dump_checkpoints: D:\code_cluster\me_swav\facebook_swav\experiments\015_investigate_accuracy\checkpoints
                                     dump_path: D:\code_cluster\me_swav\facebook_swav\experiments\015_investigate_accuracy
                                     epochs: 100
                                     final_lr: 0
                                     gamma: 0.1
                                     global_pooling: True
                                     gpu_to_work_on: 0
                                     is_slurm_job: False
                                     local_rank: 0
                                     lr: 0.3
                                     nesterov: False
                                     pretrained: D:\code_cluster\me_swav\pretrained\swav_800ep_pretrain.pth.tar
                                     rank: 0
                                     scheduler_type: cosine
                                     seed: 31
                                     use_bn: False
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 12/14/22 16:30:23 - 0:00:00 - The experiment will be stored in D:\code_cluster\me_swav\facebook_swav\experiments\015_investigate_accuracy
                                     

INFO - 12/14/22 16:30:23 - 0:00:00 - 0  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/14/22 16:30:23 - 0:00:00 - 1  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/14/22 16:30:23 - 0:00:00 - build training dataset (start)
INFO - 12/14/22 16:30:31 - 0:00:09 - build training dataset (end)
INFO - 12/14/22 16:30:31 - 0:00:09 - build validation dataset (start)
INFO - 12/14/22 16:30:32 - 0:00:09 - build validation dataset (end)
INFO - 12/14/22 16:30:32 - 0:00:09 - Building data done
INFO - 12/14/22 16:30:33 - 0:00:10 - Load pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['module.projection_head.0.weight', 'module.projection_head.0.bias', 'module.projection_head.1.weight', 'module.projection_head.1.bias', 'module.projection_head.1.running_mean', 'module.projection_head.1.running_var', 'module.projection_head.1.num_batches_tracked', 'module.projection_head.3.weight', 'module.projection_head.3.bias', 'module.prototypes.weight'])
INFO - 12/14/22 16:30:33 - 0:00:10 - ============ Starting epoch 0 ... ============
INFO - 12/14/22 16:32:55 - 0:00:00 - ============ Initialized logger ============
INFO - 12/14/22 16:32:55 - 0:00:00 - arch: resnet50
                                     batch_size: 64
                                     data_path: C:\Users\chris\Downloads\ILSVRC\Data\CLS-LOC
                                     decay_epochs: [60, 80]
                                     dist_url: env://
                                     dump_checkpoints: D:\code_cluster\me_swav\facebook_swav\experiments\015_investigate_accuracy\checkpoints
                                     dump_path: D:\code_cluster\me_swav\facebook_swav\experiments\015_investigate_accuracy
                                     epochs: 100
                                     final_lr: 0
                                     gamma: 0.1
                                     global_pooling: True
                                     gpu_to_work_on: 0
                                     is_slurm_job: False
                                     local_rank: 0
                                     lr: 0.3
                                     nesterov: False
                                     pretrained: D:\code_cluster\me_swav\pretrained\swav_800ep_pretrain.pth.tar
                                     rank: 0
                                     scheduler_type: cosine
                                     seed: 31
                                     use_bn: False
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 12/14/22 16:32:55 - 0:00:00 - The experiment will be stored in D:\code_cluster\me_swav\facebook_swav\experiments\015_investigate_accuracy
                                     

INFO - 12/14/22 16:32:55 - 0:00:00 - 0  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/14/22 16:32:55 - 0:00:00 - 1  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/14/22 16:32:55 - 0:00:00 - build training dataset (start)
INFO - 12/14/22 16:33:04 - 0:00:09 - build training dataset (end)
INFO - 12/14/22 16:33:04 - 0:00:09 - build validation dataset (start)
INFO - 12/14/22 16:33:05 - 0:00:09 - build validation dataset (end)
INFO - 12/14/22 16:33:05 - 0:00:09 - Building data done
INFO - 12/14/22 16:33:06 - 0:00:10 - Load pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['module.projection_head.0.weight', 'module.projection_head.0.bias', 'module.projection_head.1.weight', 'module.projection_head.1.bias', 'module.projection_head.1.running_mean', 'module.projection_head.1.running_var', 'module.projection_head.1.num_batches_tracked', 'module.projection_head.3.weight', 'module.projection_head.3.bias', 'module.prototypes.weight'])
INFO - 12/14/22 16:33:06 - 0:00:10 - ============ Starting epoch 0 ... ============
INFO - 12/14/22 16:47:18 - 0:00:00 - ============ Initialized logger ============
INFO - 12/14/22 16:47:18 - 0:00:00 - arch: resnet50
                                     batch_size: 64
                                     data_path: C:\Users\chris\Downloads\ILSVRC\Data\CLS-LOC
                                     decay_epochs: [60, 80]
                                     dist_url: env://
                                     dump_checkpoints: D:\code_cluster\me_swav\facebook_swav\experiments\015_investigate_accuracy\checkpoints
                                     dump_path: D:\code_cluster\me_swav\facebook_swav\experiments\015_investigate_accuracy
                                     epochs: 100
                                     final_lr: 0
                                     gamma: 0.1
                                     global_pooling: True
                                     gpu_to_work_on: 0
                                     is_slurm_job: False
                                     local_rank: 0
                                     lr: 0.3
                                     nesterov: False
                                     pretrained: D:\code_cluster\me_swav\pretrained\swav_800ep_pretrain.pth.tar
                                     rank: 0
                                     scheduler_type: cosine
                                     seed: 31
                                     use_bn: False
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 12/14/22 16:47:18 - 0:00:00 - The experiment will be stored in D:\code_cluster\me_swav\facebook_swav\experiments\015_investigate_accuracy
                                     

INFO - 12/14/22 16:47:18 - 0:00:00 - 0  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/14/22 16:47:18 - 0:00:00 - 1  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/14/22 16:47:18 - 0:00:00 - build training dataset (start)
INFO - 12/14/22 16:47:27 - 0:00:09 - build training dataset (end)
INFO - 12/14/22 16:47:27 - 0:00:09 - build validation dataset (start)
INFO - 12/14/22 16:47:28 - 0:00:10 - build validation dataset (end)
INFO - 12/14/22 16:47:28 - 0:00:10 - Building data done
INFO - 12/14/22 16:47:29 - 0:00:11 - Load pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['module.projection_head.0.weight', 'module.projection_head.0.bias', 'module.projection_head.1.weight', 'module.projection_head.1.bias', 'module.projection_head.1.running_mean', 'module.projection_head.1.running_var', 'module.projection_head.1.num_batches_tracked', 'module.projection_head.3.weight', 'module.projection_head.3.bias', 'module.prototypes.weight'])
INFO - 12/14/22 16:47:29 - 0:00:11 - ============ Starting epoch 0 ... ============
INFO - 12/14/22 16:47:54 - 0:00:36 - Model's state_dict:
INFO - 12/14/22 16:47:54 - 0:00:36 - module.conv1.weight	torch.Size([64, 3, 7, 7])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.bn1.weight	torch.Size([64])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.bn1.bias	torch.Size([64])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.bn1.running_mean	torch.Size([64])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.bn1.running_var	torch.Size([64])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.0.conv1.weight	torch.Size([64, 64, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.0.bn1.weight	torch.Size([64])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.0.bn1.bias	torch.Size([64])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.0.bn1.running_mean	torch.Size([64])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.0.bn1.running_var	torch.Size([64])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.0.conv2.weight	torch.Size([64, 64, 3, 3])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.0.bn2.weight	torch.Size([64])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.0.bn2.bias	torch.Size([64])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.0.bn2.running_mean	torch.Size([64])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.0.bn2.running_var	torch.Size([64])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.0.conv3.weight	torch.Size([256, 64, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.0.bn3.weight	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.0.bn3.bias	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.0.bn3.running_mean	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.0.bn3.running_var	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.0.downsample.0.weight	torch.Size([256, 64, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.0.downsample.1.weight	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.0.downsample.1.bias	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.0.downsample.1.running_mean	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.0.downsample.1.running_var	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.1.conv1.weight	torch.Size([64, 256, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.1.bn1.weight	torch.Size([64])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.1.bn1.bias	torch.Size([64])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.1.bn1.running_mean	torch.Size([64])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.1.bn1.running_var	torch.Size([64])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.1.conv2.weight	torch.Size([64, 64, 3, 3])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.1.bn2.weight	torch.Size([64])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.1.bn2.bias	torch.Size([64])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.1.bn2.running_mean	torch.Size([64])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.1.bn2.running_var	torch.Size([64])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.1.conv3.weight	torch.Size([256, 64, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.1.bn3.weight	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.1.bn3.bias	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.1.bn3.running_mean	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.1.bn3.running_var	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.2.conv1.weight	torch.Size([64, 256, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.2.bn1.weight	torch.Size([64])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.2.bn1.bias	torch.Size([64])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.2.bn1.running_mean	torch.Size([64])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.2.bn1.running_var	torch.Size([64])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.2.conv2.weight	torch.Size([64, 64, 3, 3])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.2.bn2.weight	torch.Size([64])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.2.bn2.bias	torch.Size([64])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.2.bn2.running_mean	torch.Size([64])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.2.bn2.running_var	torch.Size([64])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.2.conv3.weight	torch.Size([256, 64, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.2.bn3.weight	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.2.bn3.bias	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.2.bn3.running_mean	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.2.bn3.running_var	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer1.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.0.conv1.weight	torch.Size([128, 256, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.0.bn1.weight	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.0.bn1.bias	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.0.bn1.running_mean	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.0.bn1.running_var	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.0.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.0.bn2.weight	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.0.bn2.bias	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.0.bn2.running_mean	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.0.bn2.running_var	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.0.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.0.bn3.weight	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.0.bn3.bias	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.0.bn3.running_mean	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.0.bn3.running_var	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.0.downsample.0.weight	torch.Size([512, 256, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.0.downsample.1.weight	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.0.downsample.1.bias	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.0.downsample.1.running_mean	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.0.downsample.1.running_var	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.1.conv1.weight	torch.Size([128, 512, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.1.bn1.weight	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.1.bn1.bias	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.1.bn1.running_mean	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.1.bn1.running_var	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.1.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.1.bn2.weight	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.1.bn2.bias	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.1.bn2.running_mean	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.1.bn2.running_var	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.1.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.1.bn3.weight	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.1.bn3.bias	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.1.bn3.running_mean	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.1.bn3.running_var	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.2.conv1.weight	torch.Size([128, 512, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.2.bn1.weight	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.2.bn1.bias	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.2.bn1.running_mean	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.2.bn1.running_var	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.2.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.2.bn2.weight	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.2.bn2.bias	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.2.bn2.running_mean	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.2.bn2.running_var	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.2.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.2.bn3.weight	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.2.bn3.bias	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.2.bn3.running_mean	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.2.bn3.running_var	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.3.conv1.weight	torch.Size([128, 512, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.3.bn1.weight	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.3.bn1.bias	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.3.bn1.running_mean	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.3.bn1.running_var	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.3.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.3.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.3.bn2.weight	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.3.bn2.bias	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.3.bn2.running_mean	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.3.bn2.running_var	torch.Size([128])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.3.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.3.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.3.bn3.weight	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.3.bn3.bias	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.3.bn3.running_mean	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.3.bn3.running_var	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer2.3.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.0.conv1.weight	torch.Size([256, 512, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.0.bn1.weight	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.0.bn1.bias	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.0.bn1.running_mean	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.0.bn1.running_var	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.0.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.0.bn2.weight	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.0.bn2.bias	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.0.bn2.running_mean	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.0.bn2.running_var	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.0.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.0.bn3.weight	torch.Size([1024])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.0.bn3.bias	torch.Size([1024])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.0.bn3.running_mean	torch.Size([1024])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.0.bn3.running_var	torch.Size([1024])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.0.downsample.0.weight	torch.Size([1024, 512, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.0.downsample.1.weight	torch.Size([1024])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.0.downsample.1.bias	torch.Size([1024])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.0.downsample.1.running_mean	torch.Size([1024])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.0.downsample.1.running_var	torch.Size([1024])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.1.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.1.bn1.weight	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.1.bn1.bias	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.1.bn1.running_mean	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.1.bn1.running_var	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.1.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.1.bn2.weight	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.1.bn2.bias	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.1.bn2.running_mean	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.1.bn2.running_var	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.1.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.1.bn3.weight	torch.Size([1024])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.1.bn3.bias	torch.Size([1024])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.1.bn3.running_mean	torch.Size([1024])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.1.bn3.running_var	torch.Size([1024])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.2.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.2.bn1.weight	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.2.bn1.bias	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.2.bn1.running_mean	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.2.bn1.running_var	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.2.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.2.bn2.weight	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.2.bn2.bias	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.2.bn2.running_mean	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.2.bn2.running_var	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.2.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.2.bn3.weight	torch.Size([1024])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.2.bn3.bias	torch.Size([1024])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.2.bn3.running_mean	torch.Size([1024])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.2.bn3.running_var	torch.Size([1024])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.3.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.3.bn1.weight	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.3.bn1.bias	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.3.bn1.running_mean	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.3.bn1.running_var	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.3.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.3.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.3.bn2.weight	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.3.bn2.bias	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.3.bn2.running_mean	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.3.bn2.running_var	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.3.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.3.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.3.bn3.weight	torch.Size([1024])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.3.bn3.bias	torch.Size([1024])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.3.bn3.running_mean	torch.Size([1024])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.3.bn3.running_var	torch.Size([1024])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.3.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.4.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.4.bn1.weight	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.4.bn1.bias	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.4.bn1.running_mean	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.4.bn1.running_var	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.4.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.4.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.4.bn2.weight	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.4.bn2.bias	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.4.bn2.running_mean	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.4.bn2.running_var	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.4.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.4.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.4.bn3.weight	torch.Size([1024])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.4.bn3.bias	torch.Size([1024])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.4.bn3.running_mean	torch.Size([1024])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.4.bn3.running_var	torch.Size([1024])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.4.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.5.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.5.bn1.weight	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.5.bn1.bias	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.5.bn1.running_mean	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.5.bn1.running_var	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.5.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.5.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.5.bn2.weight	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.5.bn2.bias	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.5.bn2.running_mean	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.5.bn2.running_var	torch.Size([256])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.5.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.5.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.5.bn3.weight	torch.Size([1024])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.5.bn3.bias	torch.Size([1024])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.5.bn3.running_mean	torch.Size([1024])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.5.bn3.running_var	torch.Size([1024])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer3.5.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.0.conv1.weight	torch.Size([512, 1024, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.0.bn1.weight	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.0.bn1.bias	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.0.bn1.running_mean	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.0.bn1.running_var	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.0.conv2.weight	torch.Size([512, 512, 3, 3])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.0.bn2.weight	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.0.bn2.bias	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.0.bn2.running_mean	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.0.bn2.running_var	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.0.conv3.weight	torch.Size([2048, 512, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.0.bn3.weight	torch.Size([2048])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.0.bn3.bias	torch.Size([2048])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.0.bn3.running_mean	torch.Size([2048])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.0.bn3.running_var	torch.Size([2048])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.0.downsample.0.weight	torch.Size([2048, 1024, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.0.downsample.1.weight	torch.Size([2048])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.0.downsample.1.bias	torch.Size([2048])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.0.downsample.1.running_mean	torch.Size([2048])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.0.downsample.1.running_var	torch.Size([2048])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.1.conv1.weight	torch.Size([512, 2048, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.1.bn1.weight	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.1.bn1.bias	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.1.bn1.running_mean	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.1.bn1.running_var	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.1.conv2.weight	torch.Size([512, 512, 3, 3])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.1.bn2.weight	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.1.bn2.bias	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.1.bn2.running_mean	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.1.bn2.running_var	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.1.conv3.weight	torch.Size([2048, 512, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.1.bn3.weight	torch.Size([2048])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.1.bn3.bias	torch.Size([2048])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.1.bn3.running_mean	torch.Size([2048])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.1.bn3.running_var	torch.Size([2048])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.2.conv1.weight	torch.Size([512, 2048, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.2.bn1.weight	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.2.bn1.bias	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.2.bn1.running_mean	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.2.bn1.running_var	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.2.conv2.weight	torch.Size([512, 512, 3, 3])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.2.bn2.weight	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.2.bn2.bias	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.2.bn2.running_mean	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.2.bn2.running_var	torch.Size([512])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.2.conv3.weight	torch.Size([2048, 512, 1, 1])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.2.bn3.weight	torch.Size([2048])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.2.bn3.bias	torch.Size([2048])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.2.bn3.running_mean	torch.Size([2048])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.2.bn3.running_var	torch.Size([2048])
INFO - 12/14/22 16:47:54 - 0:00:36 - module.layer4.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:54:51 - 0:00:00 - ============ Initialized logger ============
INFO - 12/14/22 16:54:51 - 0:00:00 - arch: resnet50
                                     batch_size: 64
                                     data_path: C:\Users\chris\Downloads\ILSVRC\Data\CLS-LOC
                                     decay_epochs: [60, 80]
                                     dist_url: env://
                                     dump_checkpoints: D:\code_cluster\me_swav\facebook_swav\experiments\015_investigate_accuracy\checkpoints
                                     dump_path: D:\code_cluster\me_swav\facebook_swav\experiments\015_investigate_accuracy
                                     epochs: 100
                                     final_lr: 0
                                     gamma: 0.1
                                     global_pooling: True
                                     gpu_to_work_on: 0
                                     is_slurm_job: False
                                     local_rank: 0
                                     lr: 0.3
                                     nesterov: False
                                     pretrained: D:\code_cluster\me_swav\pretrained\swav_800ep_pretrain.pth.tar
                                     rank: 0
                                     scheduler_type: cosine
                                     seed: 31
                                     use_bn: False
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 12/14/22 16:54:51 - 0:00:00 - The experiment will be stored in D:\code_cluster\me_swav\facebook_swav\experiments\015_investigate_accuracy
                                     

INFO - 12/14/22 16:54:51 - 0:00:00 - 0  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/14/22 16:54:51 - 0:00:00 - 1  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/14/22 16:54:51 - 0:00:00 - build training dataset (start)
INFO - 12/14/22 16:55:00 - 0:00:09 - build training dataset (end)
INFO - 12/14/22 16:55:00 - 0:00:09 - build validation dataset (start)
INFO - 12/14/22 16:55:01 - 0:00:09 - build validation dataset (end)
INFO - 12/14/22 16:55:01 - 0:00:10 - Building data done
INFO - 12/14/22 16:55:02 - 0:00:11 - Load pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['module.projection_head.0.weight', 'module.projection_head.0.bias', 'module.projection_head.1.weight', 'module.projection_head.1.bias', 'module.projection_head.1.running_mean', 'module.projection_head.1.running_var', 'module.projection_head.1.num_batches_tracked', 'module.projection_head.3.weight', 'module.projection_head.3.bias', 'module.prototypes.weight'])
INFO - 12/14/22 16:55:02 - 0:00:11 - ============ Starting epoch 0 ... ============
INFO - 12/14/22 16:55:27 - 0:00:36 - Model's state_dict:
INFO - 12/14/22 16:55:27 - 0:00:36 - module.conv1.weight	torch.Size([64, 3, 7, 7])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.bn1.weight	torch.Size([64])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.bn1.bias	torch.Size([64])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.bn1.running_mean	torch.Size([64])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.bn1.running_var	torch.Size([64])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.0.conv1.weight	torch.Size([64, 64, 1, 1])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.0.bn1.weight	torch.Size([64])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.0.bn1.bias	torch.Size([64])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.0.bn1.running_mean	torch.Size([64])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.0.bn1.running_var	torch.Size([64])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.0.conv2.weight	torch.Size([64, 64, 3, 3])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.0.bn2.weight	torch.Size([64])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.0.bn2.bias	torch.Size([64])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.0.bn2.running_mean	torch.Size([64])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.0.bn2.running_var	torch.Size([64])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.0.conv3.weight	torch.Size([256, 64, 1, 1])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.0.bn3.weight	torch.Size([256])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.0.bn3.bias	torch.Size([256])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.0.bn3.running_mean	torch.Size([256])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.0.bn3.running_var	torch.Size([256])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.0.downsample.0.weight	torch.Size([256, 64, 1, 1])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.0.downsample.1.weight	torch.Size([256])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.0.downsample.1.bias	torch.Size([256])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.0.downsample.1.running_mean	torch.Size([256])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.0.downsample.1.running_var	torch.Size([256])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.1.conv1.weight	torch.Size([64, 256, 1, 1])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.1.bn1.weight	torch.Size([64])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.1.bn1.bias	torch.Size([64])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.1.bn1.running_mean	torch.Size([64])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.1.bn1.running_var	torch.Size([64])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.1.conv2.weight	torch.Size([64, 64, 3, 3])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.1.bn2.weight	torch.Size([64])
INFO - 12/14/22 16:55:27 - 0:00:36 - module.layer1.1.bn2.bias	torch.Size([64])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer1.1.bn2.running_mean	torch.Size([64])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer1.1.bn2.running_var	torch.Size([64])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer1.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer1.1.conv3.weight	torch.Size([256, 64, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer1.1.bn3.weight	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer1.1.bn3.bias	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer1.1.bn3.running_mean	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer1.1.bn3.running_var	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer1.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer1.2.conv1.weight	torch.Size([64, 256, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer1.2.bn1.weight	torch.Size([64])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer1.2.bn1.bias	torch.Size([64])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer1.2.bn1.running_mean	torch.Size([64])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer1.2.bn1.running_var	torch.Size([64])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer1.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer1.2.conv2.weight	torch.Size([64, 64, 3, 3])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer1.2.bn2.weight	torch.Size([64])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer1.2.bn2.bias	torch.Size([64])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer1.2.bn2.running_mean	torch.Size([64])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer1.2.bn2.running_var	torch.Size([64])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer1.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer1.2.conv3.weight	torch.Size([256, 64, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer1.2.bn3.weight	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer1.2.bn3.bias	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer1.2.bn3.running_mean	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer1.2.bn3.running_var	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer1.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.0.conv1.weight	torch.Size([128, 256, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.0.bn1.weight	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.0.bn1.bias	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.0.bn1.running_mean	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.0.bn1.running_var	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.0.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.0.bn2.weight	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.0.bn2.bias	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.0.bn2.running_mean	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.0.bn2.running_var	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.0.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.0.bn3.weight	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.0.bn3.bias	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.0.bn3.running_mean	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.0.bn3.running_var	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.0.downsample.0.weight	torch.Size([512, 256, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.0.downsample.1.weight	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.0.downsample.1.bias	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.0.downsample.1.running_mean	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.0.downsample.1.running_var	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.1.conv1.weight	torch.Size([128, 512, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.1.bn1.weight	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.1.bn1.bias	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.1.bn1.running_mean	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.1.bn1.running_var	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.1.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.1.bn2.weight	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.1.bn2.bias	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.1.bn2.running_mean	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.1.bn2.running_var	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.1.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.1.bn3.weight	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.1.bn3.bias	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.1.bn3.running_mean	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.1.bn3.running_var	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.2.conv1.weight	torch.Size([128, 512, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.2.bn1.weight	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.2.bn1.bias	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.2.bn1.running_mean	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.2.bn1.running_var	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.2.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.2.bn2.weight	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.2.bn2.bias	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.2.bn2.running_mean	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.2.bn2.running_var	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.2.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.2.bn3.weight	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.2.bn3.bias	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.2.bn3.running_mean	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.2.bn3.running_var	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.3.conv1.weight	torch.Size([128, 512, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.3.bn1.weight	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.3.bn1.bias	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.3.bn1.running_mean	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.3.bn1.running_var	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.3.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.3.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.3.bn2.weight	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.3.bn2.bias	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.3.bn2.running_mean	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.3.bn2.running_var	torch.Size([128])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.3.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.3.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.3.bn3.weight	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.3.bn3.bias	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.3.bn3.running_mean	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.3.bn3.running_var	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer2.3.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.0.conv1.weight	torch.Size([256, 512, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.0.bn1.weight	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.0.bn1.bias	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.0.bn1.running_mean	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.0.bn1.running_var	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.0.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.0.bn2.weight	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.0.bn2.bias	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.0.bn2.running_mean	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.0.bn2.running_var	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.0.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.0.bn3.weight	torch.Size([1024])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.0.bn3.bias	torch.Size([1024])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.0.bn3.running_mean	torch.Size([1024])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.0.bn3.running_var	torch.Size([1024])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.0.downsample.0.weight	torch.Size([1024, 512, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.0.downsample.1.weight	torch.Size([1024])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.0.downsample.1.bias	torch.Size([1024])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.0.downsample.1.running_mean	torch.Size([1024])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.0.downsample.1.running_var	torch.Size([1024])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.1.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.1.bn1.weight	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.1.bn1.bias	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.1.bn1.running_mean	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.1.bn1.running_var	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.1.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.1.bn2.weight	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.1.bn2.bias	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.1.bn2.running_mean	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.1.bn2.running_var	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.1.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.1.bn3.weight	torch.Size([1024])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.1.bn3.bias	torch.Size([1024])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.1.bn3.running_mean	torch.Size([1024])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.1.bn3.running_var	torch.Size([1024])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.2.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.2.bn1.weight	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.2.bn1.bias	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.2.bn1.running_mean	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.2.bn1.running_var	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.2.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.2.bn2.weight	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.2.bn2.bias	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.2.bn2.running_mean	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.2.bn2.running_var	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.2.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.2.bn3.weight	torch.Size([1024])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.2.bn3.bias	torch.Size([1024])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.2.bn3.running_mean	torch.Size([1024])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.2.bn3.running_var	torch.Size([1024])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.3.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.3.bn1.weight	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.3.bn1.bias	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.3.bn1.running_mean	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.3.bn1.running_var	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.3.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.3.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.3.bn2.weight	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.3.bn2.bias	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.3.bn2.running_mean	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.3.bn2.running_var	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.3.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.3.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.3.bn3.weight	torch.Size([1024])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.3.bn3.bias	torch.Size([1024])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.3.bn3.running_mean	torch.Size([1024])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.3.bn3.running_var	torch.Size([1024])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.3.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.4.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.4.bn1.weight	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.4.bn1.bias	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.4.bn1.running_mean	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.4.bn1.running_var	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.4.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.4.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.4.bn2.weight	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.4.bn2.bias	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.4.bn2.running_mean	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.4.bn2.running_var	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.4.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.4.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.4.bn3.weight	torch.Size([1024])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.4.bn3.bias	torch.Size([1024])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.4.bn3.running_mean	torch.Size([1024])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.4.bn3.running_var	torch.Size([1024])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.4.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.5.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.5.bn1.weight	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.5.bn1.bias	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.5.bn1.running_mean	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.5.bn1.running_var	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.5.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.5.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.5.bn2.weight	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.5.bn2.bias	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.5.bn2.running_mean	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.5.bn2.running_var	torch.Size([256])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.5.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.5.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.5.bn3.weight	torch.Size([1024])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.5.bn3.bias	torch.Size([1024])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.5.bn3.running_mean	torch.Size([1024])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.5.bn3.running_var	torch.Size([1024])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer3.5.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.0.conv1.weight	torch.Size([512, 1024, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.0.bn1.weight	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.0.bn1.bias	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.0.bn1.running_mean	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.0.bn1.running_var	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.0.conv2.weight	torch.Size([512, 512, 3, 3])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.0.bn2.weight	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.0.bn2.bias	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.0.bn2.running_mean	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.0.bn2.running_var	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.0.conv3.weight	torch.Size([2048, 512, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.0.bn3.weight	torch.Size([2048])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.0.bn3.bias	torch.Size([2048])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.0.bn3.running_mean	torch.Size([2048])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.0.bn3.running_var	torch.Size([2048])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.0.downsample.0.weight	torch.Size([2048, 1024, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.0.downsample.1.weight	torch.Size([2048])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.0.downsample.1.bias	torch.Size([2048])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.0.downsample.1.running_mean	torch.Size([2048])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.0.downsample.1.running_var	torch.Size([2048])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.1.conv1.weight	torch.Size([512, 2048, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.1.bn1.weight	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.1.bn1.bias	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.1.bn1.running_mean	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.1.bn1.running_var	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.1.conv2.weight	torch.Size([512, 512, 3, 3])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.1.bn2.weight	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.1.bn2.bias	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.1.bn2.running_mean	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.1.bn2.running_var	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.1.conv3.weight	torch.Size([2048, 512, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.1.bn3.weight	torch.Size([2048])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.1.bn3.bias	torch.Size([2048])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.1.bn3.running_mean	torch.Size([2048])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.1.bn3.running_var	torch.Size([2048])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.2.conv1.weight	torch.Size([512, 2048, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.2.bn1.weight	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.2.bn1.bias	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.2.bn1.running_mean	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.2.bn1.running_var	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.2.conv2.weight	torch.Size([512, 512, 3, 3])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.2.bn2.weight	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.2.bn2.bias	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.2.bn2.running_mean	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.2.bn2.running_var	torch.Size([512])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.2.conv3.weight	torch.Size([2048, 512, 1, 1])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.2.bn3.weight	torch.Size([2048])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.2.bn3.bias	torch.Size([2048])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.2.bn3.running_mean	torch.Size([2048])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.2.bn3.running_var	torch.Size([2048])
INFO - 12/14/22 16:55:28 - 0:00:36 - module.layer4.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/14/22 16:58:24 - 0:03:32 - Epoch[0] - Iter: [0/20019]	Time 201.543 (201.543)	Data 25.373 (25.373)	Loss 6.9162 (6.9162)	Prec 0.000 (0.000)	LR 0.3
INFO - 12/14/22 16:58:28 - 0:03:37 - Epoch[0] - Iter: [50/20019]	Time 0.094 (4.045)	Data 0.000 (0.498)	Loss 6.4493 (6.8031)	Prec 6.250 (2.543)	LR 0.3
INFO - 12/14/22 16:58:33 - 0:03:42 - Epoch[0] - Iter: [100/20019]	Time 0.092 (2.089)	Data 0.000 (0.251)	Loss 5.6339 (6.4539)	Prec 20.312 (6.173)	LR 0.3
