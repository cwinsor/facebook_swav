INFO - 12/16/22 14:55:28 - 0:00:00 - ============ Initialized logger ============
INFO - 12/16/22 14:55:28 - 0:00:00 - arch: resnet50
                                     batch_size: 64
                                     data_path: C:\Users\chris\Downloads\ILSVRC\Data\CLS-LOC
                                     decay_epochs: [60, 80]
                                     dist_url: env://
                                     dump_checkpoints: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model\checkpoints
                                     dump_path: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     epochs: 100
                                     final_lr: 0
                                     gamma: 0.1
                                     global_pooling: True
                                     gpu_to_work_on: 0
                                     is_slurm_job: False
                                     local_rank: 0
                                     lr: 0.3
                                     nesterov: False
                                     pretrained: D:\code_cluster\me_swav\pretrained\swav_800ep_pretrain.pth.tar
                                     rank: 0
                                     scheduler_type: cosine
                                     seed: 31
                                     use_bn: False
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 12/16/22 14:55:28 - 0:00:00 - The experiment will be stored in D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     

INFO - 12/16/22 14:55:28 - 0:00:00 - 0  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 14:55:28 - 0:00:00 - 1  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 14:55:28 - 0:00:00 - build training dataset (start)
INFO - 12/16/22 14:55:37 - 0:00:09 - build training dataset (end)
INFO - 12/16/22 14:55:37 - 0:00:09 - build validation dataset (start)
INFO - 12/16/22 14:55:37 - 0:00:09 - build validation dataset (end)
INFO - 12/16/22 14:55:37 - 0:00:09 - Building data done
INFO - 12/16/22 14:55:38 - 0:00:10 - Load pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['module.projection_head.0.weight', 'module.projection_head.0.bias', 'module.projection_head.1.weight', 'module.projection_head.1.bias', 'module.projection_head.1.running_mean', 'module.projection_head.1.running_var', 'module.projection_head.1.num_batches_tracked', 'module.projection_head.3.weight', 'module.projection_head.3.bias', 'module.prototypes.weight'])
INFO - 12/16/22 14:55:38 - 0:00:10 - ============ Starting epoch 0 ... ============
INFO - 12/16/22 14:56:03 - 0:00:35 - Model's state_dict:
INFO - 12/16/22 14:56:03 - 0:00:35 - module.conv1.weight	torch.Size([64, 3, 7, 7])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.bn1.weight	torch.Size([64])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.bn1.bias	torch.Size([64])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.bn1.running_mean	torch.Size([64])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.bn1.running_var	torch.Size([64])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.0.conv1.weight	torch.Size([64, 64, 1, 1])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.0.bn1.weight	torch.Size([64])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.0.bn1.bias	torch.Size([64])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.0.bn1.running_mean	torch.Size([64])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.0.bn1.running_var	torch.Size([64])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.0.conv2.weight	torch.Size([64, 64, 3, 3])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.0.bn2.weight	torch.Size([64])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.0.bn2.bias	torch.Size([64])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.0.bn2.running_mean	torch.Size([64])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.0.bn2.running_var	torch.Size([64])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.0.conv3.weight	torch.Size([256, 64, 1, 1])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.0.bn3.weight	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.0.bn3.bias	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.0.bn3.running_mean	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.0.bn3.running_var	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.0.downsample.0.weight	torch.Size([256, 64, 1, 1])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.0.downsample.1.weight	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.0.downsample.1.bias	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.0.downsample.1.running_mean	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.0.downsample.1.running_var	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.1.conv1.weight	torch.Size([64, 256, 1, 1])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.1.bn1.weight	torch.Size([64])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.1.bn1.bias	torch.Size([64])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.1.bn1.running_mean	torch.Size([64])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.1.bn1.running_var	torch.Size([64])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.1.conv2.weight	torch.Size([64, 64, 3, 3])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.1.bn2.weight	torch.Size([64])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.1.bn2.bias	torch.Size([64])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.1.bn2.running_mean	torch.Size([64])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.1.bn2.running_var	torch.Size([64])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.1.conv3.weight	torch.Size([256, 64, 1, 1])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.1.bn3.weight	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.1.bn3.bias	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.1.bn3.running_mean	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.1.bn3.running_var	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.2.conv1.weight	torch.Size([64, 256, 1, 1])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.2.bn1.weight	torch.Size([64])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.2.bn1.bias	torch.Size([64])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.2.bn1.running_mean	torch.Size([64])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.2.bn1.running_var	torch.Size([64])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.2.conv2.weight	torch.Size([64, 64, 3, 3])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.2.bn2.weight	torch.Size([64])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.2.bn2.bias	torch.Size([64])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.2.bn2.running_mean	torch.Size([64])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.2.bn2.running_var	torch.Size([64])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.2.conv3.weight	torch.Size([256, 64, 1, 1])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.2.bn3.weight	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.2.bn3.bias	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.2.bn3.running_mean	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.2.bn3.running_var	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer1.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.0.conv1.weight	torch.Size([128, 256, 1, 1])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.0.bn1.weight	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.0.bn1.bias	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.0.bn1.running_mean	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.0.bn1.running_var	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.0.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.0.bn2.weight	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.0.bn2.bias	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.0.bn2.running_mean	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.0.bn2.running_var	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.0.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.0.bn3.weight	torch.Size([512])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.0.bn3.bias	torch.Size([512])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.0.bn3.running_mean	torch.Size([512])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.0.bn3.running_var	torch.Size([512])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.0.downsample.0.weight	torch.Size([512, 256, 1, 1])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.0.downsample.1.weight	torch.Size([512])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.0.downsample.1.bias	torch.Size([512])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.0.downsample.1.running_mean	torch.Size([512])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.0.downsample.1.running_var	torch.Size([512])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.1.conv1.weight	torch.Size([128, 512, 1, 1])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.1.bn1.weight	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.1.bn1.bias	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.1.bn1.running_mean	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.1.bn1.running_var	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.1.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.1.bn2.weight	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.1.bn2.bias	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.1.bn2.running_mean	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.1.bn2.running_var	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.1.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.1.bn3.weight	torch.Size([512])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.1.bn3.bias	torch.Size([512])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.1.bn3.running_mean	torch.Size([512])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.1.bn3.running_var	torch.Size([512])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.2.conv1.weight	torch.Size([128, 512, 1, 1])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.2.bn1.weight	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.2.bn1.bias	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.2.bn1.running_mean	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.2.bn1.running_var	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.2.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.2.bn2.weight	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.2.bn2.bias	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.2.bn2.running_mean	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.2.bn2.running_var	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.2.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.2.bn3.weight	torch.Size([512])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.2.bn3.bias	torch.Size([512])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.2.bn3.running_mean	torch.Size([512])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.2.bn3.running_var	torch.Size([512])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.3.conv1.weight	torch.Size([128, 512, 1, 1])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.3.bn1.weight	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.3.bn1.bias	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.3.bn1.running_mean	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.3.bn1.running_var	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.3.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.3.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.3.bn2.weight	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.3.bn2.bias	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.3.bn2.running_mean	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.3.bn2.running_var	torch.Size([128])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.3.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.3.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.3.bn3.weight	torch.Size([512])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.3.bn3.bias	torch.Size([512])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.3.bn3.running_mean	torch.Size([512])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.3.bn3.running_var	torch.Size([512])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer2.3.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.0.conv1.weight	torch.Size([256, 512, 1, 1])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.0.bn1.weight	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.0.bn1.bias	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.0.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.0.bn1.running_var	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.0.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.0.bn2.weight	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.0.bn2.bias	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.0.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.0.bn2.running_var	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.0.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.0.bn3.weight	torch.Size([1024])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.0.bn3.bias	torch.Size([1024])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.0.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.0.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.0.downsample.0.weight	torch.Size([1024, 512, 1, 1])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.0.downsample.1.weight	torch.Size([1024])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.0.downsample.1.bias	torch.Size([1024])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.0.downsample.1.running_mean	torch.Size([1024])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.0.downsample.1.running_var	torch.Size([1024])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.1.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.1.bn1.weight	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.1.bn1.bias	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.1.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.1.bn1.running_var	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.1.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.1.bn2.weight	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.1.bn2.bias	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.1.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.1.bn2.running_var	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.1.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.1.bn3.weight	torch.Size([1024])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.1.bn3.bias	torch.Size([1024])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.1.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.1.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.2.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.2.bn1.weight	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.2.bn1.bias	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.2.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.2.bn1.running_var	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.2.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.2.bn2.weight	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.2.bn2.bias	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.2.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.2.bn2.running_var	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.2.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.2.bn3.weight	torch.Size([1024])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.2.bn3.bias	torch.Size([1024])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.2.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.2.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.3.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.3.bn1.weight	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.3.bn1.bias	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.3.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.3.bn1.running_var	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.3.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.3.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.3.bn2.weight	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.3.bn2.bias	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.3.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.3.bn2.running_var	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.3.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.3.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.3.bn3.weight	torch.Size([1024])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.3.bn3.bias	torch.Size([1024])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.3.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.3.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.3.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.4.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.4.bn1.weight	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.4.bn1.bias	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.4.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.4.bn1.running_var	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.4.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.4.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.4.bn2.weight	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.4.bn2.bias	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.4.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.4.bn2.running_var	torch.Size([256])
INFO - 12/16/22 14:56:03 - 0:00:35 - module.layer3.4.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:04 - 0:00:35 - module.layer3.4.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 14:56:04 - 0:00:35 - module.layer3.4.bn3.weight	torch.Size([1024])
INFO - 12/16/22 14:56:04 - 0:00:35 - module.layer3.4.bn3.bias	torch.Size([1024])
INFO - 12/16/22 14:56:04 - 0:00:35 - module.layer3.4.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 14:56:04 - 0:00:35 - module.layer3.4.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 14:56:04 - 0:00:35 - module.layer3.4.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:04 - 0:00:35 - module.layer3.5.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 14:56:04 - 0:00:35 - module.layer3.5.bn1.weight	torch.Size([256])
INFO - 12/16/22 14:56:04 - 0:00:35 - module.layer3.5.bn1.bias	torch.Size([256])
INFO - 12/16/22 14:56:04 - 0:00:35 - module.layer3.5.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 14:56:04 - 0:00:35 - module.layer3.5.bn1.running_var	torch.Size([256])
INFO - 12/16/22 14:56:04 - 0:00:35 - module.layer3.5.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:04 - 0:00:35 - module.layer3.5.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 14:56:04 - 0:00:35 - module.layer3.5.bn2.weight	torch.Size([256])
INFO - 12/16/22 14:56:04 - 0:00:35 - module.layer3.5.bn2.bias	torch.Size([256])
INFO - 12/16/22 14:56:04 - 0:00:35 - module.layer3.5.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 14:56:04 - 0:00:35 - module.layer3.5.bn2.running_var	torch.Size([256])
INFO - 12/16/22 14:56:04 - 0:00:35 - module.layer3.5.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:04 - 0:00:35 - module.layer3.5.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 14:56:04 - 0:00:35 - module.layer3.5.bn3.weight	torch.Size([1024])
INFO - 12/16/22 14:56:04 - 0:00:35 - module.layer3.5.bn3.bias	torch.Size([1024])
INFO - 12/16/22 14:56:04 - 0:00:35 - module.layer3.5.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 14:56:04 - 0:00:35 - module.layer3.5.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 14:56:04 - 0:00:35 - module.layer3.5.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:04 - 0:00:35 - module.layer4.0.conv1.weight	torch.Size([512, 1024, 1, 1])
INFO - 12/16/22 14:56:04 - 0:00:35 - module.layer4.0.bn1.weight	torch.Size([512])
INFO - 12/16/22 14:56:04 - 0:00:35 - module.layer4.0.bn1.bias	torch.Size([512])
INFO - 12/16/22 14:56:04 - 0:00:35 - module.layer4.0.bn1.running_mean	torch.Size([512])
INFO - 12/16/22 14:56:04 - 0:00:35 - module.layer4.0.bn1.running_var	torch.Size([512])
INFO - 12/16/22 14:56:04 - 0:00:35 - module.layer4.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.0.conv2.weight	torch.Size([512, 512, 3, 3])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.0.bn2.weight	torch.Size([512])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.0.bn2.bias	torch.Size([512])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.0.bn2.running_mean	torch.Size([512])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.0.bn2.running_var	torch.Size([512])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.0.conv3.weight	torch.Size([2048, 512, 1, 1])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.0.bn3.weight	torch.Size([2048])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.0.bn3.bias	torch.Size([2048])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.0.bn3.running_mean	torch.Size([2048])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.0.bn3.running_var	torch.Size([2048])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.0.downsample.0.weight	torch.Size([2048, 1024, 1, 1])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.0.downsample.1.weight	torch.Size([2048])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.0.downsample.1.bias	torch.Size([2048])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.0.downsample.1.running_mean	torch.Size([2048])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.0.downsample.1.running_var	torch.Size([2048])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.1.conv1.weight	torch.Size([512, 2048, 1, 1])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.1.bn1.weight	torch.Size([512])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.1.bn1.bias	torch.Size([512])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.1.bn1.running_mean	torch.Size([512])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.1.bn1.running_var	torch.Size([512])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.1.conv2.weight	torch.Size([512, 512, 3, 3])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.1.bn2.weight	torch.Size([512])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.1.bn2.bias	torch.Size([512])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.1.bn2.running_mean	torch.Size([512])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.1.bn2.running_var	torch.Size([512])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.1.conv3.weight	torch.Size([2048, 512, 1, 1])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.1.bn3.weight	torch.Size([2048])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.1.bn3.bias	torch.Size([2048])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.1.bn3.running_mean	torch.Size([2048])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.1.bn3.running_var	torch.Size([2048])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.2.conv1.weight	torch.Size([512, 2048, 1, 1])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.2.bn1.weight	torch.Size([512])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.2.bn1.bias	torch.Size([512])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.2.bn1.running_mean	torch.Size([512])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.2.bn1.running_var	torch.Size([512])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.2.conv2.weight	torch.Size([512, 512, 3, 3])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.2.bn2.weight	torch.Size([512])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.2.bn2.bias	torch.Size([512])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.2.bn2.running_mean	torch.Size([512])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.2.bn2.running_var	torch.Size([512])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.2.conv3.weight	torch.Size([2048, 512, 1, 1])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.2.bn3.weight	torch.Size([2048])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.2.bn3.bias	torch.Size([2048])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.2.bn3.running_mean	torch.Size([2048])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.2.bn3.running_var	torch.Size([2048])
INFO - 12/16/22 14:56:04 - 0:00:36 - module.layer4.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:56:04 - 0:00:36 - info.model:
INFO - 12/16/22 14:56:04 - 0:00:36 - DataParallel(
                                       (module): ResNet(
                                         (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)
                                         (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)
                                         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         (relu): ReLU(inplace=True)
                                         (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
                                         (layer1): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (layer2): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                               (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (3): Bottleneck(
                                             (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (layer3): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                               (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (3): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (4): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (5): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (layer4): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                               (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       )
                                     )
INFO - 12/16/22 14:56:07 - 0:00:39 - RegLog's state_dict:
INFO - 12/16/22 14:56:07 - 0:00:39 - module.module.linear.weight	torch.Size([1000, 2048])
INFO - 12/16/22 14:56:07 - 0:00:39 - module.module.linear.bias	torch.Size([1000])
INFO - 12/16/22 14:56:07 - 0:00:39 - info.reglog:
INFO - 12/16/22 14:56:07 - 0:00:39 - DistributedDataParallel(
                                       (module): DataParallel(
                                         (module): RegLog(
                                           (av_pool): AdaptiveAvgPool2d(output_size=(1, 1))
                                           (linear): Linear(in_features=2048, out_features=1000, bias=True)
                                         )
                                       )
                                     )
INFO - 12/16/22 14:56:08 - 0:00:40 - Epoch[0] - Iter: [0/20019]	Time 29.902 (29.902)	Data 24.635 (24.635)	Loss 6.9162 (6.9162)	Prec 0.000 (0.000)	LR 0.3
INFO - 12/16/22 14:56:20 - 0:00:52 - Epoch[0] - Iter: [50/20019]	Time 0.226 (0.808)	Data 0.000 (0.483)	Loss 6.4493 (6.8031)	Prec 6.250 (2.543)	LR 0.3
INFO - 12/16/22 14:56:31 - 0:01:03 - Epoch[0] - Iter: [100/20019]	Time 0.226 (0.521)	Data 0.000 (0.244)	Loss 5.6339 (6.4539)	Prec 20.312 (6.173)	LR 0.3
INFO - 12/16/22 14:56:42 - 0:01:14 - Epoch[0] - Iter: [150/20019]	Time 0.225 (0.423)	Data 0.000 (0.163)	Loss 4.8819 (6.1156)	Prec 26.562 (9.261)	LR 0.3
INFO - 12/16/22 14:56:54 - 0:01:26 - Epoch[0] - Iter: [200/20019]	Time 0.225 (0.374)	Data 0.000 (0.123)	Loss 4.7676 (5.8090)	Prec 20.312 (12.158)	LR 0.3
INFO - 12/16/22 14:57:05 - 0:01:37 - Epoch[0] - Iter: [250/20019]	Time 0.225 (0.344)	Data 0.000 (0.098)	Loss 4.1126 (5.5299)	Prec 28.125 (14.909)	LR 0.3
INFO - 12/16/22 14:57:16 - 0:01:48 - Epoch[0] - Iter: [300/20019]	Time 0.225 (0.325)	Data 0.000 (0.082)	Loss 4.0759 (5.2811)	Prec 32.812 (17.302)	LR 0.3
INFO - 12/16/22 14:57:28 - 0:01:59 - Epoch[0] - Iter: [350/20019]	Time 0.226 (0.311)	Data 0.000 (0.070)	Loss 3.6167 (5.0645)	Prec 29.688 (19.667)	LR 0.3
INFO - 12/16/22 14:57:39 - 0:02:11 - Epoch[0] - Iter: [400/20019]	Time 0.225 (0.300)	Data 0.000 (0.062)	Loss 3.2717 (4.8664)	Prec 45.312 (21.774)	LR 0.3
INFO - 12/16/22 14:58:19 - 0:00:00 - ============ Initialized logger ============
INFO - 12/16/22 14:58:19 - 0:00:00 - arch: resnet50
                                     batch_size: 64
                                     data_path: C:\Users\chris\Downloads\ILSVRC\Data\CLS-LOC
                                     decay_epochs: [60, 80]
                                     dist_url: env://
                                     dump_checkpoints: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model\checkpoints
                                     dump_path: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     epochs: 100
                                     final_lr: 0
                                     gamma: 0.1
                                     global_pooling: True
                                     gpu_to_work_on: 0
                                     is_slurm_job: False
                                     local_rank: 0
                                     lr: 0.3
                                     nesterov: False
                                     pretrained: D:\code_cluster\me_swav\pretrained\swav_800ep_pretrain.pth.tar
                                     rank: 0
                                     scheduler_type: cosine
                                     seed: 31
                                     use_bn: False
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 12/16/22 14:58:19 - 0:00:00 - The experiment will be stored in D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     

INFO - 12/16/22 14:58:19 - 0:00:00 - 0  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 14:58:19 - 0:00:00 - 1  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 14:58:19 - 0:00:00 - build training dataset (start)
INFO - 12/16/22 14:58:28 - 0:00:09 - build training dataset (end)
INFO - 12/16/22 14:58:28 - 0:00:09 - build validation dataset (start)
INFO - 12/16/22 14:58:29 - 0:00:09 - build validation dataset (end)
INFO - 12/16/22 14:58:29 - 0:00:09 - Building data done
INFO - 12/16/22 14:58:30 - 0:00:10 - Load pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['module.projection_head.0.weight', 'module.projection_head.0.bias', 'module.projection_head.1.weight', 'module.projection_head.1.bias', 'module.projection_head.1.running_mean', 'module.projection_head.1.running_var', 'module.projection_head.1.num_batches_tracked', 'module.projection_head.3.weight', 'module.projection_head.3.bias', 'module.prototypes.weight'])
INFO - 12/16/22 14:58:30 - 0:00:10 - ============ Starting epoch 0 ... ============
INFO - 12/16/22 14:58:55 - 0:00:35 - Model's state_dict:
INFO - 12/16/22 14:58:55 - 0:00:35 - module.conv1.weight	torch.Size([64, 3, 7, 7])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.bn1.weight	torch.Size([64])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.bn1.bias	torch.Size([64])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.bn1.running_mean	torch.Size([64])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.bn1.running_var	torch.Size([64])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.0.conv1.weight	torch.Size([64, 64, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.0.bn1.weight	torch.Size([64])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.0.bn1.bias	torch.Size([64])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.0.bn1.running_mean	torch.Size([64])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.0.bn1.running_var	torch.Size([64])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.0.conv2.weight	torch.Size([64, 64, 3, 3])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.0.bn2.weight	torch.Size([64])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.0.bn2.bias	torch.Size([64])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.0.bn2.running_mean	torch.Size([64])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.0.bn2.running_var	torch.Size([64])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.0.conv3.weight	torch.Size([256, 64, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.0.bn3.weight	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.0.bn3.bias	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.0.bn3.running_mean	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.0.bn3.running_var	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.0.downsample.0.weight	torch.Size([256, 64, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.0.downsample.1.weight	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.0.downsample.1.bias	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.0.downsample.1.running_mean	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.0.downsample.1.running_var	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.1.conv1.weight	torch.Size([64, 256, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.1.bn1.weight	torch.Size([64])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.1.bn1.bias	torch.Size([64])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.1.bn1.running_mean	torch.Size([64])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.1.bn1.running_var	torch.Size([64])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.1.conv2.weight	torch.Size([64, 64, 3, 3])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.1.bn2.weight	torch.Size([64])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.1.bn2.bias	torch.Size([64])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.1.bn2.running_mean	torch.Size([64])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.1.bn2.running_var	torch.Size([64])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.1.conv3.weight	torch.Size([256, 64, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.1.bn3.weight	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.1.bn3.bias	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.1.bn3.running_mean	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.1.bn3.running_var	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.2.conv1.weight	torch.Size([64, 256, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.2.bn1.weight	torch.Size([64])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.2.bn1.bias	torch.Size([64])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.2.bn1.running_mean	torch.Size([64])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.2.bn1.running_var	torch.Size([64])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.2.conv2.weight	torch.Size([64, 64, 3, 3])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.2.bn2.weight	torch.Size([64])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.2.bn2.bias	torch.Size([64])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.2.bn2.running_mean	torch.Size([64])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.2.bn2.running_var	torch.Size([64])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.2.conv3.weight	torch.Size([256, 64, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.2.bn3.weight	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.2.bn3.bias	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.2.bn3.running_mean	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.2.bn3.running_var	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer1.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.0.conv1.weight	torch.Size([128, 256, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.0.bn1.weight	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.0.bn1.bias	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.0.bn1.running_mean	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.0.bn1.running_var	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.0.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.0.bn2.weight	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.0.bn2.bias	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.0.bn2.running_mean	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.0.bn2.running_var	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.0.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.0.bn3.weight	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.0.bn3.bias	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.0.bn3.running_mean	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.0.bn3.running_var	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.0.downsample.0.weight	torch.Size([512, 256, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.0.downsample.1.weight	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.0.downsample.1.bias	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.0.downsample.1.running_mean	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.0.downsample.1.running_var	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.1.conv1.weight	torch.Size([128, 512, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.1.bn1.weight	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.1.bn1.bias	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.1.bn1.running_mean	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.1.bn1.running_var	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.1.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.1.bn2.weight	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.1.bn2.bias	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.1.bn2.running_mean	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.1.bn2.running_var	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.1.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.1.bn3.weight	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.1.bn3.bias	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.1.bn3.running_mean	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.1.bn3.running_var	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.2.conv1.weight	torch.Size([128, 512, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.2.bn1.weight	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.2.bn1.bias	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.2.bn1.running_mean	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.2.bn1.running_var	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.2.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.2.bn2.weight	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.2.bn2.bias	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.2.bn2.running_mean	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.2.bn2.running_var	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.2.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.2.bn3.weight	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.2.bn3.bias	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.2.bn3.running_mean	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.2.bn3.running_var	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.3.conv1.weight	torch.Size([128, 512, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.3.bn1.weight	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.3.bn1.bias	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.3.bn1.running_mean	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.3.bn1.running_var	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.3.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.3.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.3.bn2.weight	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.3.bn2.bias	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.3.bn2.running_mean	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.3.bn2.running_var	torch.Size([128])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.3.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.3.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.3.bn3.weight	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.3.bn3.bias	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.3.bn3.running_mean	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.3.bn3.running_var	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer2.3.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.0.conv1.weight	torch.Size([256, 512, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.0.bn1.weight	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.0.bn1.bias	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.0.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.0.bn1.running_var	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.0.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.0.bn2.weight	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.0.bn2.bias	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.0.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.0.bn2.running_var	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.0.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.0.bn3.weight	torch.Size([1024])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.0.bn3.bias	torch.Size([1024])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.0.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.0.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.0.downsample.0.weight	torch.Size([1024, 512, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.0.downsample.1.weight	torch.Size([1024])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.0.downsample.1.bias	torch.Size([1024])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.0.downsample.1.running_mean	torch.Size([1024])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.0.downsample.1.running_var	torch.Size([1024])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.1.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.1.bn1.weight	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.1.bn1.bias	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.1.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.1.bn1.running_var	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.1.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.1.bn2.weight	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.1.bn2.bias	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.1.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.1.bn2.running_var	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.1.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.1.bn3.weight	torch.Size([1024])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.1.bn3.bias	torch.Size([1024])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.1.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.1.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.2.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.2.bn1.weight	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.2.bn1.bias	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.2.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.2.bn1.running_var	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.2.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.2.bn2.weight	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.2.bn2.bias	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.2.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.2.bn2.running_var	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.2.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.2.bn3.weight	torch.Size([1024])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.2.bn3.bias	torch.Size([1024])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.2.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.2.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.3.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.3.bn1.weight	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.3.bn1.bias	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.3.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.3.bn1.running_var	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.3.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.3.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.3.bn2.weight	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.3.bn2.bias	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.3.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.3.bn2.running_var	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.3.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.3.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.3.bn3.weight	torch.Size([1024])
INFO - 12/16/22 14:58:55 - 0:00:35 - module.layer3.3.bn3.bias	torch.Size([1024])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.3.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.3.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.3.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.4.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.4.bn1.weight	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.4.bn1.bias	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.4.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.4.bn1.running_var	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.4.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.4.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.4.bn2.weight	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.4.bn2.bias	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.4.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.4.bn2.running_var	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.4.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.4.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.4.bn3.weight	torch.Size([1024])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.4.bn3.bias	torch.Size([1024])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.4.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.4.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.4.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.5.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.5.bn1.weight	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.5.bn1.bias	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.5.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.5.bn1.running_var	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.5.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.5.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.5.bn2.weight	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.5.bn2.bias	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.5.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.5.bn2.running_var	torch.Size([256])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.5.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.5.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.5.bn3.weight	torch.Size([1024])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.5.bn3.bias	torch.Size([1024])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.5.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.5.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer3.5.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.0.conv1.weight	torch.Size([512, 1024, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.0.bn1.weight	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.0.bn1.bias	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.0.bn1.running_mean	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.0.bn1.running_var	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.0.conv2.weight	torch.Size([512, 512, 3, 3])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.0.bn2.weight	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.0.bn2.bias	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.0.bn2.running_mean	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.0.bn2.running_var	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.0.conv3.weight	torch.Size([2048, 512, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.0.bn3.weight	torch.Size([2048])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.0.bn3.bias	torch.Size([2048])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.0.bn3.running_mean	torch.Size([2048])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.0.bn3.running_var	torch.Size([2048])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.0.downsample.0.weight	torch.Size([2048, 1024, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.0.downsample.1.weight	torch.Size([2048])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.0.downsample.1.bias	torch.Size([2048])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.0.downsample.1.running_mean	torch.Size([2048])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.0.downsample.1.running_var	torch.Size([2048])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.1.conv1.weight	torch.Size([512, 2048, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.1.bn1.weight	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.1.bn1.bias	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.1.bn1.running_mean	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.1.bn1.running_var	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.1.conv2.weight	torch.Size([512, 512, 3, 3])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.1.bn2.weight	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.1.bn2.bias	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.1.bn2.running_mean	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.1.bn2.running_var	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.1.conv3.weight	torch.Size([2048, 512, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.1.bn3.weight	torch.Size([2048])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.1.bn3.bias	torch.Size([2048])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.1.bn3.running_mean	torch.Size([2048])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.1.bn3.running_var	torch.Size([2048])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.2.conv1.weight	torch.Size([512, 2048, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.2.bn1.weight	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.2.bn1.bias	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.2.bn1.running_mean	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.2.bn1.running_var	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.2.conv2.weight	torch.Size([512, 512, 3, 3])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.2.bn2.weight	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.2.bn2.bias	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.2.bn2.running_mean	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.2.bn2.running_var	torch.Size([512])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.2.conv3.weight	torch.Size([2048, 512, 1, 1])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.2.bn3.weight	torch.Size([2048])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.2.bn3.bias	torch.Size([2048])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.2.bn3.running_mean	torch.Size([2048])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.2.bn3.running_var	torch.Size([2048])
INFO - 12/16/22 14:58:55 - 0:00:36 - module.layer4.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 14:58:55 - 0:00:36 - info.model:
INFO - 12/16/22 14:58:55 - 0:00:36 - DataParallel(
                                       (module): ResNet(
                                         (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)
                                         (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)
                                         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         (relu): ReLU(inplace=True)
                                         (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
                                         (layer1): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (layer2): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                               (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (3): Bottleneck(
                                             (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (layer3): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                               (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (3): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (4): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (5): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (layer4): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                               (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       )
                                     )
INFO - 12/16/22 14:58:59 - 0:00:39 - RegLog's state_dict:
INFO - 12/16/22 14:58:59 - 0:00:39 - module.module.linear.weight	torch.Size([1000, 2048])
INFO - 12/16/22 14:58:59 - 0:00:39 - module.module.linear.bias	torch.Size([1000])
INFO - 12/16/22 14:58:59 - 0:00:39 - info.reglog:
INFO - 12/16/22 14:58:59 - 0:00:39 - DistributedDataParallel(
                                       (module): DataParallel(
                                         (module): RegLog(
                                           (av_pool): AdaptiveAvgPool2d(output_size=(1, 1))
                                           (linear): Linear(in_features=2048, out_features=1000, bias=True)
                                         )
                                       )
                                     )
INFO - 12/16/22 14:58:59 - 0:00:39 - Epoch[0] - Iter: [0/20019]	Time 28.689 (28.689)	Data 24.711 (24.711)	Loss 6.9162 (6.9162)	Prec 0.000 (0.000)	LR 0.3
INFO - 12/16/22 14:59:03 - 0:00:44 - Epoch[0] - Iter: [50/20019]	Time 0.094 (0.656)	Data 0.000 (0.485)	Loss 6.4492 (6.8031)	Prec 6.250 (2.543)	LR 0.3
INFO - 12/16/22 14:59:08 - 0:00:49 - Epoch[0] - Iter: [100/20019]	Time 0.094 (0.378)	Data 0.000 (0.245)	Loss 5.6339 (6.4539)	Prec 20.312 (6.173)	LR 0.3
INFO - 12/16/22 14:59:13 - 0:00:53 - Epoch[0] - Iter: [150/20019]	Time 0.093 (0.284)	Data 0.000 (0.164)	Loss 4.8819 (6.1156)	Prec 26.562 (9.261)	LR 0.3
INFO - 12/16/22 14:59:17 - 0:00:58 - Epoch[0] - Iter: [200/20019]	Time 0.094 (0.236)	Data 0.000 (0.123)	Loss 4.7676 (5.8090)	Prec 20.312 (12.158)	LR 0.3
INFO - 12/16/22 14:59:22 - 0:01:03 - Epoch[0] - Iter: [250/20019]	Time 0.093 (0.208)	Data 0.000 (0.099)	Loss 4.1125 (5.5299)	Prec 28.125 (14.903)	LR 0.3
INFO - 12/16/22 14:59:27 - 0:01:07 - Epoch[0] - Iter: [300/20019]	Time 0.093 (0.189)	Data 0.000 (0.082)	Loss 4.0759 (5.2812)	Prec 32.812 (17.297)	LR 0.3
INFO - 12/16/22 14:59:32 - 0:01:12 - Epoch[0] - Iter: [350/20019]	Time 0.093 (0.176)	Data 0.000 (0.071)	Loss 3.6168 (5.0645)	Prec 29.688 (19.663)	LR 0.3
INFO - 12/16/22 14:59:36 - 0:01:17 - Epoch[0] - Iter: [400/20019]	Time 0.093 (0.165)	Data 0.000 (0.062)	Loss 3.2716 (4.8665)	Prec 45.312 (21.770)	LR 0.3
INFO - 12/16/22 14:59:41 - 0:01:21 - Epoch[0] - Iter: [450/20019]	Time 0.093 (0.157)	Data 0.000 (0.055)	Loss 3.2689 (4.6906)	Prec 37.500 (23.784)	LR 0.3
INFO - 12/16/22 14:59:46 - 0:01:26 - Epoch[0] - Iter: [500/20019]	Time 0.093 (0.151)	Data 0.000 (0.050)	Loss 2.5443 (4.5337)	Prec 51.562 (25.530)	LR 0.3
INFO - 12/16/22 14:59:50 - 0:01:31 - Epoch[0] - Iter: [550/20019]	Time 0.093 (0.146)	Data 0.000 (0.045)	Loss 2.6959 (4.4020)	Prec 46.875 (27.002)	LR 0.3
INFO - 12/16/22 14:59:55 - 0:01:36 - Epoch[0] - Iter: [600/20019]	Time 0.094 (0.142)	Data 0.000 (0.041)	Loss 3.1438 (4.2776)	Prec 39.062 (28.403)	LR 0.3
INFO - 12/16/22 15:00:00 - 0:01:40 - Epoch[0] - Iter: [650/20019]	Time 0.093 (0.138)	Data 0.000 (0.038)	Loss 2.4970 (4.1686)	Prec 51.562 (29.714)	LR 0.3
INFO - 12/16/22 15:00:04 - 0:01:45 - Epoch[0] - Iter: [700/20019]	Time 0.095 (0.135)	Data 0.000 (0.035)	Loss 2.8148 (4.0676)	Prec 48.438 (30.824)	LR 0.3
INFO - 12/16/22 15:00:09 - 0:01:50 - Epoch[0] - Iter: [750/20019]	Time 0.093 (0.132)	Data 0.000 (0.033)	Loss 2.3888 (3.9763)	Prec 48.438 (31.891)	LR 0.3
INFO - 12/16/22 15:00:14 - 0:01:54 - Epoch[0] - Iter: [800/20019]	Time 0.093 (0.130)	Data 0.000 (0.031)	Loss 2.8675 (3.8925)	Prec 39.062 (32.830)	LR 0.3
INFO - 12/16/22 15:00:19 - 0:01:59 - Epoch[0] - Iter: [850/20019]	Time 0.094 (0.128)	Data 0.000 (0.029)	Loss 2.7196 (3.8198)	Prec 43.750 (33.650)	LR 0.3
INFO - 12/16/22 15:00:23 - 0:02:04 - Epoch[0] - Iter: [900/20019]	Time 0.097 (0.126)	Data 0.000 (0.028)	Loss 2.7171 (3.7496)	Prec 46.875 (34.429)	LR 0.3
INFO - 12/16/22 15:00:28 - 0:02:09 - Epoch[0] - Iter: [950/20019]	Time 0.094 (0.124)	Data 0.000 (0.026)	Loss 2.3440 (3.6841)	Prec 48.438 (35.241)	LR 0.3
INFO - 12/16/22 15:15:23 - 0:00:00 - ============ Initialized logger ============
INFO - 12/16/22 15:15:23 - 0:00:00 - arch: resnet50
                                     batch_size: 64
                                     data_path: C:\Users\chris\Downloads\ILSVRC\Data\CLS-LOC
                                     decay_epochs: [60, 80]
                                     dist_url: env://
                                     dump_checkpoints: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model\checkpoints
                                     dump_path: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     epochs: 100
                                     final_lr: 0
                                     gamma: 0.1
                                     global_pooling: True
                                     gpu_to_work_on: 0
                                     is_slurm_job: False
                                     local_rank: 0
                                     lr: 0.3
                                     nesterov: False
                                     pretrained: D:\code_cluster\me_swav\pretrained\swav_800ep_pretrain.pth.tar
                                     rank: 0
                                     scheduler_type: cosine
                                     seed: 31
                                     use_bn: False
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 12/16/22 15:15:23 - 0:00:00 - The experiment will be stored in D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     

INFO - 12/16/22 15:15:23 - 0:00:00 - 0  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 15:15:23 - 0:00:00 - 1  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 15:15:23 - 0:00:00 - build training dataset (start)
INFO - 12/16/22 15:15:32 - 0:00:09 - build training dataset (end)
INFO - 12/16/22 15:15:32 - 0:00:09 - build validation dataset (start)
INFO - 12/16/22 15:15:32 - 0:00:09 - build validation dataset (end)
INFO - 12/16/22 15:15:32 - 0:00:09 - Building data done
INFO - 12/16/22 15:16:16 - 0:00:00 - ============ Initialized logger ============
INFO - 12/16/22 15:16:16 - 0:00:00 - arch: resnet50
                                     batch_size: 64
                                     data_path: C:\Users\chris\Downloads\ILSVRC\Data\CLS-LOC
                                     decay_epochs: [60, 80]
                                     dist_url: env://
                                     dump_checkpoints: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model\checkpoints
                                     dump_path: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     epochs: 100
                                     final_lr: 0
                                     gamma: 0.1
                                     global_pooling: True
                                     gpu_to_work_on: 0
                                     is_slurm_job: False
                                     local_rank: 0
                                     lr: 0.3
                                     nesterov: False
                                     pretrained: D:\code_cluster\me_swav\pretrained\swav_800ep_pretrain.pth.tar
                                     rank: 0
                                     scheduler_type: cosine
                                     seed: 31
                                     use_bn: False
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 12/16/22 15:16:16 - 0:00:00 - The experiment will be stored in D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     

INFO - 12/16/22 15:16:16 - 0:00:00 - 0  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 15:16:16 - 0:00:00 - 1  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 15:16:16 - 0:00:00 - build training dataset (start)
INFO - 12/16/22 15:16:25 - 0:00:09 - build training dataset (end)
INFO - 12/16/22 15:16:25 - 0:00:09 - build validation dataset (start)
INFO - 12/16/22 15:16:25 - 0:00:10 - build validation dataset (end)
INFO - 12/16/22 15:16:25 - 0:00:10 - Building data done
INFO - 12/16/22 15:16:26 - 0:00:10 - Load pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['module.projection_head.0.weight', 'module.projection_head.0.bias', 'module.projection_head.1.weight', 'module.projection_head.1.bias', 'module.projection_head.1.running_mean', 'module.projection_head.1.running_var', 'module.projection_head.1.num_batches_tracked', 'module.projection_head.3.weight', 'module.projection_head.3.bias', 'module.prototypes.weight'])
INFO - 12/16/22 15:16:26 - 0:00:10 - ============ Starting epoch 0 ... ============
INFO - 12/16/22 15:16:51 - 0:00:35 - gpu0: pynvml module not found, please install pynvml
INFO - 12/16/22 15:16:51 - 0:00:35 - gpu1: pynvml module not found, please install pynvml
INFO - 12/16/22 15:16:51 - 0:00:35 - Model's state_dict:
INFO - 12/16/22 15:16:51 - 0:00:35 - module.conv1.weight	torch.Size([64, 3, 7, 7])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.bn1.weight	torch.Size([64])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.bn1.bias	torch.Size([64])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.bn1.running_mean	torch.Size([64])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.bn1.running_var	torch.Size([64])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.0.conv1.weight	torch.Size([64, 64, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.0.bn1.weight	torch.Size([64])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.0.bn1.bias	torch.Size([64])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.0.bn1.running_mean	torch.Size([64])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.0.bn1.running_var	torch.Size([64])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.0.conv2.weight	torch.Size([64, 64, 3, 3])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.0.bn2.weight	torch.Size([64])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.0.bn2.bias	torch.Size([64])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.0.bn2.running_mean	torch.Size([64])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.0.bn2.running_var	torch.Size([64])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.0.conv3.weight	torch.Size([256, 64, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.0.bn3.weight	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.0.bn3.bias	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.0.bn3.running_mean	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.0.bn3.running_var	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.0.downsample.0.weight	torch.Size([256, 64, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.0.downsample.1.weight	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.0.downsample.1.bias	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.0.downsample.1.running_mean	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.0.downsample.1.running_var	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.1.conv1.weight	torch.Size([64, 256, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.1.bn1.weight	torch.Size([64])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.1.bn1.bias	torch.Size([64])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.1.bn1.running_mean	torch.Size([64])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.1.bn1.running_var	torch.Size([64])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.1.conv2.weight	torch.Size([64, 64, 3, 3])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.1.bn2.weight	torch.Size([64])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.1.bn2.bias	torch.Size([64])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.1.bn2.running_mean	torch.Size([64])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.1.bn2.running_var	torch.Size([64])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.1.conv3.weight	torch.Size([256, 64, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.1.bn3.weight	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.1.bn3.bias	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.1.bn3.running_mean	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.1.bn3.running_var	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.2.conv1.weight	torch.Size([64, 256, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.2.bn1.weight	torch.Size([64])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.2.bn1.bias	torch.Size([64])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.2.bn1.running_mean	torch.Size([64])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.2.bn1.running_var	torch.Size([64])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.2.conv2.weight	torch.Size([64, 64, 3, 3])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.2.bn2.weight	torch.Size([64])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.2.bn2.bias	torch.Size([64])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.2.bn2.running_mean	torch.Size([64])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.2.bn2.running_var	torch.Size([64])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.2.conv3.weight	torch.Size([256, 64, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.2.bn3.weight	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.2.bn3.bias	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.2.bn3.running_mean	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.2.bn3.running_var	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer1.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.0.conv1.weight	torch.Size([128, 256, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.0.bn1.weight	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.0.bn1.bias	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.0.bn1.running_mean	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.0.bn1.running_var	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.0.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.0.bn2.weight	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.0.bn2.bias	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.0.bn2.running_mean	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.0.bn2.running_var	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.0.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.0.bn3.weight	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.0.bn3.bias	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.0.bn3.running_mean	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.0.bn3.running_var	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.0.downsample.0.weight	torch.Size([512, 256, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.0.downsample.1.weight	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.0.downsample.1.bias	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.0.downsample.1.running_mean	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.0.downsample.1.running_var	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.1.conv1.weight	torch.Size([128, 512, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.1.bn1.weight	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.1.bn1.bias	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.1.bn1.running_mean	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.1.bn1.running_var	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.1.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.1.bn2.weight	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.1.bn2.bias	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.1.bn2.running_mean	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.1.bn2.running_var	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.1.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.1.bn3.weight	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.1.bn3.bias	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.1.bn3.running_mean	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.1.bn3.running_var	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.2.conv1.weight	torch.Size([128, 512, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.2.bn1.weight	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.2.bn1.bias	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.2.bn1.running_mean	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.2.bn1.running_var	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.2.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.2.bn2.weight	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.2.bn2.bias	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.2.bn2.running_mean	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.2.bn2.running_var	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.2.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.2.bn3.weight	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.2.bn3.bias	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.2.bn3.running_mean	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.2.bn3.running_var	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.3.conv1.weight	torch.Size([128, 512, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.3.bn1.weight	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.3.bn1.bias	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.3.bn1.running_mean	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.3.bn1.running_var	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.3.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.3.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.3.bn2.weight	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.3.bn2.bias	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.3.bn2.running_mean	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.3.bn2.running_var	torch.Size([128])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.3.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.3.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.3.bn3.weight	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.3.bn3.bias	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.3.bn3.running_mean	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.3.bn3.running_var	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer2.3.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.0.conv1.weight	torch.Size([256, 512, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.0.bn1.weight	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.0.bn1.bias	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.0.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.0.bn1.running_var	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.0.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.0.bn2.weight	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.0.bn2.bias	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.0.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.0.bn2.running_var	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.0.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.0.bn3.weight	torch.Size([1024])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.0.bn3.bias	torch.Size([1024])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.0.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.0.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.0.downsample.0.weight	torch.Size([1024, 512, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.0.downsample.1.weight	torch.Size([1024])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.0.downsample.1.bias	torch.Size([1024])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.0.downsample.1.running_mean	torch.Size([1024])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.0.downsample.1.running_var	torch.Size([1024])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.1.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.1.bn1.weight	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.1.bn1.bias	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.1.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.1.bn1.running_var	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.1.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.1.bn2.weight	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.1.bn2.bias	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.1.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.1.bn2.running_var	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.1.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.1.bn3.weight	torch.Size([1024])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.1.bn3.bias	torch.Size([1024])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.1.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.1.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.2.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.2.bn1.weight	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.2.bn1.bias	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.2.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.2.bn1.running_var	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.2.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.2.bn2.weight	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.2.bn2.bias	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.2.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.2.bn2.running_var	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.2.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.2.bn3.weight	torch.Size([1024])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.2.bn3.bias	torch.Size([1024])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.2.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.2.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.3.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.3.bn1.weight	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.3.bn1.bias	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.3.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.3.bn1.running_var	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.3.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.3.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.3.bn2.weight	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.3.bn2.bias	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.3.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.3.bn2.running_var	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.3.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.3.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.3.bn3.weight	torch.Size([1024])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.3.bn3.bias	torch.Size([1024])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.3.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.3.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.3.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.4.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.4.bn1.weight	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.4.bn1.bias	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.4.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.4.bn1.running_var	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.4.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.4.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.4.bn2.weight	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.4.bn2.bias	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.4.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.4.bn2.running_var	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.4.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.4.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.4.bn3.weight	torch.Size([1024])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.4.bn3.bias	torch.Size([1024])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.4.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.4.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.4.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.5.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.5.bn1.weight	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.5.bn1.bias	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.5.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.5.bn1.running_var	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.5.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.5.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.5.bn2.weight	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.5.bn2.bias	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.5.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.5.bn2.running_var	torch.Size([256])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.5.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.5.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.5.bn3.weight	torch.Size([1024])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.5.bn3.bias	torch.Size([1024])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.5.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.5.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer3.5.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.0.conv1.weight	torch.Size([512, 1024, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.0.bn1.weight	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.0.bn1.bias	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.0.bn1.running_mean	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.0.bn1.running_var	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.0.conv2.weight	torch.Size([512, 512, 3, 3])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.0.bn2.weight	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.0.bn2.bias	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.0.bn2.running_mean	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.0.bn2.running_var	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.0.conv3.weight	torch.Size([2048, 512, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.0.bn3.weight	torch.Size([2048])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.0.bn3.bias	torch.Size([2048])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.0.bn3.running_mean	torch.Size([2048])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.0.bn3.running_var	torch.Size([2048])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.0.downsample.0.weight	torch.Size([2048, 1024, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.0.downsample.1.weight	torch.Size([2048])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.0.downsample.1.bias	torch.Size([2048])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.0.downsample.1.running_mean	torch.Size([2048])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.0.downsample.1.running_var	torch.Size([2048])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.1.conv1.weight	torch.Size([512, 2048, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.1.bn1.weight	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.1.bn1.bias	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.1.bn1.running_mean	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.1.bn1.running_var	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.1.conv2.weight	torch.Size([512, 512, 3, 3])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.1.bn2.weight	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.1.bn2.bias	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.1.bn2.running_mean	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.1.bn2.running_var	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.1.conv3.weight	torch.Size([2048, 512, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.1.bn3.weight	torch.Size([2048])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.1.bn3.bias	torch.Size([2048])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.1.bn3.running_mean	torch.Size([2048])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.1.bn3.running_var	torch.Size([2048])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.2.conv1.weight	torch.Size([512, 2048, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.2.bn1.weight	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.2.bn1.bias	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.2.bn1.running_mean	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.2.bn1.running_var	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.2.conv2.weight	torch.Size([512, 512, 3, 3])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.2.bn2.weight	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.2.bn2.bias	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.2.bn2.running_mean	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.2.bn2.running_var	torch.Size([512])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.2.conv3.weight	torch.Size([2048, 512, 1, 1])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.2.bn3.weight	torch.Size([2048])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.2.bn3.bias	torch.Size([2048])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.2.bn3.running_mean	torch.Size([2048])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.2.bn3.running_var	torch.Size([2048])
INFO - 12/16/22 15:16:51 - 0:00:35 - module.layer4.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 15:16:51 - 0:00:35 - info.model:
INFO - 12/16/22 15:16:51 - 0:00:35 - DataParallel(
                                       (module): ResNet(
                                         (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)
                                         (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)
                                         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         (relu): ReLU(inplace=True)
                                         (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
                                         (layer1): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (layer2): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                               (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (3): Bottleneck(
                                             (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (layer3): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                               (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (3): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (4): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (5): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (layer4): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                               (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       )
                                     )
INFO - 12/16/22 15:16:55 - 0:00:39 - RegLog's state_dict:
INFO - 12/16/22 15:16:55 - 0:00:39 - module.module.linear.weight	torch.Size([1000, 2048])
INFO - 12/16/22 15:16:55 - 0:00:39 - module.module.linear.bias	torch.Size([1000])
INFO - 12/16/22 15:16:55 - 0:00:39 - info.reglog:
INFO - 12/16/22 15:16:55 - 0:00:39 - DistributedDataParallel(
                                       (module): DataParallel(
                                         (module): RegLog(
                                           (av_pool): AdaptiveAvgPool2d(output_size=(1, 1))
                                           (linear): Linear(in_features=2048, out_features=1000, bias=True)
                                         )
                                       )
                                     )
INFO - 12/16/22 15:16:55 - 0:00:39 - Epoch[0] - Iter: [0/20019]	Time 28.567 (28.567)	Data 24.441 (24.441)	Loss 6.9162 (6.9162)	Prec 0.000 (0.000)	LR 0.3
INFO - 12/16/22 15:17:00 - 0:00:44 - Epoch[0] - Iter: [50/20019]	Time 0.094 (0.654)	Data 0.000 (0.479)	Loss 6.4493 (6.8031)	Prec 6.250 (2.543)	LR 0.3
INFO - 12/16/22 15:17:04 - 0:00:49 - Epoch[0] - Iter: [100/20019]	Time 0.094 (0.377)	Data 0.000 (0.242)	Loss 5.6339 (6.4539)	Prec 20.312 (6.157)	LR 0.3
INFO - 12/16/22 15:17:09 - 0:00:53 - Epoch[0] - Iter: [150/20019]	Time 0.094 (0.283)	Data 0.000 (0.162)	Loss 4.8818 (6.1155)	Prec 26.562 (9.251)	LR 0.3
INFO - 12/16/22 15:17:14 - 0:00:58 - Epoch[0] - Iter: [200/20019]	Time 0.093 (0.236)	Data 0.000 (0.122)	Loss 4.7676 (5.8090)	Prec 20.312 (12.150)	LR 0.3
INFO - 12/16/22 15:17:19 - 0:01:03 - Epoch[0] - Iter: [250/20019]	Time 0.094 (0.208)	Data 0.000 (0.098)	Loss 4.1126 (5.5299)	Prec 28.125 (14.903)	LR 0.3
INFO - 12/16/22 15:17:23 - 0:01:07 - Epoch[0] - Iter: [300/20019]	Time 0.093 (0.189)	Data 0.000 (0.081)	Loss 4.0759 (5.2811)	Prec 32.812 (17.297)	LR 0.3
INFO - 12/16/22 15:17:28 - 0:01:12 - Epoch[0] - Iter: [350/20019]	Time 0.094 (0.176)	Data 0.000 (0.070)	Loss 3.6167 (5.0645)	Prec 29.688 (19.663)	LR 0.3
INFO - 12/16/22 15:17:33 - 0:01:17 - Epoch[0] - Iter: [400/20019]	Time 0.093 (0.166)	Data 0.000 (0.061)	Loss 3.2717 (4.8664)	Prec 45.312 (21.770)	LR 0.3
INFO - 12/16/22 15:17:37 - 0:01:22 - Epoch[0] - Iter: [450/20019]	Time 0.094 (0.158)	Data 0.000 (0.054)	Loss 3.2688 (4.6905)	Prec 37.500 (23.784)	LR 0.3
INFO - 12/16/22 15:17:42 - 0:01:26 - Epoch[0] - Iter: [500/20019]	Time 0.094 (0.151)	Data 0.000 (0.049)	Loss 2.5443 (4.5337)	Prec 51.562 (25.530)	LR 0.3
INFO - 12/16/22 15:17:47 - 0:01:31 - Epoch[0] - Iter: [550/20019]	Time 0.094 (0.146)	Data 0.000 (0.045)	Loss 2.6958 (4.4020)	Prec 46.875 (27.002)	LR 0.3
INFO - 12/16/22 15:17:52 - 0:01:36 - Epoch[0] - Iter: [600/20019]	Time 0.094 (0.142)	Data 0.000 (0.041)	Loss 3.1438 (4.2776)	Prec 39.062 (28.403)	LR 0.3
INFO - 12/16/22 15:17:56 - 0:01:41 - Epoch[0] - Iter: [650/20019]	Time 0.094 (0.138)	Data 0.000 (0.038)	Loss 2.4970 (4.1686)	Prec 51.562 (29.714)	LR 0.3
INFO - 12/16/22 15:18:01 - 0:01:45 - Epoch[0] - Iter: [700/20019]	Time 0.094 (0.135)	Data 0.000 (0.035)	Loss 2.8148 (4.0676)	Prec 48.438 (30.824)	LR 0.3
INFO - 12/16/22 15:18:06 - 0:01:50 - Epoch[0] - Iter: [750/20019]	Time 0.094 (0.133)	Data 0.000 (0.033)	Loss 2.3888 (3.9763)	Prec 48.438 (31.889)	LR 0.3
INFO - 12/16/22 15:18:11 - 0:01:55 - Epoch[0] - Iter: [800/20019]	Time 0.094 (0.130)	Data 0.000 (0.031)	Loss 2.8674 (3.8925)	Prec 39.062 (32.828)	LR 0.3
INFO - 12/16/22 15:18:15 - 0:01:59 - Epoch[0] - Iter: [850/20019]	Time 0.094 (0.128)	Data 0.000 (0.029)	Loss 2.7196 (3.8198)	Prec 43.750 (33.648)	LR 0.3
INFO - 12/16/22 15:18:20 - 0:02:04 - Epoch[0] - Iter: [900/20019]	Time 0.094 (0.126)	Data 0.000 (0.027)	Loss 2.7172 (3.7495)	Prec 46.875 (34.427)	LR 0.3
INFO - 12/16/22 15:18:25 - 0:02:09 - Epoch[0] - Iter: [950/20019]	Time 0.094 (0.124)	Data 0.000 (0.026)	Loss 2.3441 (3.6841)	Prec 48.438 (35.239)	LR 0.3
INFO - 12/16/22 15:18:29 - 0:02:14 - Epoch[0] - Iter: [1000/20019]	Time 0.094 (0.123)	Data 0.000 (0.025)	Loss 2.4545 (3.6229)	Prec 46.875 (35.897)	LR 0.3
INFO - 12/16/22 15:18:34 - 0:02:18 - Epoch[0] - Iter: [1050/20019]	Time 0.094 (0.122)	Data 0.000 (0.023)	Loss 2.3962 (3.5660)	Prec 53.125 (36.611)	LR 0.3
INFO - 12/16/22 15:18:39 - 0:02:23 - Epoch[0] - Iter: [1100/20019]	Time 0.094 (0.120)	Data 0.000 (0.022)	Loss 2.5512 (3.5109)	Prec 46.875 (37.213)	LR 0.3
INFO - 12/16/22 15:18:44 - 0:02:28 - Epoch[0] - Iter: [1150/20019]	Time 0.094 (0.119)	Data 0.000 (0.021)	Loss 2.4410 (3.4649)	Prec 46.875 (37.751)	LR 0.3
INFO - 12/16/22 15:18:48 - 0:02:33 - Epoch[0] - Iter: [1200/20019]	Time 0.094 (0.118)	Data 0.000 (0.021)	Loss 2.3747 (3.4189)	Prec 43.750 (38.269)	LR 0.3
INFO - 12/16/22 15:18:53 - 0:02:37 - Epoch[0] - Iter: [1250/20019]	Time 0.093 (0.117)	Data 0.000 (0.020)	Loss 2.1021 (3.3760)	Prec 56.250 (38.784)	LR 0.3
INFO - 12/16/22 15:18:58 - 0:02:42 - Epoch[0] - Iter: [1300/20019]	Time 0.094 (0.116)	Data 0.000 (0.019)	Loss 2.0688 (3.3335)	Prec 51.562 (39.291)	LR 0.3
INFO - 12/16/22 15:19:03 - 0:02:47 - Epoch[0] - Iter: [1350/20019]	Time 0.094 (0.116)	Data 0.000 (0.018)	Loss 1.9608 (3.2936)	Prec 56.250 (39.796)	LR 0.3
INFO - 12/16/22 15:19:07 - 0:02:51 - Epoch[0] - Iter: [1400/20019]	Time 0.094 (0.115)	Data 0.000 (0.018)	Loss 2.2488 (3.2564)	Prec 48.438 (40.221)	LR 0.3
INFO - 12/16/22 15:19:12 - 0:02:56 - Epoch[0] - Iter: [1450/20019]	Time 0.094 (0.114)	Data 0.000 (0.017)	Loss 2.4463 (3.2187)	Prec 56.250 (40.693)	LR 0.3
INFO - 12/16/22 15:19:17 - 0:03:01 - Epoch[0] - Iter: [1500/20019]	Time 0.094 (0.114)	Data 0.000 (0.017)	Loss 1.7531 (3.1844)	Prec 67.188 (41.115)	LR 0.3
INFO - 12/16/22 15:19:22 - 0:03:06 - Epoch[0] - Iter: [1550/20019]	Time 0.094 (0.113)	Data 0.000 (0.016)	Loss 2.2067 (3.1531)	Prec 45.312 (41.468)	LR 0.3
INFO - 12/16/22 15:19:26 - 0:03:10 - Epoch[0] - Iter: [1600/20019]	Time 0.095 (0.112)	Data 0.000 (0.015)	Loss 2.5841 (3.1224)	Prec 51.562 (41.860)	LR 0.3
INFO - 12/16/22 15:19:31 - 0:03:15 - Epoch[0] - Iter: [1650/20019]	Time 0.094 (0.112)	Data 0.000 (0.015)	Loss 1.8762 (3.0949)	Prec 57.812 (42.171)	LR 0.3
INFO - 12/16/22 15:19:36 - 0:03:20 - Epoch[0] - Iter: [1700/20019]	Time 0.097 (0.111)	Data 0.000 (0.015)	Loss 2.1623 (3.0673)	Prec 53.125 (42.539)	LR 0.3
INFO - 12/16/22 15:19:41 - 0:03:25 - Epoch[0] - Iter: [1750/20019]	Time 0.095 (0.111)	Data 0.000 (0.014)	Loss 2.1601 (3.0397)	Prec 53.125 (42.897)	LR 0.3
INFO - 12/16/22 15:19:45 - 0:03:30 - Epoch[0] - Iter: [1800/20019]	Time 0.107 (0.111)	Data 0.000 (0.014)	Loss 2.6903 (3.0144)	Prec 40.625 (43.209)	LR 0.3
INFO - 12/16/22 15:19:50 - 0:03:34 - Epoch[0] - Iter: [1850/20019]	Time 0.094 (0.110)	Data 0.000 (0.013)	Loss 2.3126 (2.9884)	Prec 53.125 (43.552)	LR 0.3
INFO - 12/16/22 15:19:55 - 0:03:39 - Epoch[0] - Iter: [1900/20019]	Time 0.094 (0.110)	Data 0.000 (0.013)	Loss 2.4180 (2.9642)	Prec 43.750 (43.840)	LR 0.3
INFO - 12/16/22 15:20:00 - 0:03:44 - Epoch[0] - Iter: [1950/20019]	Time 0.100 (0.109)	Data 0.000 (0.013)	Loss 2.7797 (2.9419)	Prec 40.625 (44.101)	LR 0.3
INFO - 12/16/22 15:20:04 - 0:03:49 - Epoch[0] - Iter: [2000/20019]	Time 0.095 (0.109)	Data 0.000 (0.012)	Loss 2.0175 (2.9207)	Prec 53.125 (44.381)	LR 0.3
INFO - 12/16/22 15:20:09 - 0:03:53 - Epoch[0] - Iter: [2050/20019]	Time 0.094 (0.109)	Data 0.000 (0.012)	Loss 2.1902 (2.8993)	Prec 48.438 (44.638)	LR 0.3
INFO - 12/16/22 15:20:14 - 0:03:58 - Epoch[0] - Iter: [2100/20019]	Time 0.095 (0.108)	Data 0.000 (0.012)	Loss 2.1131 (2.8783)	Prec 50.000 (44.888)	LR 0.3
INFO - 12/16/22 15:20:19 - 0:04:03 - Epoch[0] - Iter: [2150/20019]	Time 0.096 (0.108)	Data 0.000 (0.012)	Loss 1.8266 (2.8584)	Prec 53.125 (45.139)	LR 0.3
INFO - 12/16/22 15:20:24 - 0:04:08 - Epoch[0] - Iter: [2200/20019]	Time 0.095 (0.108)	Data 0.000 (0.011)	Loss 2.3331 (2.8400)	Prec 54.688 (45.393)	LR 0.3
INFO - 12/16/22 15:20:28 - 0:04:12 - Epoch[0] - Iter: [2250/20019]	Time 0.094 (0.107)	Data 0.000 (0.011)	Loss 1.4851 (2.8201)	Prec 70.312 (45.646)	LR 0.3
INFO - 12/16/22 15:20:33 - 0:04:17 - Epoch[0] - Iter: [2300/20019]	Time 0.095 (0.107)	Data 0.000 (0.011)	Loss 2.2274 (2.8023)	Prec 53.125 (45.875)	LR 0.3
INFO - 12/16/22 15:20:38 - 0:04:22 - Epoch[0] - Iter: [2350/20019]	Time 0.096 (0.107)	Data 0.000 (0.011)	Loss 2.0640 (2.7851)	Prec 50.000 (46.109)	LR 0.3
INFO - 12/16/22 15:20:43 - 0:04:27 - Epoch[0] - Iter: [2400/20019]	Time 0.094 (0.107)	Data 0.000 (0.010)	Loss 2.3159 (2.7684)	Prec 45.312 (46.331)	LR 0.3
INFO - 12/16/22 15:20:47 - 0:04:32 - Epoch[0] - Iter: [2450/20019]	Time 0.094 (0.107)	Data 0.000 (0.010)	Loss 2.2085 (2.7536)	Prec 50.000 (46.511)	LR 0.3
INFO - 12/16/22 15:20:53 - 0:00:00 - ============ Initialized logger ============
INFO - 12/16/22 15:20:53 - 0:00:00 - arch: resnet50
                                     batch_size: 64
                                     data_path: C:\Users\chris\Downloads\ILSVRC\Data\CLS-LOC
                                     decay_epochs: [60, 80]
                                     dist_url: env://
                                     dump_checkpoints: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model\checkpoints
                                     dump_path: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     epochs: 100
                                     final_lr: 0
                                     gamma: 0.1
                                     global_pooling: True
                                     gpu_to_work_on: 0
                                     is_slurm_job: False
                                     local_rank: 0
                                     lr: 0.3
                                     nesterov: False
                                     pretrained: D:\code_cluster\me_swav\pretrained\swav_800ep_pretrain.pth.tar
                                     rank: 0
                                     scheduler_type: cosine
                                     seed: 31
                                     use_bn: False
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 12/16/22 15:20:53 - 0:00:00 - The experiment will be stored in D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     

INFO - 12/16/22 15:20:53 - 0:00:00 - 0  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 15:20:53 - 0:00:00 - 1  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 15:20:53 - 0:00:00 - build training dataset (start)
INFO - 12/16/22 15:21:03 - 0:00:10 - build training dataset (end)
INFO - 12/16/22 15:21:03 - 0:00:10 - build validation dataset (start)
INFO - 12/16/22 15:21:03 - 0:00:10 - build validation dataset (end)
INFO - 12/16/22 15:21:03 - 0:00:10 - Building data done
INFO - 12/16/22 15:21:04 - 0:00:11 - Load pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['module.projection_head.0.weight', 'module.projection_head.0.bias', 'module.projection_head.1.weight', 'module.projection_head.1.bias', 'module.projection_head.1.running_mean', 'module.projection_head.1.running_var', 'module.projection_head.1.num_batches_tracked', 'module.projection_head.3.weight', 'module.projection_head.3.bias', 'module.prototypes.weight'])
INFO - 12/16/22 15:21:04 - 0:00:11 - ============ Starting epoch 0 ... ============
INFO - 12/16/22 15:23:54 - 0:00:00 - ============ Initialized logger ============
INFO - 12/16/22 15:23:54 - 0:00:00 - arch: resnet50
                                     batch_size: 64
                                     data_path: C:\Users\chris\Downloads\ILSVRC\Data\CLS-LOC
                                     decay_epochs: [60, 80]
                                     dist_url: env://
                                     dump_checkpoints: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model\checkpoints
                                     dump_path: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     epochs: 100
                                     final_lr: 0
                                     gamma: 0.1
                                     global_pooling: True
                                     gpu_to_work_on: 0
                                     is_slurm_job: False
                                     local_rank: 0
                                     lr: 0.3
                                     nesterov: False
                                     pretrained: D:\code_cluster\me_swav\pretrained\swav_800ep_pretrain.pth.tar
                                     rank: 0
                                     scheduler_type: cosine
                                     seed: 31
                                     use_bn: False
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 12/16/22 15:23:54 - 0:00:00 - The experiment will be stored in D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     

INFO - 12/16/22 15:23:54 - 0:00:00 - 0  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 15:23:54 - 0:00:00 - 1  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 15:23:54 - 0:00:00 - build training dataset (start)
INFO - 12/16/22 15:24:03 - 0:00:09 - build training dataset (end)
INFO - 12/16/22 15:24:03 - 0:00:09 - build validation dataset (start)
INFO - 12/16/22 15:24:03 - 0:00:09 - build validation dataset (end)
INFO - 12/16/22 15:24:03 - 0:00:09 - Building data done
INFO - 12/16/22 15:24:04 - 0:00:10 - Load pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['module.projection_head.0.weight', 'module.projection_head.0.bias', 'module.projection_head.1.weight', 'module.projection_head.1.bias', 'module.projection_head.1.running_mean', 'module.projection_head.1.running_var', 'module.projection_head.1.num_batches_tracked', 'module.projection_head.3.weight', 'module.projection_head.3.bias', 'module.prototypes.weight'])
INFO - 12/16/22 15:24:04 - 0:00:10 - ============ Starting epoch 0 ... ============
INFO - 12/16/22 15:27:48 - 0:00:00 - ============ Initialized logger ============
INFO - 12/16/22 15:27:48 - 0:00:00 - arch: resnet50
                                     batch_size: 64
                                     data_path: C:\Users\chris\Downloads\ILSVRC\Data\CLS-LOC
                                     decay_epochs: [60, 80]
                                     dist_url: env://
                                     dump_checkpoints: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model\checkpoints
                                     dump_path: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     epochs: 100
                                     final_lr: 0
                                     gamma: 0.1
                                     global_pooling: True
                                     gpu_to_work_on: 0
                                     is_slurm_job: False
                                     local_rank: 0
                                     lr: 0.3
                                     nesterov: False
                                     pretrained: D:\code_cluster\me_swav\pretrained\swav_800ep_pretrain.pth.tar
                                     rank: 0
                                     scheduler_type: cosine
                                     seed: 31
                                     use_bn: False
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 12/16/22 15:27:48 - 0:00:00 - The experiment will be stored in D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     

INFO - 12/16/22 15:27:48 - 0:00:00 - 0  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 15:27:48 - 0:00:00 - 1  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 15:27:48 - 0:00:00 - build training dataset (start)
INFO - 12/16/22 15:27:57 - 0:00:09 - build training dataset (end)
INFO - 12/16/22 15:27:57 - 0:00:09 - build validation dataset (start)
INFO - 12/16/22 15:27:57 - 0:00:09 - build validation dataset (end)
INFO - 12/16/22 15:27:57 - 0:00:09 - Building data done
INFO - 12/16/22 15:27:58 - 0:00:10 - Load pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['module.projection_head.0.weight', 'module.projection_head.0.bias', 'module.projection_head.1.weight', 'module.projection_head.1.bias', 'module.projection_head.1.running_mean', 'module.projection_head.1.running_var', 'module.projection_head.1.num_batches_tracked', 'module.projection_head.3.weight', 'module.projection_head.3.bias', 'module.prototypes.weight'])
INFO - 12/16/22 15:27:58 - 0:00:10 - ============ Starting epoch 0 ... ============
INFO - 12/16/22 15:29:21 - 0:00:00 - ============ Initialized logger ============
INFO - 12/16/22 15:29:21 - 0:00:00 - arch: resnet50
                                     batch_size: 64
                                     data_path: C:\Users\chris\Downloads\ILSVRC\Data\CLS-LOC
                                     decay_epochs: [60, 80]
                                     dist_url: env://
                                     dump_checkpoints: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model\checkpoints
                                     dump_path: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     epochs: 100
                                     final_lr: 0
                                     gamma: 0.1
                                     global_pooling: True
                                     gpu_to_work_on: 0
                                     is_slurm_job: False
                                     local_rank: 0
                                     lr: 0.3
                                     nesterov: False
                                     pretrained: D:\code_cluster\me_swav\pretrained\swav_800ep_pretrain.pth.tar
                                     rank: 0
                                     scheduler_type: cosine
                                     seed: 31
                                     use_bn: False
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 12/16/22 15:29:21 - 0:00:00 - The experiment will be stored in D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     

INFO - 12/16/22 15:29:21 - 0:00:00 - 0  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 15:29:21 - 0:00:00 - 1  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 15:29:21 - 0:00:00 - build training dataset (start)
INFO - 12/16/22 15:29:30 - 0:00:09 - build training dataset (end)
INFO - 12/16/22 15:29:30 - 0:00:09 - build validation dataset (start)
INFO - 12/16/22 15:29:31 - 0:00:09 - build validation dataset (end)
INFO - 12/16/22 15:29:31 - 0:00:09 - Building data done
INFO - 12/16/22 15:29:31 - 0:00:10 - Load pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['module.projection_head.0.weight', 'module.projection_head.0.bias', 'module.projection_head.1.weight', 'module.projection_head.1.bias', 'module.projection_head.1.running_mean', 'module.projection_head.1.running_var', 'module.projection_head.1.num_batches_tracked', 'module.projection_head.3.weight', 'module.projection_head.3.bias', 'module.prototypes.weight'])
INFO - 12/16/22 15:29:31 - 0:00:10 - ============ Starting epoch 0 ... ============
INFO - 12/16/22 15:33:29 - 0:00:00 - ============ Initialized logger ============
INFO - 12/16/22 15:33:29 - 0:00:00 - arch: resnet50
                                     batch_size: 64
                                     data_path: C:\Users\chris\Downloads\ILSVRC\Data\CLS-LOC
                                     decay_epochs: [60, 80]
                                     dist_url: env://
                                     dump_checkpoints: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model\checkpoints
                                     dump_path: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     epochs: 100
                                     final_lr: 0
                                     gamma: 0.1
                                     global_pooling: True
                                     gpu_to_work_on: 0
                                     is_slurm_job: False
                                     local_rank: 0
                                     lr: 0.3
                                     nesterov: False
                                     pretrained: D:\code_cluster\me_swav\pretrained\swav_800ep_pretrain.pth.tar
                                     rank: 0
                                     scheduler_type: cosine
                                     seed: 31
                                     use_bn: False
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 12/16/22 15:33:29 - 0:00:00 - The experiment will be stored in D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     

INFO - 12/16/22 15:33:29 - 0:00:00 - 0  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 15:33:29 - 0:00:00 - 1  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 15:33:29 - 0:00:00 - build training dataset (start)
INFO - 12/16/22 15:33:38 - 0:00:09 - build training dataset (end)
INFO - 12/16/22 15:33:38 - 0:00:09 - build validation dataset (start)
INFO - 12/16/22 15:33:38 - 0:00:10 - build validation dataset (end)
INFO - 12/16/22 15:33:38 - 0:00:10 - Building data done
INFO - 12/16/22 15:33:39 - 0:00:11 - Load pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['module.projection_head.0.weight', 'module.projection_head.0.bias', 'module.projection_head.1.weight', 'module.projection_head.1.bias', 'module.projection_head.1.running_mean', 'module.projection_head.1.running_var', 'module.projection_head.1.num_batches_tracked', 'module.projection_head.3.weight', 'module.projection_head.3.bias', 'module.prototypes.weight'])
INFO - 12/16/22 15:33:39 - 0:00:11 - ============ Starting epoch 0 ... ============
INFO - 12/16/22 15:37:35 - 0:00:00 - ============ Initialized logger ============
INFO - 12/16/22 15:37:35 - 0:00:00 - arch: resnet50
                                     batch_size: 64
                                     data_path: C:\Users\chris\Downloads\ILSVRC\Data\CLS-LOC
                                     decay_epochs: [60, 80]
                                     dist_url: env://
                                     dump_checkpoints: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model\checkpoints
                                     dump_path: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     epochs: 100
                                     final_lr: 0
                                     gamma: 0.1
                                     global_pooling: True
                                     gpu_to_work_on: 0
                                     is_slurm_job: False
                                     local_rank: 0
                                     lr: 0.3
                                     nesterov: False
                                     pretrained: D:\code_cluster\me_swav\pretrained\swav_800ep_pretrain.pth.tar
                                     rank: 0
                                     scheduler_type: cosine
                                     seed: 31
                                     use_bn: False
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 12/16/22 15:37:35 - 0:00:00 - The experiment will be stored in D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     

INFO - 12/16/22 15:37:35 - 0:00:00 - 0  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 15:37:35 - 0:00:00 - 1  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 15:37:35 - 0:00:00 - build training dataset (start)
INFO - 12/16/22 15:37:44 - 0:00:09 - build training dataset (end)
INFO - 12/16/22 15:37:44 - 0:00:09 - build validation dataset (start)
INFO - 12/16/22 15:37:44 - 0:00:09 - build validation dataset (end)
INFO - 12/16/22 15:37:44 - 0:00:09 - Building data done
INFO - 12/16/22 15:37:45 - 0:00:10 - Load pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['module.projection_head.0.weight', 'module.projection_head.0.bias', 'module.projection_head.1.weight', 'module.projection_head.1.bias', 'module.projection_head.1.running_mean', 'module.projection_head.1.running_var', 'module.projection_head.1.num_batches_tracked', 'module.projection_head.3.weight', 'module.projection_head.3.bias', 'module.prototypes.weight'])
INFO - 12/16/22 15:37:45 - 0:00:10 - ============ Starting epoch 0 ... ============
INFO - 12/16/22 15:58:15 - 0:00:00 - ============ Initialized logger ============
INFO - 12/16/22 15:58:15 - 0:00:00 - arch: resnet50
                                     batch_size: 64
                                     data_path: C:\Users\chris\Downloads\ILSVRC\Data\CLS-LOC
                                     decay_epochs: [60, 80]
                                     dist_url: env://
                                     dump_checkpoints: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model\checkpoints
                                     dump_path: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     epochs: 100
                                     final_lr: 0
                                     gamma: 0.1
                                     global_pooling: True
                                     gpu_to_work_on: 0
                                     is_slurm_job: False
                                     local_rank: 0
                                     lr: 0.3
                                     nesterov: False
                                     pretrained: D:\code_cluster\me_swav\pretrained\swav_800ep_pretrain.pth.tar
                                     rank: 0
                                     scheduler_type: cosine
                                     seed: 31
                                     use_bn: False
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 12/16/22 15:58:15 - 0:00:00 - The experiment will be stored in D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     

INFO - 12/16/22 15:58:15 - 0:00:00 - 0  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 15:58:15 - 0:00:00 - 1  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 15:58:15 - 0:00:00 - build training dataset (start)
INFO - 12/16/22 15:58:24 - 0:00:09 - build training dataset (end)
INFO - 12/16/22 15:58:24 - 0:00:09 - build validation dataset (start)
INFO - 12/16/22 15:58:24 - 0:00:09 - build validation dataset (end)
INFO - 12/16/22 15:58:24 - 0:00:09 - Building data done
INFO - 12/16/22 15:58:25 - 0:00:10 - Load pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['module.projection_head.0.weight', 'module.projection_head.0.bias', 'module.projection_head.1.weight', 'module.projection_head.1.bias', 'module.projection_head.1.running_mean', 'module.projection_head.1.running_var', 'module.projection_head.1.num_batches_tracked', 'module.projection_head.3.weight', 'module.projection_head.3.bias', 'module.prototypes.weight'])
INFO - 12/16/22 15:58:25 - 0:00:10 - ============ Starting epoch 0 ... ============
INFO - 12/16/22 15:59:39 - 0:00:00 - ============ Initialized logger ============
INFO - 12/16/22 15:59:39 - 0:00:00 - arch: resnet50
                                     batch_size: 64
                                     data_path: C:\Users\chris\Downloads\ILSVRC\Data\CLS-LOC
                                     decay_epochs: [60, 80]
                                     dist_url: env://
                                     dump_checkpoints: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model\checkpoints
                                     dump_path: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     epochs: 100
                                     final_lr: 0
                                     gamma: 0.1
                                     global_pooling: True
                                     gpu_to_work_on: 0
                                     is_slurm_job: False
                                     local_rank: 0
                                     lr: 0.3
                                     nesterov: False
                                     pretrained: D:\code_cluster\me_swav\pretrained\swav_800ep_pretrain.pth.tar
                                     rank: 0
                                     scheduler_type: cosine
                                     seed: 31
                                     use_bn: False
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 12/16/22 15:59:39 - 0:00:00 - The experiment will be stored in D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     

INFO - 12/16/22 15:59:39 - 0:00:00 - 0  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 15:59:39 - 0:00:00 - 1  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 15:59:39 - 0:00:00 - build training dataset (start)
INFO - 12/16/22 15:59:48 - 0:00:09 - build training dataset (end)
INFO - 12/16/22 15:59:48 - 0:00:09 - build validation dataset (start)
INFO - 12/16/22 15:59:48 - 0:00:09 - build validation dataset (end)
INFO - 12/16/22 15:59:48 - 0:00:09 - Building data done
INFO - 12/16/22 15:59:49 - 0:00:10 - Load pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['module.projection_head.0.weight', 'module.projection_head.0.bias', 'module.projection_head.1.weight', 'module.projection_head.1.bias', 'module.projection_head.1.running_mean', 'module.projection_head.1.running_var', 'module.projection_head.1.num_batches_tracked', 'module.projection_head.3.weight', 'module.projection_head.3.bias', 'module.prototypes.weight'])
INFO - 12/16/22 15:59:49 - 0:00:10 - ============ Starting epoch 0 ... ============
INFO - 12/16/22 16:01:32 - 0:00:00 - ============ Initialized logger ============
INFO - 12/16/22 16:01:32 - 0:00:00 - arch: resnet50
                                     batch_size: 64
                                     data_path: C:\Users\chris\Downloads\ILSVRC\Data\CLS-LOC
                                     decay_epochs: [60, 80]
                                     dist_url: env://
                                     dump_checkpoints: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model\checkpoints
                                     dump_path: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     epochs: 100
                                     final_lr: 0
                                     gamma: 0.1
                                     global_pooling: True
                                     gpu_to_work_on: 0
                                     is_slurm_job: False
                                     local_rank: 0
                                     lr: 0.3
                                     nesterov: False
                                     pretrained: D:\code_cluster\me_swav\pretrained\swav_800ep_pretrain.pth.tar
                                     rank: 0
                                     scheduler_type: cosine
                                     seed: 31
                                     use_bn: False
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 12/16/22 16:01:32 - 0:00:00 - The experiment will be stored in D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     

INFO - 12/16/22 16:01:32 - 0:00:00 - 0  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 16:01:32 - 0:00:00 - 1  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 16:01:32 - 0:00:00 - build training dataset (start)
INFO - 12/16/22 16:01:41 - 0:00:09 - build training dataset (end)
INFO - 12/16/22 16:01:41 - 0:00:09 - build validation dataset (start)
INFO - 12/16/22 16:01:41 - 0:00:09 - build validation dataset (end)
INFO - 12/16/22 16:01:41 - 0:00:09 - Building data done
INFO - 12/16/22 16:01:42 - 0:00:10 - Load pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['module.projection_head.0.weight', 'module.projection_head.0.bias', 'module.projection_head.1.weight', 'module.projection_head.1.bias', 'module.projection_head.1.running_mean', 'module.projection_head.1.running_var', 'module.projection_head.1.num_batches_tracked', 'module.projection_head.3.weight', 'module.projection_head.3.bias', 'module.prototypes.weight'])
INFO - 12/16/22 16:01:42 - 0:00:10 - ============ Starting epoch 0 ... ============
INFO - 12/16/22 16:05:19 - 0:00:00 - ============ Initialized logger ============
INFO - 12/16/22 16:05:19 - 0:00:00 - arch: resnet50
                                     batch_size: 64
                                     data_path: C:\Users\chris\Downloads\ILSVRC\Data\CLS-LOC
                                     decay_epochs: [60, 80]
                                     dist_url: env://
                                     dump_checkpoints: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model\checkpoints
                                     dump_path: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     epochs: 100
                                     final_lr: 0
                                     gamma: 0.1
                                     global_pooling: True
                                     gpu_to_work_on: 0
                                     is_slurm_job: False
                                     local_rank: 0
                                     lr: 0.3
                                     nesterov: False
                                     pretrained: D:\code_cluster\me_swav\pretrained\swav_800ep_pretrain.pth.tar
                                     rank: 0
                                     scheduler_type: cosine
                                     seed: 31
                                     use_bn: False
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 12/16/22 16:05:19 - 0:00:00 - The experiment will be stored in D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     

INFO - 12/16/22 16:05:19 - 0:00:00 - 0  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 16:05:19 - 0:00:00 - 1  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 16:05:19 - 0:00:00 - build training dataset (start)
INFO - 12/16/22 16:05:29 - 0:00:09 - build training dataset (end)
INFO - 12/16/22 16:05:29 - 0:00:09 - build validation dataset (start)
INFO - 12/16/22 16:05:29 - 0:00:10 - build validation dataset (end)
INFO - 12/16/22 16:05:29 - 0:00:10 - Building data done
INFO - 12/16/22 16:05:30 - 0:00:11 - Load pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['module.projection_head.0.weight', 'module.projection_head.0.bias', 'module.projection_head.1.weight', 'module.projection_head.1.bias', 'module.projection_head.1.running_mean', 'module.projection_head.1.running_var', 'module.projection_head.1.num_batches_tracked', 'module.projection_head.3.weight', 'module.projection_head.3.bias', 'module.prototypes.weight'])
INFO - 12/16/22 16:05:30 - 0:00:11 - ============ Starting epoch 0 ... ============
INFO - 12/16/22 16:06:25 - 0:01:05 - Model's state_dict:
INFO - 12/16/22 16:06:25 - 0:01:05 - module.conv1.weight	torch.Size([64, 3, 7, 7])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.bn1.weight	torch.Size([64])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.bn1.bias	torch.Size([64])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.bn1.running_mean	torch.Size([64])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.bn1.running_var	torch.Size([64])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.0.conv1.weight	torch.Size([64, 64, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.0.bn1.weight	torch.Size([64])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.0.bn1.bias	torch.Size([64])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.0.bn1.running_mean	torch.Size([64])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.0.bn1.running_var	torch.Size([64])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.0.conv2.weight	torch.Size([64, 64, 3, 3])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.0.bn2.weight	torch.Size([64])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.0.bn2.bias	torch.Size([64])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.0.bn2.running_mean	torch.Size([64])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.0.bn2.running_var	torch.Size([64])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.0.conv3.weight	torch.Size([256, 64, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.0.bn3.weight	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.0.bn3.bias	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.0.bn3.running_mean	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.0.bn3.running_var	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.0.downsample.0.weight	torch.Size([256, 64, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.0.downsample.1.weight	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.0.downsample.1.bias	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.0.downsample.1.running_mean	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.0.downsample.1.running_var	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.1.conv1.weight	torch.Size([64, 256, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.1.bn1.weight	torch.Size([64])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.1.bn1.bias	torch.Size([64])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.1.bn1.running_mean	torch.Size([64])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.1.bn1.running_var	torch.Size([64])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.1.conv2.weight	torch.Size([64, 64, 3, 3])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.1.bn2.weight	torch.Size([64])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.1.bn2.bias	torch.Size([64])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.1.bn2.running_mean	torch.Size([64])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.1.bn2.running_var	torch.Size([64])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.1.conv3.weight	torch.Size([256, 64, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.1.bn3.weight	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.1.bn3.bias	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.1.bn3.running_mean	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.1.bn3.running_var	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.2.conv1.weight	torch.Size([64, 256, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.2.bn1.weight	torch.Size([64])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.2.bn1.bias	torch.Size([64])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.2.bn1.running_mean	torch.Size([64])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.2.bn1.running_var	torch.Size([64])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.2.conv2.weight	torch.Size([64, 64, 3, 3])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.2.bn2.weight	torch.Size([64])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.2.bn2.bias	torch.Size([64])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.2.bn2.running_mean	torch.Size([64])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.2.bn2.running_var	torch.Size([64])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.2.conv3.weight	torch.Size([256, 64, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.2.bn3.weight	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.2.bn3.bias	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.2.bn3.running_mean	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.2.bn3.running_var	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer1.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.0.conv1.weight	torch.Size([128, 256, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.0.bn1.weight	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.0.bn1.bias	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.0.bn1.running_mean	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.0.bn1.running_var	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.0.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.0.bn2.weight	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.0.bn2.bias	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.0.bn2.running_mean	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.0.bn2.running_var	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.0.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.0.bn3.weight	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.0.bn3.bias	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.0.bn3.running_mean	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.0.bn3.running_var	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.0.downsample.0.weight	torch.Size([512, 256, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.0.downsample.1.weight	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.0.downsample.1.bias	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.0.downsample.1.running_mean	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.0.downsample.1.running_var	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.1.conv1.weight	torch.Size([128, 512, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.1.bn1.weight	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.1.bn1.bias	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.1.bn1.running_mean	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.1.bn1.running_var	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.1.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.1.bn2.weight	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.1.bn2.bias	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.1.bn2.running_mean	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.1.bn2.running_var	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.1.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.1.bn3.weight	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.1.bn3.bias	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.1.bn3.running_mean	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.1.bn3.running_var	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.2.conv1.weight	torch.Size([128, 512, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.2.bn1.weight	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.2.bn1.bias	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.2.bn1.running_mean	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.2.bn1.running_var	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.2.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.2.bn2.weight	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.2.bn2.bias	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.2.bn2.running_mean	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.2.bn2.running_var	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.2.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.2.bn3.weight	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.2.bn3.bias	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.2.bn3.running_mean	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.2.bn3.running_var	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.3.conv1.weight	torch.Size([128, 512, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.3.bn1.weight	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.3.bn1.bias	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.3.bn1.running_mean	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.3.bn1.running_var	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.3.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.3.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.3.bn2.weight	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.3.bn2.bias	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.3.bn2.running_mean	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.3.bn2.running_var	torch.Size([128])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.3.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.3.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.3.bn3.weight	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.3.bn3.bias	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.3.bn3.running_mean	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.3.bn3.running_var	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer2.3.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer3.0.conv1.weight	torch.Size([256, 512, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer3.0.bn1.weight	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer3.0.bn1.bias	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer3.0.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer3.0.bn1.running_var	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer3.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:05 - module.layer3.0.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.0.bn2.weight	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.0.bn2.bias	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.0.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.0.bn2.running_var	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.0.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.0.bn3.weight	torch.Size([1024])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.0.bn3.bias	torch.Size([1024])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.0.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.0.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.0.downsample.0.weight	torch.Size([1024, 512, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.0.downsample.1.weight	torch.Size([1024])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.0.downsample.1.bias	torch.Size([1024])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.0.downsample.1.running_mean	torch.Size([1024])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.0.downsample.1.running_var	torch.Size([1024])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.1.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.1.bn1.weight	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.1.bn1.bias	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.1.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.1.bn1.running_var	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.1.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.1.bn2.weight	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.1.bn2.bias	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.1.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.1.bn2.running_var	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.1.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.1.bn3.weight	torch.Size([1024])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.1.bn3.bias	torch.Size([1024])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.1.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.1.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.2.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.2.bn1.weight	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.2.bn1.bias	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.2.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.2.bn1.running_var	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.2.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.2.bn2.weight	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.2.bn2.bias	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.2.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.2.bn2.running_var	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.2.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.2.bn3.weight	torch.Size([1024])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.2.bn3.bias	torch.Size([1024])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.2.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.2.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.3.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.3.bn1.weight	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.3.bn1.bias	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.3.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.3.bn1.running_var	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.3.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.3.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.3.bn2.weight	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.3.bn2.bias	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.3.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.3.bn2.running_var	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.3.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.3.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.3.bn3.weight	torch.Size([1024])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.3.bn3.bias	torch.Size([1024])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.3.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.3.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.3.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.4.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.4.bn1.weight	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.4.bn1.bias	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.4.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.4.bn1.running_var	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.4.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.4.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.4.bn2.weight	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.4.bn2.bias	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.4.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.4.bn2.running_var	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.4.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.4.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.4.bn3.weight	torch.Size([1024])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.4.bn3.bias	torch.Size([1024])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.4.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.4.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.4.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.5.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.5.bn1.weight	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.5.bn1.bias	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.5.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.5.bn1.running_var	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.5.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.5.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.5.bn2.weight	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.5.bn2.bias	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.5.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.5.bn2.running_var	torch.Size([256])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.5.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.5.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.5.bn3.weight	torch.Size([1024])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.5.bn3.bias	torch.Size([1024])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.5.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.5.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer3.5.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.0.conv1.weight	torch.Size([512, 1024, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.0.bn1.weight	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.0.bn1.bias	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.0.bn1.running_mean	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.0.bn1.running_var	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.0.conv2.weight	torch.Size([512, 512, 3, 3])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.0.bn2.weight	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.0.bn2.bias	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.0.bn2.running_mean	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.0.bn2.running_var	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.0.conv3.weight	torch.Size([2048, 512, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.0.bn3.weight	torch.Size([2048])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.0.bn3.bias	torch.Size([2048])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.0.bn3.running_mean	torch.Size([2048])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.0.bn3.running_var	torch.Size([2048])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.0.downsample.0.weight	torch.Size([2048, 1024, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.0.downsample.1.weight	torch.Size([2048])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.0.downsample.1.bias	torch.Size([2048])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.0.downsample.1.running_mean	torch.Size([2048])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.0.downsample.1.running_var	torch.Size([2048])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.1.conv1.weight	torch.Size([512, 2048, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.1.bn1.weight	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.1.bn1.bias	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.1.bn1.running_mean	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.1.bn1.running_var	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.1.conv2.weight	torch.Size([512, 512, 3, 3])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.1.bn2.weight	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.1.bn2.bias	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.1.bn2.running_mean	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.1.bn2.running_var	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.1.conv3.weight	torch.Size([2048, 512, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.1.bn3.weight	torch.Size([2048])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.1.bn3.bias	torch.Size([2048])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.1.bn3.running_mean	torch.Size([2048])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.1.bn3.running_var	torch.Size([2048])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.2.conv1.weight	torch.Size([512, 2048, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.2.bn1.weight	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.2.bn1.bias	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.2.bn1.running_mean	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.2.bn1.running_var	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.2.conv2.weight	torch.Size([512, 512, 3, 3])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.2.bn2.weight	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.2.bn2.bias	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.2.bn2.running_mean	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.2.bn2.running_var	torch.Size([512])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.2.conv3.weight	torch.Size([2048, 512, 1, 1])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.2.bn3.weight	torch.Size([2048])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.2.bn3.bias	torch.Size([2048])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.2.bn3.running_mean	torch.Size([2048])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.2.bn3.running_var	torch.Size([2048])
INFO - 12/16/22 16:06:25 - 0:01:06 - module.layer4.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:06:25 - 0:01:06 - info.model:
INFO - 12/16/22 16:06:25 - 0:01:06 - DataParallel(
                                       (module): ResNet(
                                         (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)
                                         (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)
                                         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         (relu): ReLU(inplace=True)
                                         (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
                                         (layer1): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (layer2): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                               (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (3): Bottleneck(
                                             (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (layer3): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                               (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (3): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (4): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (5): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (layer4): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                               (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       )
                                     )
INFO - 12/16/22 16:06:29 - 0:01:09 - RegLog's state_dict:
INFO - 12/16/22 16:06:29 - 0:01:09 - module.module.linear.weight	torch.Size([1000, 2048])
INFO - 12/16/22 16:06:29 - 0:01:09 - module.module.linear.bias	torch.Size([1000])
INFO - 12/16/22 16:06:29 - 0:01:09 - info.reglog:
INFO - 12/16/22 16:06:29 - 0:01:09 - DistributedDataParallel(
                                       (module): DataParallel(
                                         (module): RegLog(
                                           (av_pool): AdaptiveAvgPool2d(output_size=(1, 1))
                                           (linear): Linear(in_features=2048, out_features=1000, bias=True)
                                         )
                                       )
                                     )
INFO - 12/16/22 16:06:29 - 0:01:09 - Epoch[0] - Iter: [0/20019]	Time 58.506 (58.506)	Data 24.988 (24.988)	Loss 6.9162 (6.9162)	Prec 0.000 (0.000)	LR 0.3
INFO - 12/16/22 16:08:42 - 0:00:00 - ============ Initialized logger ============
INFO - 12/16/22 16:08:42 - 0:00:00 - arch: resnet50
                                     batch_size: 64
                                     data_path: C:\Users\chris\Downloads\ILSVRC\Data\CLS-LOC
                                     decay_epochs: [60, 80]
                                     dist_url: env://
                                     dump_checkpoints: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model\checkpoints
                                     dump_path: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     epochs: 100
                                     final_lr: 0
                                     gamma: 0.1
                                     global_pooling: True
                                     gpu_to_work_on: 0
                                     is_slurm_job: False
                                     local_rank: 0
                                     lr: 0.3
                                     nesterov: False
                                     pretrained: D:\code_cluster\me_swav\pretrained\swav_800ep_pretrain.pth.tar
                                     rank: 0
                                     scheduler_type: cosine
                                     seed: 31
                                     use_bn: False
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 12/16/22 16:08:42 - 0:00:00 - The experiment will be stored in D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     

INFO - 12/16/22 16:08:42 - 0:00:00 - 0  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 16:08:42 - 0:00:00 - 1  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 16:08:42 - 0:00:00 - build training dataset (start)
INFO - 12/16/22 16:08:51 - 0:00:09 - build training dataset (end)
INFO - 12/16/22 16:08:51 - 0:00:09 - build validation dataset (start)
INFO - 12/16/22 16:08:51 - 0:00:09 - build validation dataset (end)
INFO - 12/16/22 16:08:51 - 0:00:09 - Building data done
INFO - 12/16/22 16:08:52 - 0:00:10 - Load pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['module.projection_head.0.weight', 'module.projection_head.0.bias', 'module.projection_head.1.weight', 'module.projection_head.1.bias', 'module.projection_head.1.running_mean', 'module.projection_head.1.running_var', 'module.projection_head.1.num_batches_tracked', 'module.projection_head.3.weight', 'module.projection_head.3.bias', 'module.prototypes.weight'])
INFO - 12/16/22 16:08:52 - 0:00:10 - ============ Starting epoch 0 ... ============
INFO - 12/16/22 16:09:34 - 0:00:52 - gpu0 processes: GPU:0
                                     process       8496 uses        0.000 MB GPU memory
                                     process       7700 uses        0.000 MB GPU memory
                                     process       5400 uses        0.000 MB GPU memory
INFO - 12/16/22 16:09:36 - 0:00:54 - gpu1 processes: GPU:1
                                     process       8496 uses        0.000 MB GPU memory
                                     process       7700 uses        0.000 MB GPU memory
                                     process       5400 uses        0.000 MB GPU memory
INFO - 12/16/22 16:33:44 - 0:00:00 - ============ Initialized logger ============
INFO - 12/16/22 16:33:44 - 0:00:00 - arch: resnet50
                                     batch_size: 64
                                     data_path: C:\Users\chris\Downloads\ILSVRC\Data\CLS-LOC
                                     decay_epochs: [60, 80]
                                     dist_url: env://
                                     dump_checkpoints: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model\checkpoints
                                     dump_path: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     epochs: 100
                                     final_lr: 0
                                     gamma: 0.1
                                     global_pooling: True
                                     gpu_to_work_on: 0
                                     is_slurm_job: False
                                     local_rank: 0
                                     lr: 0.3
                                     nesterov: False
                                     pretrained: D:\code_cluster\me_swav\pretrained\swav_800ep_pretrain.pth.tar
                                     rank: 0
                                     scheduler_type: cosine
                                     seed: 31
                                     use_bn: False
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 12/16/22 16:33:44 - 0:00:00 - The experiment will be stored in D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     

INFO - 12/16/22 16:33:44 - 0:00:00 - 0  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 16:33:44 - 0:00:00 - 1  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 16:33:44 - 0:00:00 - build training dataset (start)
INFO - 12/16/22 16:33:53 - 0:00:09 - build training dataset (end)
INFO - 12/16/22 16:33:53 - 0:00:09 - build validation dataset (start)
INFO - 12/16/22 16:33:53 - 0:00:10 - build validation dataset (end)
INFO - 12/16/22 16:33:53 - 0:00:10 - Building data done
INFO - 12/16/22 16:33:54 - 0:00:10 - Load pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['module.projection_head.0.weight', 'module.projection_head.0.bias', 'module.projection_head.1.weight', 'module.projection_head.1.bias', 'module.projection_head.1.running_mean', 'module.projection_head.1.running_var', 'module.projection_head.1.num_batches_tracked', 'module.projection_head.3.weight', 'module.projection_head.3.bias', 'module.prototypes.weight'])
INFO - 12/16/22 16:33:54 - 0:00:10 - ============ Starting epoch 0 ... ============
INFO - 12/16/22 16:35:07 - 0:01:23 - Model's state_dict:
INFO - 12/16/22 16:35:07 - 0:01:23 - module.conv1.weight	torch.Size([64, 3, 7, 7])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.bn1.weight	torch.Size([64])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.bn1.bias	torch.Size([64])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.bn1.running_mean	torch.Size([64])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.bn1.running_var	torch.Size([64])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.0.conv1.weight	torch.Size([64, 64, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.0.bn1.weight	torch.Size([64])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.0.bn1.bias	torch.Size([64])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.0.bn1.running_mean	torch.Size([64])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.0.bn1.running_var	torch.Size([64])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.0.conv2.weight	torch.Size([64, 64, 3, 3])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.0.bn2.weight	torch.Size([64])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.0.bn2.bias	torch.Size([64])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.0.bn2.running_mean	torch.Size([64])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.0.bn2.running_var	torch.Size([64])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.0.conv3.weight	torch.Size([256, 64, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.0.bn3.weight	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.0.bn3.bias	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.0.bn3.running_mean	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.0.bn3.running_var	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.0.downsample.0.weight	torch.Size([256, 64, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.0.downsample.1.weight	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.0.downsample.1.bias	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.0.downsample.1.running_mean	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.0.downsample.1.running_var	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.1.conv1.weight	torch.Size([64, 256, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.1.bn1.weight	torch.Size([64])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.1.bn1.bias	torch.Size([64])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.1.bn1.running_mean	torch.Size([64])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.1.bn1.running_var	torch.Size([64])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.1.conv2.weight	torch.Size([64, 64, 3, 3])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.1.bn2.weight	torch.Size([64])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.1.bn2.bias	torch.Size([64])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.1.bn2.running_mean	torch.Size([64])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.1.bn2.running_var	torch.Size([64])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.1.conv3.weight	torch.Size([256, 64, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.1.bn3.weight	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.1.bn3.bias	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.1.bn3.running_mean	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.1.bn3.running_var	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.2.conv1.weight	torch.Size([64, 256, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.2.bn1.weight	torch.Size([64])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.2.bn1.bias	torch.Size([64])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.2.bn1.running_mean	torch.Size([64])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.2.bn1.running_var	torch.Size([64])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.2.conv2.weight	torch.Size([64, 64, 3, 3])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.2.bn2.weight	torch.Size([64])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.2.bn2.bias	torch.Size([64])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.2.bn2.running_mean	torch.Size([64])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.2.bn2.running_var	torch.Size([64])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.2.conv3.weight	torch.Size([256, 64, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.2.bn3.weight	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.2.bn3.bias	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.2.bn3.running_mean	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.2.bn3.running_var	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer1.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.0.conv1.weight	torch.Size([128, 256, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.0.bn1.weight	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.0.bn1.bias	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.0.bn1.running_mean	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.0.bn1.running_var	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.0.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.0.bn2.weight	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.0.bn2.bias	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.0.bn2.running_mean	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.0.bn2.running_var	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.0.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.0.bn3.weight	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.0.bn3.bias	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.0.bn3.running_mean	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.0.bn3.running_var	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.0.downsample.0.weight	torch.Size([512, 256, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.0.downsample.1.weight	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.0.downsample.1.bias	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.0.downsample.1.running_mean	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.0.downsample.1.running_var	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.1.conv1.weight	torch.Size([128, 512, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.1.bn1.weight	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.1.bn1.bias	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.1.bn1.running_mean	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.1.bn1.running_var	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.1.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.1.bn2.weight	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.1.bn2.bias	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.1.bn2.running_mean	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.1.bn2.running_var	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.1.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.1.bn3.weight	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.1.bn3.bias	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.1.bn3.running_mean	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.1.bn3.running_var	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.2.conv1.weight	torch.Size([128, 512, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.2.bn1.weight	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.2.bn1.bias	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.2.bn1.running_mean	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.2.bn1.running_var	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.2.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.2.bn2.weight	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.2.bn2.bias	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.2.bn2.running_mean	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.2.bn2.running_var	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.2.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.2.bn3.weight	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.2.bn3.bias	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.2.bn3.running_mean	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.2.bn3.running_var	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.3.conv1.weight	torch.Size([128, 512, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.3.bn1.weight	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.3.bn1.bias	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.3.bn1.running_mean	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.3.bn1.running_var	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.3.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.3.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.3.bn2.weight	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.3.bn2.bias	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.3.bn2.running_mean	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.3.bn2.running_var	torch.Size([128])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.3.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.3.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.3.bn3.weight	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.3.bn3.bias	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.3.bn3.running_mean	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.3.bn3.running_var	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer2.3.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.0.conv1.weight	torch.Size([256, 512, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.0.bn1.weight	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.0.bn1.bias	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.0.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.0.bn1.running_var	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.0.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.0.bn2.weight	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.0.bn2.bias	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.0.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.0.bn2.running_var	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.0.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.0.bn3.weight	torch.Size([1024])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.0.bn3.bias	torch.Size([1024])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.0.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.0.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.0.downsample.0.weight	torch.Size([1024, 512, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.0.downsample.1.weight	torch.Size([1024])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.0.downsample.1.bias	torch.Size([1024])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.0.downsample.1.running_mean	torch.Size([1024])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.0.downsample.1.running_var	torch.Size([1024])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.1.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.1.bn1.weight	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.1.bn1.bias	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.1.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.1.bn1.running_var	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.1.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.1.bn2.weight	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.1.bn2.bias	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.1.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.1.bn2.running_var	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.1.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.1.bn3.weight	torch.Size([1024])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.1.bn3.bias	torch.Size([1024])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.1.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.1.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.2.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.2.bn1.weight	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.2.bn1.bias	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.2.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.2.bn1.running_var	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.2.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.2.bn2.weight	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.2.bn2.bias	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.2.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.2.bn2.running_var	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.2.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.2.bn3.weight	torch.Size([1024])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.2.bn3.bias	torch.Size([1024])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.2.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.2.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.3.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.3.bn1.weight	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.3.bn1.bias	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.3.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.3.bn1.running_var	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.3.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.3.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.3.bn2.weight	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.3.bn2.bias	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.3.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.3.bn2.running_var	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.3.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.3.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.3.bn3.weight	torch.Size([1024])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.3.bn3.bias	torch.Size([1024])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.3.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.3.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.3.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.4.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.4.bn1.weight	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.4.bn1.bias	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.4.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.4.bn1.running_var	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.4.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.4.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.4.bn2.weight	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.4.bn2.bias	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.4.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.4.bn2.running_var	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.4.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.4.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.4.bn3.weight	torch.Size([1024])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.4.bn3.bias	torch.Size([1024])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.4.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.4.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.4.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.5.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.5.bn1.weight	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.5.bn1.bias	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.5.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.5.bn1.running_var	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.5.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.5.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.5.bn2.weight	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.5.bn2.bias	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.5.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.5.bn2.running_var	torch.Size([256])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.5.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.5.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.5.bn3.weight	torch.Size([1024])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.5.bn3.bias	torch.Size([1024])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.5.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.5.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer3.5.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.0.conv1.weight	torch.Size([512, 1024, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.0.bn1.weight	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.0.bn1.bias	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.0.bn1.running_mean	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.0.bn1.running_var	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.0.conv2.weight	torch.Size([512, 512, 3, 3])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.0.bn2.weight	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.0.bn2.bias	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.0.bn2.running_mean	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.0.bn2.running_var	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.0.conv3.weight	torch.Size([2048, 512, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.0.bn3.weight	torch.Size([2048])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.0.bn3.bias	torch.Size([2048])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.0.bn3.running_mean	torch.Size([2048])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.0.bn3.running_var	torch.Size([2048])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.0.downsample.0.weight	torch.Size([2048, 1024, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.0.downsample.1.weight	torch.Size([2048])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.0.downsample.1.bias	torch.Size([2048])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.0.downsample.1.running_mean	torch.Size([2048])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.0.downsample.1.running_var	torch.Size([2048])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.1.conv1.weight	torch.Size([512, 2048, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.1.bn1.weight	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.1.bn1.bias	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.1.bn1.running_mean	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.1.bn1.running_var	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.1.conv2.weight	torch.Size([512, 512, 3, 3])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.1.bn2.weight	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.1.bn2.bias	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.1.bn2.running_mean	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.1.bn2.running_var	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.1.conv3.weight	torch.Size([2048, 512, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.1.bn3.weight	torch.Size([2048])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.1.bn3.bias	torch.Size([2048])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.1.bn3.running_mean	torch.Size([2048])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.1.bn3.running_var	torch.Size([2048])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.2.conv1.weight	torch.Size([512, 2048, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.2.bn1.weight	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.2.bn1.bias	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.2.bn1.running_mean	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.2.bn1.running_var	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.2.conv2.weight	torch.Size([512, 512, 3, 3])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.2.bn2.weight	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.2.bn2.bias	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.2.bn2.running_mean	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.2.bn2.running_var	torch.Size([512])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.2.conv3.weight	torch.Size([2048, 512, 1, 1])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.2.bn3.weight	torch.Size([2048])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.2.bn3.bias	torch.Size([2048])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.2.bn3.running_mean	torch.Size([2048])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.2.bn3.running_var	torch.Size([2048])
INFO - 12/16/22 16:35:07 - 0:01:23 - module.layer4.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:35:07 - 0:01:23 - info.model:
INFO - 12/16/22 16:35:07 - 0:01:23 - DataParallel(
                                       (module): ResNet(
                                         (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)
                                         (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)
                                         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         (relu): ReLU(inplace=True)
                                         (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
                                         (layer1): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (layer2): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                               (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (3): Bottleneck(
                                             (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (layer3): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                               (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (3): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (4): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (5): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (layer4): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                               (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       )
                                     )
INFO - 12/16/22 16:35:16 - 0:01:32 - gpu0 processes: GPU:0
                                     process       5020 uses        0.000 MB GPU memory
                                     process       7700 uses        0.000 MB GPU memory
                                     process       5400 uses        0.000 MB GPU memory
INFO - 12/16/22 16:35:18 - 0:01:35 - gpu1 processes: GPU:1
                                     process       5020 uses        0.000 MB GPU memory
                                     process       7700 uses        0.000 MB GPU memory
                                     process       5400 uses        0.000 MB GPU memory
INFO - 12/16/22 16:35:44 - 0:00:00 - ============ Initialized logger ============
INFO - 12/16/22 16:35:44 - 0:00:00 - arch: resnet50
                                     batch_size: 64
                                     data_path: C:\Users\chris\Downloads\ILSVRC\Data\CLS-LOC
                                     decay_epochs: [60, 80]
                                     dist_url: env://
                                     dump_checkpoints: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model\checkpoints
                                     dump_path: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     epochs: 100
                                     final_lr: 0
                                     gamma: 0.1
                                     global_pooling: True
                                     gpu_to_work_on: 0
                                     is_slurm_job: False
                                     local_rank: 0
                                     lr: 0.3
                                     nesterov: False
                                     pretrained: D:\code_cluster\me_swav\pretrained\swav_800ep_pretrain.pth.tar
                                     rank: 0
                                     scheduler_type: cosine
                                     seed: 31
                                     use_bn: False
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 12/16/22 16:35:44 - 0:00:00 - The experiment will be stored in D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     

INFO - 12/16/22 16:35:44 - 0:00:00 - 0  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 16:35:44 - 0:00:00 - 1  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 16:35:44 - 0:00:00 - build training dataset (start)
INFO - 12/16/22 16:35:53 - 0:00:09 - build training dataset (end)
INFO - 12/16/22 16:35:53 - 0:00:09 - build validation dataset (start)
INFO - 12/16/22 16:35:53 - 0:00:09 - build validation dataset (end)
INFO - 12/16/22 16:35:53 - 0:00:09 - Building data done
INFO - 12/16/22 16:35:54 - 0:00:10 - Load pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['module.projection_head.0.weight', 'module.projection_head.0.bias', 'module.projection_head.1.weight', 'module.projection_head.1.bias', 'module.projection_head.1.running_mean', 'module.projection_head.1.running_var', 'module.projection_head.1.num_batches_tracked', 'module.projection_head.3.weight', 'module.projection_head.3.bias', 'module.prototypes.weight'])
INFO - 12/16/22 16:35:54 - 0:00:10 - ============ Starting epoch 0 ... ============
INFO - 12/16/22 16:36:19 - 0:00:35 - Model's state_dict:
INFO - 12/16/22 16:36:19 - 0:00:35 - module.conv1.weight	torch.Size([64, 3, 7, 7])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.bn1.weight	torch.Size([64])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.bn1.bias	torch.Size([64])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.bn1.running_mean	torch.Size([64])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.bn1.running_var	torch.Size([64])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.0.conv1.weight	torch.Size([64, 64, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.0.bn1.weight	torch.Size([64])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.0.bn1.bias	torch.Size([64])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.0.bn1.running_mean	torch.Size([64])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.0.bn1.running_var	torch.Size([64])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.0.conv2.weight	torch.Size([64, 64, 3, 3])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.0.bn2.weight	torch.Size([64])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.0.bn2.bias	torch.Size([64])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.0.bn2.running_mean	torch.Size([64])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.0.bn2.running_var	torch.Size([64])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.0.conv3.weight	torch.Size([256, 64, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.0.bn3.weight	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.0.bn3.bias	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.0.bn3.running_mean	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.0.bn3.running_var	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.0.downsample.0.weight	torch.Size([256, 64, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.0.downsample.1.weight	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.0.downsample.1.bias	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.0.downsample.1.running_mean	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.0.downsample.1.running_var	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.1.conv1.weight	torch.Size([64, 256, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.1.bn1.weight	torch.Size([64])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.1.bn1.bias	torch.Size([64])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.1.bn1.running_mean	torch.Size([64])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.1.bn1.running_var	torch.Size([64])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.1.conv2.weight	torch.Size([64, 64, 3, 3])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.1.bn2.weight	torch.Size([64])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.1.bn2.bias	torch.Size([64])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.1.bn2.running_mean	torch.Size([64])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.1.bn2.running_var	torch.Size([64])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.1.conv3.weight	torch.Size([256, 64, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.1.bn3.weight	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.1.bn3.bias	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.1.bn3.running_mean	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.1.bn3.running_var	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.2.conv1.weight	torch.Size([64, 256, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.2.bn1.weight	torch.Size([64])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.2.bn1.bias	torch.Size([64])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.2.bn1.running_mean	torch.Size([64])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.2.bn1.running_var	torch.Size([64])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.2.conv2.weight	torch.Size([64, 64, 3, 3])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.2.bn2.weight	torch.Size([64])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.2.bn2.bias	torch.Size([64])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.2.bn2.running_mean	torch.Size([64])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.2.bn2.running_var	torch.Size([64])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.2.conv3.weight	torch.Size([256, 64, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.2.bn3.weight	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.2.bn3.bias	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.2.bn3.running_mean	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.2.bn3.running_var	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer1.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.0.conv1.weight	torch.Size([128, 256, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.0.bn1.weight	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.0.bn1.bias	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.0.bn1.running_mean	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.0.bn1.running_var	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.0.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.0.bn2.weight	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.0.bn2.bias	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.0.bn2.running_mean	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.0.bn2.running_var	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.0.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.0.bn3.weight	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.0.bn3.bias	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.0.bn3.running_mean	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.0.bn3.running_var	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.0.downsample.0.weight	torch.Size([512, 256, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.0.downsample.1.weight	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.0.downsample.1.bias	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.0.downsample.1.running_mean	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.0.downsample.1.running_var	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.1.conv1.weight	torch.Size([128, 512, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.1.bn1.weight	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.1.bn1.bias	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.1.bn1.running_mean	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.1.bn1.running_var	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.1.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.1.bn2.weight	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.1.bn2.bias	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.1.bn2.running_mean	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.1.bn2.running_var	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.1.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.1.bn3.weight	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.1.bn3.bias	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.1.bn3.running_mean	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.1.bn3.running_var	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.2.conv1.weight	torch.Size([128, 512, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.2.bn1.weight	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.2.bn1.bias	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.2.bn1.running_mean	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.2.bn1.running_var	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.2.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.2.bn2.weight	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.2.bn2.bias	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.2.bn2.running_mean	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.2.bn2.running_var	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.2.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.2.bn3.weight	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.2.bn3.bias	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.2.bn3.running_mean	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.2.bn3.running_var	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:35 - module.layer2.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer2.3.conv1.weight	torch.Size([128, 512, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer2.3.bn1.weight	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer2.3.bn1.bias	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer2.3.bn1.running_mean	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer2.3.bn1.running_var	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer2.3.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer2.3.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer2.3.bn2.weight	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer2.3.bn2.bias	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer2.3.bn2.running_mean	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer2.3.bn2.running_var	torch.Size([128])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer2.3.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer2.3.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer2.3.bn3.weight	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer2.3.bn3.bias	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer2.3.bn3.running_mean	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer2.3.bn3.running_var	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer2.3.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.0.conv1.weight	torch.Size([256, 512, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.0.bn1.weight	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.0.bn1.bias	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.0.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.0.bn1.running_var	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.0.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.0.bn2.weight	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.0.bn2.bias	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.0.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.0.bn2.running_var	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.0.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.0.bn3.weight	torch.Size([1024])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.0.bn3.bias	torch.Size([1024])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.0.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.0.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.0.downsample.0.weight	torch.Size([1024, 512, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.0.downsample.1.weight	torch.Size([1024])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.0.downsample.1.bias	torch.Size([1024])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.0.downsample.1.running_mean	torch.Size([1024])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.0.downsample.1.running_var	torch.Size([1024])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.1.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.1.bn1.weight	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.1.bn1.bias	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.1.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.1.bn1.running_var	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.1.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.1.bn2.weight	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.1.bn2.bias	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.1.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.1.bn2.running_var	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.1.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.1.bn3.weight	torch.Size([1024])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.1.bn3.bias	torch.Size([1024])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.1.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.1.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.2.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.2.bn1.weight	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.2.bn1.bias	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.2.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.2.bn1.running_var	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.2.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.2.bn2.weight	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.2.bn2.bias	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.2.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.2.bn2.running_var	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.2.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.2.bn3.weight	torch.Size([1024])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.2.bn3.bias	torch.Size([1024])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.2.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.2.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.3.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.3.bn1.weight	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.3.bn1.bias	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.3.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.3.bn1.running_var	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.3.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.3.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.3.bn2.weight	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.3.bn2.bias	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.3.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.3.bn2.running_var	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.3.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.3.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.3.bn3.weight	torch.Size([1024])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.3.bn3.bias	torch.Size([1024])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.3.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.3.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.3.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.4.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.4.bn1.weight	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.4.bn1.bias	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.4.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.4.bn1.running_var	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.4.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.4.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.4.bn2.weight	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.4.bn2.bias	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.4.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.4.bn2.running_var	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.4.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.4.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.4.bn3.weight	torch.Size([1024])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.4.bn3.bias	torch.Size([1024])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.4.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.4.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.4.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.5.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.5.bn1.weight	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.5.bn1.bias	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.5.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.5.bn1.running_var	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.5.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.5.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.5.bn2.weight	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.5.bn2.bias	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.5.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.5.bn2.running_var	torch.Size([256])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.5.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.5.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.5.bn3.weight	torch.Size([1024])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.5.bn3.bias	torch.Size([1024])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.5.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.5.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer3.5.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.0.conv1.weight	torch.Size([512, 1024, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.0.bn1.weight	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.0.bn1.bias	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.0.bn1.running_mean	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.0.bn1.running_var	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.0.conv2.weight	torch.Size([512, 512, 3, 3])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.0.bn2.weight	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.0.bn2.bias	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.0.bn2.running_mean	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.0.bn2.running_var	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.0.conv3.weight	torch.Size([2048, 512, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.0.bn3.weight	torch.Size([2048])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.0.bn3.bias	torch.Size([2048])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.0.bn3.running_mean	torch.Size([2048])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.0.bn3.running_var	torch.Size([2048])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.0.downsample.0.weight	torch.Size([2048, 1024, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.0.downsample.1.weight	torch.Size([2048])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.0.downsample.1.bias	torch.Size([2048])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.0.downsample.1.running_mean	torch.Size([2048])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.0.downsample.1.running_var	torch.Size([2048])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.1.conv1.weight	torch.Size([512, 2048, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.1.bn1.weight	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.1.bn1.bias	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.1.bn1.running_mean	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.1.bn1.running_var	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.1.conv2.weight	torch.Size([512, 512, 3, 3])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.1.bn2.weight	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.1.bn2.bias	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.1.bn2.running_mean	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.1.bn2.running_var	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.1.conv3.weight	torch.Size([2048, 512, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.1.bn3.weight	torch.Size([2048])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.1.bn3.bias	torch.Size([2048])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.1.bn3.running_mean	torch.Size([2048])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.1.bn3.running_var	torch.Size([2048])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.2.conv1.weight	torch.Size([512, 2048, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.2.bn1.weight	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.2.bn1.bias	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.2.bn1.running_mean	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.2.bn1.running_var	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.2.conv2.weight	torch.Size([512, 512, 3, 3])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.2.bn2.weight	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.2.bn2.bias	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.2.bn2.running_mean	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.2.bn2.running_var	torch.Size([512])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.2.conv3.weight	torch.Size([2048, 512, 1, 1])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.2.bn3.weight	torch.Size([2048])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.2.bn3.bias	torch.Size([2048])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.2.bn3.running_mean	torch.Size([2048])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.2.bn3.running_var	torch.Size([2048])
INFO - 12/16/22 16:36:19 - 0:00:36 - module.layer4.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:36:19 - 0:00:36 - info.model:
INFO - 12/16/22 16:36:19 - 0:00:36 - DataParallel(
                                       (module): ResNet(
                                         (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)
                                         (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)
                                         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         (relu): ReLU(inplace=True)
                                         (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
                                         (layer1): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (layer2): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                               (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (3): Bottleneck(
                                             (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (layer3): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                               (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (3): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (4): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (5): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (layer4): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                               (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       )
                                     )
INFO - 12/16/22 16:36:33 - 0:00:49 - gpu0 processes: GPU:0
                                     process       5892 uses        0.000 MB GPU memory
                                     process       7700 uses        0.000 MB GPU memory
                                     process       5892 uses        0.000 MB GPU memory
                                     process       5400 uses        0.000 MB GPU memory
INFO - 12/16/22 16:36:36 - 0:00:53 - gpu1 processes: GPU:1
                                     process       5892 uses        0.000 MB GPU memory
                                     process       7700 uses        0.000 MB GPU memory
                                     process       5892 uses        0.000 MB GPU memory
                                     process       5400 uses        0.000 MB GPU memory
INFO - 12/16/22 16:42:49 - 0:00:00 - ============ Initialized logger ============
INFO - 12/16/22 16:42:49 - 0:00:00 - arch: resnet50
                                     batch_size: 64
                                     data_path: C:\Users\chris\Downloads\ILSVRC\Data\CLS-LOC
                                     decay_epochs: [60, 80]
                                     dist_url: env://
                                     dump_checkpoints: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model\checkpoints
                                     dump_path: D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     epochs: 100
                                     final_lr: 0
                                     gamma: 0.1
                                     global_pooling: True
                                     gpu_to_work_on: 0
                                     is_slurm_job: False
                                     local_rank: 0
                                     lr: 0.3
                                     nesterov: False
                                     pretrained: D:\code_cluster\me_swav\pretrained\swav_800ep_pretrain.pth.tar
                                     rank: 0
                                     scheduler_type: cosine
                                     seed: 31
                                     use_bn: False
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 12/16/22 16:42:49 - 0:00:00 - The experiment will be stored in D:\code_cluster\me_swav\facebook_swav\experiments\015a_eval_lin_model
                                     

INFO - 12/16/22 16:42:49 - 0:00:00 - 0  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 16:42:49 - 0:00:00 - 1  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/16/22 16:42:49 - 0:00:00 - build training dataset (start)
INFO - 12/16/22 16:42:58 - 0:00:09 - build training dataset (end)
INFO - 12/16/22 16:42:58 - 0:00:09 - build validation dataset (start)
INFO - 12/16/22 16:42:59 - 0:00:10 - build validation dataset (end)
INFO - 12/16/22 16:42:59 - 0:00:10 - Building data done
INFO - 12/16/22 16:43:00 - 0:00:11 - Load pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['module.projection_head.0.weight', 'module.projection_head.0.bias', 'module.projection_head.1.weight', 'module.projection_head.1.bias', 'module.projection_head.1.running_mean', 'module.projection_head.1.running_var', 'module.projection_head.1.num_batches_tracked', 'module.projection_head.3.weight', 'module.projection_head.3.bias', 'module.prototypes.weight'])
INFO - 12/16/22 16:43:00 - 0:00:11 - ============ Starting epoch 0 ... ============
INFO - 12/16/22 16:43:24 - 0:00:35 - Model's state_dict:
INFO - 12/16/22 16:43:24 - 0:00:35 - module.conv1.weight	torch.Size([64, 3, 7, 7])
INFO - 12/16/22 16:43:24 - 0:00:35 - module.bn1.weight	torch.Size([64])
INFO - 12/16/22 16:43:24 - 0:00:35 - module.bn1.bias	torch.Size([64])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.bn1.running_mean	torch.Size([64])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.bn1.running_var	torch.Size([64])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.layer1.0.conv1.weight	torch.Size([64, 64, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.layer1.0.bn1.weight	torch.Size([64])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.layer1.0.bn1.bias	torch.Size([64])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.layer1.0.bn1.running_mean	torch.Size([64])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.layer1.0.bn1.running_var	torch.Size([64])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.layer1.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.layer1.0.conv2.weight	torch.Size([64, 64, 3, 3])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.layer1.0.bn2.weight	torch.Size([64])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.layer1.0.bn2.bias	torch.Size([64])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.layer1.0.bn2.running_mean	torch.Size([64])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.layer1.0.bn2.running_var	torch.Size([64])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.layer1.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.layer1.0.conv3.weight	torch.Size([256, 64, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.layer1.0.bn3.weight	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.layer1.0.bn3.bias	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.layer1.0.bn3.running_mean	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.layer1.0.bn3.running_var	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.layer1.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.layer1.0.downsample.0.weight	torch.Size([256, 64, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.layer1.0.downsample.1.weight	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.layer1.0.downsample.1.bias	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.layer1.0.downsample.1.running_mean	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.layer1.0.downsample.1.running_var	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.layer1.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.layer1.1.conv1.weight	torch.Size([64, 256, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.layer1.1.bn1.weight	torch.Size([64])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.layer1.1.bn1.bias	torch.Size([64])
INFO - 12/16/22 16:43:25 - 0:00:35 - module.layer1.1.bn1.running_mean	torch.Size([64])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.1.bn1.running_var	torch.Size([64])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.1.conv2.weight	torch.Size([64, 64, 3, 3])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.1.bn2.weight	torch.Size([64])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.1.bn2.bias	torch.Size([64])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.1.bn2.running_mean	torch.Size([64])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.1.bn2.running_var	torch.Size([64])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.1.conv3.weight	torch.Size([256, 64, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.1.bn3.weight	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.1.bn3.bias	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.1.bn3.running_mean	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.1.bn3.running_var	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.2.conv1.weight	torch.Size([64, 256, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.2.bn1.weight	torch.Size([64])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.2.bn1.bias	torch.Size([64])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.2.bn1.running_mean	torch.Size([64])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.2.bn1.running_var	torch.Size([64])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.2.conv2.weight	torch.Size([64, 64, 3, 3])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.2.bn2.weight	torch.Size([64])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.2.bn2.bias	torch.Size([64])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.2.bn2.running_mean	torch.Size([64])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.2.bn2.running_var	torch.Size([64])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.2.conv3.weight	torch.Size([256, 64, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.2.bn3.weight	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.2.bn3.bias	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.2.bn3.running_mean	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.2.bn3.running_var	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer1.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.0.conv1.weight	torch.Size([128, 256, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.0.bn1.weight	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.0.bn1.bias	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.0.bn1.running_mean	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.0.bn1.running_var	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.0.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.0.bn2.weight	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.0.bn2.bias	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.0.bn2.running_mean	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.0.bn2.running_var	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.0.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.0.bn3.weight	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.0.bn3.bias	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.0.bn3.running_mean	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.0.bn3.running_var	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.0.downsample.0.weight	torch.Size([512, 256, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.0.downsample.1.weight	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.0.downsample.1.bias	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.0.downsample.1.running_mean	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.0.downsample.1.running_var	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.1.conv1.weight	torch.Size([128, 512, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.1.bn1.weight	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.1.bn1.bias	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.1.bn1.running_mean	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.1.bn1.running_var	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.1.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.1.bn2.weight	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.1.bn2.bias	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.1.bn2.running_mean	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.1.bn2.running_var	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.1.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.1.bn3.weight	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.1.bn3.bias	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.1.bn3.running_mean	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.1.bn3.running_var	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.2.conv1.weight	torch.Size([128, 512, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.2.bn1.weight	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.2.bn1.bias	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.2.bn1.running_mean	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.2.bn1.running_var	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.2.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.2.bn2.weight	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.2.bn2.bias	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.2.bn2.running_mean	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.2.bn2.running_var	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.2.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.2.bn3.weight	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.2.bn3.bias	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.2.bn3.running_mean	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.2.bn3.running_var	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.3.conv1.weight	torch.Size([128, 512, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.3.bn1.weight	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.3.bn1.bias	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.3.bn1.running_mean	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.3.bn1.running_var	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.3.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.3.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.3.bn2.weight	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.3.bn2.bias	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.3.bn2.running_mean	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.3.bn2.running_var	torch.Size([128])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.3.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.3.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.3.bn3.weight	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.3.bn3.bias	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.3.bn3.running_mean	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.3.bn3.running_var	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer2.3.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.0.conv1.weight	torch.Size([256, 512, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.0.bn1.weight	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.0.bn1.bias	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.0.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.0.bn1.running_var	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.0.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.0.bn2.weight	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.0.bn2.bias	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.0.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.0.bn2.running_var	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.0.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.0.bn3.weight	torch.Size([1024])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.0.bn3.bias	torch.Size([1024])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.0.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.0.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.0.downsample.0.weight	torch.Size([1024, 512, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.0.downsample.1.weight	torch.Size([1024])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.0.downsample.1.bias	torch.Size([1024])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.0.downsample.1.running_mean	torch.Size([1024])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.0.downsample.1.running_var	torch.Size([1024])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.1.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.1.bn1.weight	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.1.bn1.bias	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.1.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.1.bn1.running_var	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.1.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.1.bn2.weight	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.1.bn2.bias	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.1.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.1.bn2.running_var	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.1.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.1.bn3.weight	torch.Size([1024])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.1.bn3.bias	torch.Size([1024])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.1.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.1.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.2.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.2.bn1.weight	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.2.bn1.bias	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.2.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.2.bn1.running_var	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.2.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.2.bn2.weight	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.2.bn2.bias	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.2.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.2.bn2.running_var	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.2.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.2.bn3.weight	torch.Size([1024])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.2.bn3.bias	torch.Size([1024])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.2.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.2.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.3.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.3.bn1.weight	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.3.bn1.bias	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.3.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.3.bn1.running_var	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.3.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.3.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.3.bn2.weight	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.3.bn2.bias	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.3.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.3.bn2.running_var	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.3.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.3.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.3.bn3.weight	torch.Size([1024])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.3.bn3.bias	torch.Size([1024])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.3.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.3.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.3.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.4.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.4.bn1.weight	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.4.bn1.bias	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.4.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.4.bn1.running_var	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.4.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.4.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.4.bn2.weight	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.4.bn2.bias	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.4.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.4.bn2.running_var	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.4.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.4.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.4.bn3.weight	torch.Size([1024])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.4.bn3.bias	torch.Size([1024])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.4.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.4.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.4.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.5.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.5.bn1.weight	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.5.bn1.bias	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.5.bn1.running_mean	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.5.bn1.running_var	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.5.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.5.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.5.bn2.weight	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.5.bn2.bias	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.5.bn2.running_mean	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.5.bn2.running_var	torch.Size([256])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.5.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.5.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.5.bn3.weight	torch.Size([1024])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.5.bn3.bias	torch.Size([1024])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.5.bn3.running_mean	torch.Size([1024])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.5.bn3.running_var	torch.Size([1024])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer3.5.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.0.conv1.weight	torch.Size([512, 1024, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.0.bn1.weight	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.0.bn1.bias	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.0.bn1.running_mean	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.0.bn1.running_var	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.0.conv2.weight	torch.Size([512, 512, 3, 3])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.0.bn2.weight	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.0.bn2.bias	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.0.bn2.running_mean	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.0.bn2.running_var	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.0.conv3.weight	torch.Size([2048, 512, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.0.bn3.weight	torch.Size([2048])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.0.bn3.bias	torch.Size([2048])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.0.bn3.running_mean	torch.Size([2048])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.0.bn3.running_var	torch.Size([2048])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.0.downsample.0.weight	torch.Size([2048, 1024, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.0.downsample.1.weight	torch.Size([2048])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.0.downsample.1.bias	torch.Size([2048])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.0.downsample.1.running_mean	torch.Size([2048])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.0.downsample.1.running_var	torch.Size([2048])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.1.conv1.weight	torch.Size([512, 2048, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.1.bn1.weight	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.1.bn1.bias	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.1.bn1.running_mean	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.1.bn1.running_var	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.1.conv2.weight	torch.Size([512, 512, 3, 3])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.1.bn2.weight	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.1.bn2.bias	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.1.bn2.running_mean	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.1.bn2.running_var	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.1.conv3.weight	torch.Size([2048, 512, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.1.bn3.weight	torch.Size([2048])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.1.bn3.bias	torch.Size([2048])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.1.bn3.running_mean	torch.Size([2048])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.1.bn3.running_var	torch.Size([2048])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.2.conv1.weight	torch.Size([512, 2048, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.2.bn1.weight	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.2.bn1.bias	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.2.bn1.running_mean	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.2.bn1.running_var	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.2.conv2.weight	torch.Size([512, 512, 3, 3])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.2.bn2.weight	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.2.bn2.bias	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.2.bn2.running_mean	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.2.bn2.running_var	torch.Size([512])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.2.conv3.weight	torch.Size([2048, 512, 1, 1])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.2.bn3.weight	torch.Size([2048])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.2.bn3.bias	torch.Size([2048])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.2.bn3.running_mean	torch.Size([2048])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.2.bn3.running_var	torch.Size([2048])
INFO - 12/16/22 16:43:25 - 0:00:36 - module.layer4.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/16/22 16:43:25 - 0:00:36 - info.model:
INFO - 12/16/22 16:43:25 - 0:00:36 - DataParallel(
                                       (module): ResNet(
                                         (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)
                                         (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)
                                         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         (relu): ReLU(inplace=True)
                                         (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
                                         (layer1): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (layer2): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                               (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (3): Bottleneck(
                                             (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (layer3): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                               (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (3): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (4): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (5): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (layer4): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                               (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       )
                                     )
INFO - 12/16/22 16:43:37 - 0:00:48 - gpu0 processes: GPU:0
                                     process       5380 uses        0.000 MB GPU memory
                                     process       7700 uses        0.000 MB GPU memory
                                     process       5380 uses        0.000 MB GPU memory
                                     process       5400 uses        0.000 MB GPU memory
INFO - 12/16/22 16:43:37 - 0:00:48 - gpu1 processes: GPU:1
                                     process       5380 uses        0.000 MB GPU memory
                                     process       7700 uses        0.000 MB GPU memory
                                     process       5380 uses        0.000 MB GPU memory
                                     process       5400 uses        0.000 MB GPU memory
INFO - 12/16/22 16:43:37 - 0:00:48 - mem_summary: |===========================================================================|
                                     |                  PyTorch CUDA memory summary, device ID 0                 |
                                     |---------------------------------------------------------------------------|
                                     |            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
                                     |===========================================================================|
                                     |        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
                                     |---------------------------------------------------------------------------|
                                     | Allocated memory      |  260051 KB |    2763 MB |   22097 MB |   21843 MB |
                                     |       from large pool |  222812 KB |    2727 MB |   22058 MB |   21840 MB |
                                     |       from small pool |   37239 KB |      36 MB |      38 MB |       2 MB |
                                     |---------------------------------------------------------------------------|
                                     | Active memory         |  260051 KB |    2763 MB |   22097 MB |   21843 MB |
                                     |       from large pool |  222812 KB |    2727 MB |   22058 MB |   21840 MB |
                                     |       from small pool |   37239 KB |      36 MB |      38 MB |       2 MB |
                                     |---------------------------------------------------------------------------|
                                     | GPU reserved memory   |  378880 KB |    3958 MB |   10366 MB |    9996 MB |
                                     |       from large pool |  339968 KB |    3922 MB |   10322 MB |    9990 MB |
                                     |       from small pool |   38912 KB |      38 MB |      44 MB |       6 MB |
                                     |---------------------------------------------------------------------------|
                                     | Non-releasable memory |   18477 KB |    2471 MB |   24725 MB |   24707 MB |
                                     |       from large pool |   16804 KB |    2471 MB |   24693 MB |   24677 MB |
                                     |       from small pool |    1673 KB |       2 MB |      32 MB |      30 MB |
                                     |---------------------------------------------------------------------------|
                                     | Allocations           |     655    |     666    |    1008    |     353    |
                                     |       from large pool |      39    |      45    |     221    |     182    |
                                     |       from small pool |     616    |     627    |     787    |     171    |
                                     |---------------------------------------------------------------------------|
                                     | Active allocs         |     655    |     666    |    1008    |     353    |
                                     |       from large pool |      39    |      45    |     221    |     182    |
                                     |       from small pool |     616    |     627    |     787    |     171    |
                                     |---------------------------------------------------------------------------|
                                     | GPU reserved segments |      31    |      36    |      49    |      18    |
                                     |       from large pool |      12    |      17    |      27    |      15    |
                                     |       from small pool |      19    |      19    |      22    |       3    |
                                     |---------------------------------------------------------------------------|
                                     | Non-releasable allocs |       8    |      12    |     142    |     134    |
                                     |       from large pool |       5    |      11    |      89    |      84    |
                                     |       from small pool |       3    |       5    |      53    |      50    |
                                     |---------------------------------------------------------------------------|
                                     | Oversize allocations  |       0    |       0    |       0    |       0    |
                                     |---------------------------------------------------------------------------|
                                     | Oversize GPU segments |       0    |       0    |       0    |       0    |
                                     |===========================================================================|
                                     
INFO - 12/16/22 16:43:37 - 0:00:48 - RegLog's state_dict:
INFO - 12/16/22 16:43:37 - 0:00:48 - module.module.linear.weight	torch.Size([1000, 2048])
INFO - 12/16/22 16:43:37 - 0:00:48 - module.module.linear.bias	torch.Size([1000])
INFO - 12/16/22 16:43:37 - 0:00:48 - info.reglog:
INFO - 12/16/22 16:43:37 - 0:00:48 - DistributedDataParallel(
                                       (module): DataParallel(
                                         (module): RegLog(
                                           (av_pool): AdaptiveAvgPool2d(output_size=(1, 1))
                                           (linear): Linear(in_features=2048, out_features=1000, bias=True)
                                         )
                                       )
                                     )
INFO - 12/16/22 16:43:37 - 0:00:48 - Epoch[0] - Iter: [0/20019]	Time 37.456 (37.456)	Data 24.829 (24.829)	Loss 6.9162 (6.9162)	Prec 0.000 (0.000)	LR 0.3
INFO - 12/16/22 16:43:42 - 0:00:53 - Epoch[0] - Iter: [50/20019]	Time 0.103 (0.836)	Data 0.000 (0.487)	Loss 6.4493 (6.8031)	Prec 6.250 (2.543)	LR 0.3
INFO - 12/16/22 16:43:47 - 0:00:58 - Epoch[0] - Iter: [100/20019]	Time 0.103 (0.474)	Data 0.000 (0.246)	Loss 5.6339 (6.4539)	Prec 20.312 (6.173)	LR 0.3
INFO - 12/16/22 16:43:53 - 0:01:04 - Epoch[0] - Iter: [150/20019]	Time 0.103 (0.352)	Data 0.000 (0.165)	Loss 4.8819 (6.1156)	Prec 26.562 (9.261)	LR 0.3
INFO - 12/16/22 16:43:58 - 0:01:09 - Epoch[0] - Iter: [200/20019]	Time 0.104 (0.290)	Data 0.000 (0.124)	Loss 4.7676 (5.8090)	Prec 20.312 (12.158)	LR 0.3
INFO - 12/16/22 16:44:03 - 0:01:14 - Epoch[0] - Iter: [250/20019]	Time 0.106 (0.253)	Data 0.000 (0.099)	Loss 4.1126 (5.5299)	Prec 28.125 (14.909)	LR 0.3
INFO - 12/16/22 16:44:08 - 0:01:19 - Epoch[0] - Iter: [300/20019]	Time 0.103 (0.228)	Data 0.000 (0.083)	Loss 4.0759 (5.2811)	Prec 32.812 (17.302)	LR 0.3
INFO - 12/16/22 16:44:14 - 0:01:25 - Epoch[0] - Iter: [350/20019]	Time 0.102 (0.211)	Data 0.000 (0.071)	Loss 3.6167 (5.0645)	Prec 29.688 (19.667)	LR 0.3
INFO - 12/16/22 16:44:19 - 0:01:30 - Epoch[0] - Iter: [400/20019]	Time 0.103 (0.198)	Data 0.000 (0.062)	Loss 3.2717 (4.8664)	Prec 45.312 (21.774)	LR 0.3
INFO - 12/16/22 16:44:24 - 0:01:35 - Epoch[0] - Iter: [450/20019]	Time 0.103 (0.187)	Data 0.000 (0.055)	Loss 3.2688 (4.6905)	Prec 37.500 (23.787)	LR 0.3
INFO - 12/16/22 16:44:29 - 0:01:40 - Epoch[0] - Iter: [500/20019]	Time 0.103 (0.179)	Data 0.000 (0.050)	Loss 2.5444 (4.5337)	Prec 51.562 (25.533)	LR 0.3
INFO - 12/16/22 16:44:35 - 0:01:46 - Epoch[0] - Iter: [550/20019]	Time 0.104 (0.172)	Data 0.000 (0.045)	Loss 2.6958 (4.4020)	Prec 46.875 (27.005)	LR 0.3
INFO - 12/16/22 16:44:40 - 0:01:51 - Epoch[0] - Iter: [600/20019]	Time 0.106 (0.167)	Data 0.000 (0.042)	Loss 3.1438 (4.2776)	Prec 39.062 (28.403)	LR 0.3
INFO - 12/16/22 16:44:45 - 0:01:56 - Epoch[0] - Iter: [650/20019]	Time 0.107 (0.162)	Data 0.000 (0.038)	Loss 2.4970 (4.1686)	Prec 51.562 (29.714)	LR 0.3
INFO - 12/16/22 16:44:51 - 0:02:01 - Epoch[0] - Iter: [700/20019]	Time 0.105 (0.158)	Data 0.000 (0.036)	Loss 2.8147 (4.0676)	Prec 48.438 (30.824)	LR 0.3
INFO - 12/16/22 16:44:56 - 0:02:07 - Epoch[0] - Iter: [750/20019]	Time 0.107 (0.155)	Data 0.000 (0.033)	Loss 2.3889 (3.9763)	Prec 48.438 (31.889)	LR 0.3
INFO - 12/16/22 16:45:01 - 0:02:12 - Epoch[0] - Iter: [800/20019]	Time 0.107 (0.152)	Data 0.000 (0.031)	Loss 2.8674 (3.8925)	Prec 39.062 (32.828)	LR 0.3
INFO - 12/16/22 16:45:06 - 0:02:17 - Epoch[0] - Iter: [850/20019]	Time 0.103 (0.149)	Data 0.000 (0.029)	Loss 2.7196 (3.8198)	Prec 43.750 (33.648)	LR 0.3
INFO - 12/16/22 16:45:12 - 0:02:23 - Epoch[0] - Iter: [900/20019]	Time 0.105 (0.146)	Data 0.000 (0.028)	Loss 2.7172 (3.7496)	Prec 46.875 (34.427)	LR 0.3
INFO - 12/16/22 16:45:17 - 0:02:28 - Epoch[0] - Iter: [950/20019]	Time 0.106 (0.144)	Data 0.000 (0.026)	Loss 2.3441 (3.6841)	Prec 48.438 (35.238)	LR 0.3
INFO - 12/16/22 16:45:22 - 0:02:33 - Epoch[0] - Iter: [1000/20019]	Time 0.105 (0.142)	Data 0.000 (0.025)	Loss 2.4546 (3.6229)	Prec 46.875 (35.895)	LR 0.3
INFO - 12/16/22 16:45:28 - 0:02:39 - Epoch[0] - Iter: [1050/20019]	Time 0.106 (0.141)	Data 0.000 (0.024)	Loss 2.3963 (3.5660)	Prec 53.125 (36.609)	LR 0.3
INFO - 12/16/22 16:45:33 - 0:02:44 - Epoch[0] - Iter: [1100/20019]	Time 0.108 (0.139)	Data 0.000 (0.023)	Loss 2.5513 (3.5109)	Prec 46.875 (37.212)	LR 0.3
INFO - 12/16/22 16:45:38 - 0:02:49 - Epoch[0] - Iter: [1150/20019]	Time 0.105 (0.138)	Data 0.000 (0.022)	Loss 2.4410 (3.4649)	Prec 46.875 (37.750)	LR 0.3
INFO - 12/16/22 16:45:44 - 0:02:55 - Epoch[0] - Iter: [1200/20019]	Time 0.107 (0.136)	Data 0.000 (0.021)	Loss 2.3747 (3.4189)	Prec 43.750 (38.268)	LR 0.3
INFO - 12/16/22 16:45:49 - 0:03:00 - Epoch[0] - Iter: [1250/20019]	Time 0.107 (0.135)	Data 0.000 (0.020)	Loss 2.1022 (3.3760)	Prec 56.250 (38.783)	LR 0.3
INFO - 12/16/22 16:45:54 - 0:03:05 - Epoch[0] - Iter: [1300/20019]	Time 0.106 (0.134)	Data 0.000 (0.019)	Loss 2.0688 (3.3335)	Prec 51.562 (39.289)	LR 0.3
INFO - 12/16/22 16:46:00 - 0:03:11 - Epoch[0] - Iter: [1350/20019]	Time 0.109 (0.133)	Data 0.000 (0.019)	Loss 1.9608 (3.2936)	Prec 56.250 (39.795)	LR 0.3
INFO - 12/16/22 16:46:05 - 0:03:16 - Epoch[0] - Iter: [1400/20019]	Time 0.105 (0.132)	Data 0.000 (0.018)	Loss 2.2488 (3.2564)	Prec 48.438 (40.220)	LR 0.3
INFO - 12/16/22 16:46:10 - 0:03:21 - Epoch[0] - Iter: [1450/20019]	Time 0.107 (0.131)	Data 0.000 (0.017)	Loss 2.4462 (3.2187)	Prec 56.250 (40.692)	LR 0.3
INFO - 12/16/22 16:46:16 - 0:03:27 - Epoch[0] - Iter: [1500/20019]	Time 0.107 (0.131)	Data 0.000 (0.017)	Loss 1.7531 (3.1844)	Prec 67.188 (41.114)	LR 0.3
INFO - 12/16/22 16:46:21 - 0:03:32 - Epoch[0] - Iter: [1550/20019]	Time 0.107 (0.130)	Data 0.000 (0.016)	Loss 2.2067 (3.1531)	Prec 45.312 (41.467)	LR 0.3
INFO - 12/16/22 16:46:26 - 0:03:37 - Epoch[0] - Iter: [1600/20019]	Time 0.113 (0.129)	Data 0.000 (0.016)	Loss 2.5841 (3.1224)	Prec 51.562 (41.859)	LR 0.3
INFO - 12/16/22 16:46:32 - 0:03:43 - Epoch[0] - Iter: [1650/20019]	Time 0.106 (0.128)	Data 0.000 (0.015)	Loss 1.8762 (3.0949)	Prec 57.812 (42.171)	LR 0.3
INFO - 12/16/22 16:46:37 - 0:03:48 - Epoch[0] - Iter: [1700/20019]	Time 0.108 (0.128)	Data 0.000 (0.015)	Loss 2.1623 (3.0673)	Prec 53.125 (42.539)	LR 0.3
INFO - 12/16/22 16:46:43 - 0:03:53 - Epoch[0] - Iter: [1750/20019]	Time 0.105 (0.127)	Data 0.000 (0.014)	Loss 2.1601 (3.0397)	Prec 53.125 (42.897)	LR 0.3
INFO - 12/16/22 16:46:48 - 0:03:59 - Epoch[0] - Iter: [1800/20019]	Time 0.106 (0.127)	Data 0.000 (0.014)	Loss 2.6903 (3.0144)	Prec 40.625 (43.209)	LR 0.3
INFO - 12/16/22 16:46:53 - 0:04:04 - Epoch[0] - Iter: [1850/20019]	Time 0.106 (0.126)	Data 0.000 (0.014)	Loss 2.3126 (2.9884)	Prec 53.125 (43.552)	LR 0.3
INFO - 12/16/22 16:46:59 - 0:04:10 - Epoch[0] - Iter: [1900/20019]	Time 0.106 (0.126)	Data 0.000 (0.013)	Loss 2.4180 (2.9642)	Prec 43.750 (43.840)	LR 0.3
INFO - 12/16/22 16:47:04 - 0:04:15 - Epoch[0] - Iter: [1950/20019]	Time 0.109 (0.125)	Data 0.000 (0.013)	Loss 2.7797 (2.9419)	Prec 40.625 (44.101)	LR 0.3
INFO - 12/16/22 16:47:09 - 0:04:20 - Epoch[0] - Iter: [2000/20019]	Time 0.105 (0.125)	Data 0.000 (0.013)	Loss 2.0175 (2.9207)	Prec 53.125 (44.381)	LR 0.3
INFO - 12/16/22 16:47:15 - 0:04:26 - Epoch[0] - Iter: [2050/20019]	Time 0.108 (0.124)	Data 0.000 (0.012)	Loss 2.1902 (2.8993)	Prec 48.438 (44.638)	LR 0.3
INFO - 12/16/22 16:47:20 - 0:04:31 - Epoch[0] - Iter: [2100/20019]	Time 0.110 (0.124)	Data 0.000 (0.012)	Loss 2.1130 (2.8783)	Prec 50.000 (44.888)	LR 0.3
INFO - 12/16/22 16:47:26 - 0:04:36 - Epoch[0] - Iter: [2150/20019]	Time 0.105 (0.124)	Data 0.000 (0.012)	Loss 1.8266 (2.8584)	Prec 53.125 (45.140)	LR 0.3
INFO - 12/16/22 16:47:31 - 0:04:42 - Epoch[0] - Iter: [2200/20019]	Time 0.105 (0.123)	Data 0.000 (0.012)	Loss 2.3330 (2.8400)	Prec 54.688 (45.394)	LR 0.3
INFO - 12/16/22 16:47:36 - 0:04:47 - Epoch[0] - Iter: [2250/20019]	Time 0.106 (0.123)	Data 0.000 (0.011)	Loss 1.4851 (2.8201)	Prec 70.312 (45.646)	LR 0.3
INFO - 12/16/22 16:47:42 - 0:04:53 - Epoch[0] - Iter: [2300/20019]	Time 0.107 (0.123)	Data 0.000 (0.011)	Loss 2.2273 (2.8023)	Prec 53.125 (45.875)	LR 0.3
INFO - 12/16/22 16:47:47 - 0:04:58 - Epoch[0] - Iter: [2350/20019]	Time 0.108 (0.122)	Data 0.000 (0.011)	Loss 2.0640 (2.7851)	Prec 50.000 (46.109)	LR 0.3
INFO - 12/16/22 16:47:53 - 0:05:04 - Epoch[0] - Iter: [2400/20019]	Time 0.107 (0.122)	Data 0.000 (0.011)	Loss 2.3159 (2.7684)	Prec 45.312 (46.330)	LR 0.3
INFO - 12/16/22 16:47:58 - 0:05:09 - Epoch[0] - Iter: [2450/20019]	Time 0.105 (0.122)	Data 0.000 (0.010)	Loss 2.2085 (2.7536)	Prec 50.000 (46.510)	LR 0.3
INFO - 12/16/22 16:48:03 - 0:05:14 - Epoch[0] - Iter: [2500/20019]	Time 0.107 (0.121)	Data 0.000 (0.010)	Loss 1.9842 (2.7376)	Prec 50.000 (46.708)	LR 0.3
INFO - 12/16/22 16:48:09 - 0:05:20 - Epoch[0] - Iter: [2550/20019]	Time 0.109 (0.121)	Data 0.000 (0.010)	Loss 1.8157 (2.7222)	Prec 51.562 (46.893)	LR 0.3
INFO - 12/16/22 16:48:14 - 0:05:25 - Epoch[0] - Iter: [2600/20019]	Time 0.107 (0.121)	Data 0.000 (0.010)	Loss 1.9470 (2.7071)	Prec 60.938 (47.073)	LR 0.3
INFO - 12/16/22 16:48:20 - 0:05:31 - Epoch[0] - Iter: [2650/20019]	Time 0.107 (0.121)	Data 0.000 (0.010)	Loss 2.6910 (2.6925)	Prec 40.625 (47.258)	LR 0.3
INFO - 12/16/22 16:48:25 - 0:05:36 - Epoch[0] - Iter: [2700/20019]	Time 0.108 (0.120)	Data 0.000 (0.009)	Loss 2.2711 (2.6791)	Prec 54.688 (47.422)	LR 0.3
INFO - 12/16/22 16:48:30 - 0:05:41 - Epoch[0] - Iter: [2750/20019]	Time 0.108 (0.120)	Data 0.000 (0.009)	Loss 1.5767 (2.6661)	Prec 62.500 (47.592)	LR 0.3
INFO - 12/16/22 16:48:36 - 0:05:47 - Epoch[0] - Iter: [2800/20019]	Time 0.108 (0.120)	Data 0.000 (0.009)	Loss 2.5274 (2.6521)	Prec 51.562 (47.805)	LR 0.3
INFO - 12/16/22 16:48:41 - 0:05:52 - Epoch[0] - Iter: [2850/20019]	Time 0.108 (0.120)	Data 0.000 (0.009)	Loss 1.6351 (2.6408)	Prec 67.188 (47.944)	LR 0.3
INFO - 12/16/22 16:48:47 - 0:05:58 - Epoch[0] - Iter: [2900/20019]	Time 0.109 (0.120)	Data 0.000 (0.009)	Loss 1.6519 (2.6286)	Prec 67.188 (48.093)	LR 0.3
INFO - 12/16/22 16:48:52 - 0:06:03 - Epoch[0] - Iter: [2950/20019]	Time 0.108 (0.119)	Data 0.000 (0.009)	Loss 2.1128 (2.6172)	Prec 51.562 (48.243)	LR 0.3
INFO - 12/16/22 16:48:58 - 0:06:09 - Epoch[0] - Iter: [3000/20019]	Time 0.109 (0.119)	Data 0.000 (0.009)	Loss 1.8098 (2.6052)	Prec 60.938 (48.400)	LR 0.3
INFO - 12/16/22 16:49:03 - 0:06:14 - Epoch[0] - Iter: [3050/20019]	Time 0.109 (0.119)	Data 0.000 (0.008)	Loss 1.7295 (2.5945)	Prec 62.500 (48.529)	LR 0.3
INFO - 12/16/22 16:49:08 - 0:06:19 - Epoch[0] - Iter: [3100/20019]	Time 0.107 (0.119)	Data 0.000 (0.008)	Loss 1.9947 (2.5828)	Prec 51.562 (48.675)	LR 0.3
