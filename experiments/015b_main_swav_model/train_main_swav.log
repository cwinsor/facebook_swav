INFO - 12/15/22 16:50:10 - 0:00:00 - ============ Initialized logger ============
INFO - 12/15/22 16:50:10 - 0:00:00 - arch: resnet50
                                     base_lr: 4.8
                                     batch_size: 64
                                     checkpoint_freq: 25
                                     crops_for_assign: [0, 1]
                                     data_path: C:\Users\chris\Downloads\ILSVRC\Data\CLS-LOC
                                     dist_url: $dist_url
                                     dump_checkpoints: D:\code_cluster\me_swav\facebook_swav\experiments\015b_main_swav_model\checkpoints
                                     dump_path: D:\code_cluster\me_swav\facebook_swav\experiments\015b_main_swav_model
                                     epoch_queue_starts: 15
                                     epochs: 800
                                     epsilon: 0.05
                                     feat_dim: 128
                                     final_lr: 0.0048
                                     freeze_prototypes_niters: 313
                                     gpu_to_work_on: 0
                                     hidden_mlp: 2048
                                     is_slurm_job: False
                                     local_rank: 0
                                     max_scale_crops: [1.0, 0.14]
                                     min_scale_crops: [0.14, 0.05]
                                     nmb_crops: [2, 6]
                                     nmb_prototypes: 3000
                                     queue_length: 0
                                     rank: 0
                                     seed: 31
                                     sinkhorn_iterations: 3
                                     size_crops: [224, 96]
                                     start_warmup: 0.3
                                     sync_bn: pytorch
                                     syncbn_process_group_size: 8
                                     temperature: 0.1
                                     use_fp16: False
                                     warmup_epochs: 10
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 12/15/22 16:50:10 - 0:00:00 - The experiment will be stored in D:\code_cluster\me_swav\facebook_swav\experiments\015b_main_swav_model
                                     

INFO - 12/15/22 16:50:10 - 0:00:00 - 0  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/15/22 16:50:10 - 0:00:00 - 1  _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)
INFO - 12/15/22 16:50:20 - 0:00:10 - Building data done with 1431167 images loaded.
INFO - 12/15/22 16:50:20 - 0:00:10 - Building model done.
INFO - 12/15/22 16:50:20 - 0:00:10 - Building optimizer
INFO - 12/15/22 16:51:48 - 0:01:38 - Building optimizer done.
INFO - 12/15/22 16:51:48 - 0:01:38 - ============ Starting epoch 0 ... ============
INFO - 12/15/22 16:52:15 - 0:02:06 - Model's state_dict:
INFO - 12/15/22 16:52:15 - 0:02:06 - module.conv1.weight	torch.Size([64, 3, 7, 7])
INFO - 12/15/22 16:52:15 - 0:02:06 - module.bn1.weight	torch.Size([64])
INFO - 12/15/22 16:52:15 - 0:02:06 - module.bn1.bias	torch.Size([64])
INFO - 12/15/22 16:52:15 - 0:02:06 - module.bn1.running_mean	torch.Size([64])
INFO - 12/15/22 16:52:15 - 0:02:06 - module.bn1.running_var	torch.Size([64])
INFO - 12/15/22 16:52:15 - 0:02:06 - module.bn1.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:15 - 0:02:06 - module.layer1.0.conv1.weight	torch.Size([64, 64, 1, 1])
INFO - 12/15/22 16:52:15 - 0:02:06 - module.layer1.0.bn1.weight	torch.Size([64])
INFO - 12/15/22 16:52:15 - 0:02:06 - module.layer1.0.bn1.bias	torch.Size([64])
INFO - 12/15/22 16:52:15 - 0:02:06 - module.layer1.0.bn1.running_mean	torch.Size([64])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.0.bn1.running_var	torch.Size([64])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.0.conv2.weight	torch.Size([64, 64, 3, 3])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.0.bn2.weight	torch.Size([64])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.0.bn2.bias	torch.Size([64])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.0.bn2.running_mean	torch.Size([64])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.0.bn2.running_var	torch.Size([64])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.0.conv3.weight	torch.Size([256, 64, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.0.bn3.weight	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.0.bn3.bias	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.0.bn3.running_mean	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.0.bn3.running_var	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.0.downsample.0.weight	torch.Size([256, 64, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.0.downsample.1.weight	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.0.downsample.1.bias	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.0.downsample.1.running_mean	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.0.downsample.1.running_var	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.1.conv1.weight	torch.Size([64, 256, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.1.bn1.weight	torch.Size([64])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.1.bn1.bias	torch.Size([64])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.1.bn1.running_mean	torch.Size([64])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.1.bn1.running_var	torch.Size([64])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.1.conv2.weight	torch.Size([64, 64, 3, 3])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.1.bn2.weight	torch.Size([64])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.1.bn2.bias	torch.Size([64])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.1.bn2.running_mean	torch.Size([64])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.1.bn2.running_var	torch.Size([64])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.1.conv3.weight	torch.Size([256, 64, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.1.bn3.weight	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.1.bn3.bias	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.1.bn3.running_mean	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.1.bn3.running_var	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.2.conv1.weight	torch.Size([64, 256, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.2.bn1.weight	torch.Size([64])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.2.bn1.bias	torch.Size([64])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.2.bn1.running_mean	torch.Size([64])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.2.bn1.running_var	torch.Size([64])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.2.conv2.weight	torch.Size([64, 64, 3, 3])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.2.bn2.weight	torch.Size([64])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.2.bn2.bias	torch.Size([64])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.2.bn2.running_mean	torch.Size([64])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.2.bn2.running_var	torch.Size([64])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.2.conv3.weight	torch.Size([256, 64, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.2.bn3.weight	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.2.bn3.bias	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.2.bn3.running_mean	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.2.bn3.running_var	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer1.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.0.conv1.weight	torch.Size([128, 256, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.0.bn1.weight	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.0.bn1.bias	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.0.bn1.running_mean	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.0.bn1.running_var	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.0.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.0.bn2.weight	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.0.bn2.bias	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.0.bn2.running_mean	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.0.bn2.running_var	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.0.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.0.bn3.weight	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.0.bn3.bias	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.0.bn3.running_mean	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.0.bn3.running_var	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.0.downsample.0.weight	torch.Size([512, 256, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.0.downsample.1.weight	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.0.downsample.1.bias	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.0.downsample.1.running_mean	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.0.downsample.1.running_var	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.1.conv1.weight	torch.Size([128, 512, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.1.bn1.weight	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.1.bn1.bias	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.1.bn1.running_mean	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.1.bn1.running_var	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.1.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.1.bn2.weight	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.1.bn2.bias	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.1.bn2.running_mean	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.1.bn2.running_var	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.1.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.1.bn3.weight	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.1.bn3.bias	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.1.bn3.running_mean	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.1.bn3.running_var	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.2.conv1.weight	torch.Size([128, 512, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.2.bn1.weight	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.2.bn1.bias	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.2.bn1.running_mean	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.2.bn1.running_var	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.2.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.2.bn2.weight	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.2.bn2.bias	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.2.bn2.running_mean	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.2.bn2.running_var	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.2.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.2.bn3.weight	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.2.bn3.bias	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.2.bn3.running_mean	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.2.bn3.running_var	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.3.conv1.weight	torch.Size([128, 512, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.3.bn1.weight	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.3.bn1.bias	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.3.bn1.running_mean	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.3.bn1.running_var	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.3.bn1.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.3.conv2.weight	torch.Size([128, 128, 3, 3])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.3.bn2.weight	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.3.bn2.bias	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.3.bn2.running_mean	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.3.bn2.running_var	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.3.bn2.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.3.conv3.weight	torch.Size([512, 128, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.3.bn3.weight	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.3.bn3.bias	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.3.bn3.running_mean	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.3.bn3.running_var	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer2.3.bn3.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.0.conv1.weight	torch.Size([256, 512, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.0.bn1.weight	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.0.bn1.bias	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.0.bn1.running_mean	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.0.bn1.running_var	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.0.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.0.bn2.weight	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.0.bn2.bias	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.0.bn2.running_mean	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.0.bn2.running_var	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.0.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.0.bn3.weight	torch.Size([1024])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.0.bn3.bias	torch.Size([1024])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.0.bn3.running_mean	torch.Size([1024])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.0.bn3.running_var	torch.Size([1024])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.0.downsample.0.weight	torch.Size([1024, 512, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.0.downsample.1.weight	torch.Size([1024])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.0.downsample.1.bias	torch.Size([1024])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.0.downsample.1.running_mean	torch.Size([1024])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.0.downsample.1.running_var	torch.Size([1024])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.1.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.1.bn1.weight	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.1.bn1.bias	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.1.bn1.running_mean	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.1.bn1.running_var	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.1.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.1.bn2.weight	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.1.bn2.bias	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.1.bn2.running_mean	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.1.bn2.running_var	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.1.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.1.bn3.weight	torch.Size([1024])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.1.bn3.bias	torch.Size([1024])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.1.bn3.running_mean	torch.Size([1024])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.1.bn3.running_var	torch.Size([1024])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.2.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.2.bn1.weight	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.2.bn1.bias	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.2.bn1.running_mean	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.2.bn1.running_var	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.2.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.2.bn2.weight	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.2.bn2.bias	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.2.bn2.running_mean	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.2.bn2.running_var	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.2.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.2.bn3.weight	torch.Size([1024])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.2.bn3.bias	torch.Size([1024])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.2.bn3.running_mean	torch.Size([1024])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.2.bn3.running_var	torch.Size([1024])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.3.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.3.bn1.weight	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.3.bn1.bias	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.3.bn1.running_mean	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.3.bn1.running_var	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.3.bn1.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.3.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.3.bn2.weight	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.3.bn2.bias	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.3.bn2.running_mean	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.3.bn2.running_var	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.3.bn2.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.3.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.3.bn3.weight	torch.Size([1024])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.3.bn3.bias	torch.Size([1024])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.3.bn3.running_mean	torch.Size([1024])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.3.bn3.running_var	torch.Size([1024])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.3.bn3.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.4.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.4.bn1.weight	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.4.bn1.bias	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.4.bn1.running_mean	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.4.bn1.running_var	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.4.bn1.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.4.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.4.bn2.weight	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.4.bn2.bias	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.4.bn2.running_mean	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.4.bn2.running_var	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.4.bn2.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.4.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.4.bn3.weight	torch.Size([1024])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.4.bn3.bias	torch.Size([1024])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.4.bn3.running_mean	torch.Size([1024])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.4.bn3.running_var	torch.Size([1024])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.4.bn3.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.5.conv1.weight	torch.Size([256, 1024, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.5.bn1.weight	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.5.bn1.bias	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.5.bn1.running_mean	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.5.bn1.running_var	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.5.bn1.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.5.conv2.weight	torch.Size([256, 256, 3, 3])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.5.bn2.weight	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.5.bn2.bias	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.5.bn2.running_mean	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.5.bn2.running_var	torch.Size([256])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.5.bn2.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.5.conv3.weight	torch.Size([1024, 256, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.5.bn3.weight	torch.Size([1024])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.5.bn3.bias	torch.Size([1024])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.5.bn3.running_mean	torch.Size([1024])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.5.bn3.running_var	torch.Size([1024])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer3.5.bn3.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer4.0.conv1.weight	torch.Size([512, 1024, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer4.0.bn1.weight	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer4.0.bn1.bias	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer4.0.bn1.running_mean	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer4.0.bn1.running_var	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer4.0.bn1.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer4.0.conv2.weight	torch.Size([512, 512, 3, 3])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer4.0.bn2.weight	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer4.0.bn2.bias	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer4.0.bn2.running_mean	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer4.0.bn2.running_var	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer4.0.bn2.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer4.0.conv3.weight	torch.Size([2048, 512, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer4.0.bn3.weight	torch.Size([2048])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer4.0.bn3.bias	torch.Size([2048])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer4.0.bn3.running_mean	torch.Size([2048])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer4.0.bn3.running_var	torch.Size([2048])
INFO - 12/15/22 16:52:16 - 0:02:06 - module.layer4.0.bn3.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.0.downsample.0.weight	torch.Size([2048, 1024, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.0.downsample.1.weight	torch.Size([2048])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.0.downsample.1.bias	torch.Size([2048])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.0.downsample.1.running_mean	torch.Size([2048])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.0.downsample.1.running_var	torch.Size([2048])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.0.downsample.1.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.1.conv1.weight	torch.Size([512, 2048, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.1.bn1.weight	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.1.bn1.bias	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.1.bn1.running_mean	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.1.bn1.running_var	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.1.bn1.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.1.conv2.weight	torch.Size([512, 512, 3, 3])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.1.bn2.weight	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.1.bn2.bias	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.1.bn2.running_mean	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.1.bn2.running_var	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.1.bn2.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.1.conv3.weight	torch.Size([2048, 512, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.1.bn3.weight	torch.Size([2048])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.1.bn3.bias	torch.Size([2048])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.1.bn3.running_mean	torch.Size([2048])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.1.bn3.running_var	torch.Size([2048])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.1.bn3.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.2.conv1.weight	torch.Size([512, 2048, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.2.bn1.weight	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.2.bn1.bias	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.2.bn1.running_mean	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.2.bn1.running_var	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.2.bn1.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.2.conv2.weight	torch.Size([512, 512, 3, 3])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.2.bn2.weight	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.2.bn2.bias	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.2.bn2.running_mean	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.2.bn2.running_var	torch.Size([512])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.2.bn2.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.2.conv3.weight	torch.Size([2048, 512, 1, 1])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.2.bn3.weight	torch.Size([2048])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.2.bn3.bias	torch.Size([2048])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.2.bn3.running_mean	torch.Size([2048])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.2.bn3.running_var	torch.Size([2048])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.layer4.2.bn3.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.projection_head.0.weight	torch.Size([2048, 2048])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.projection_head.0.bias	torch.Size([2048])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.projection_head.1.weight	torch.Size([2048])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.projection_head.1.bias	torch.Size([2048])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.projection_head.1.running_mean	torch.Size([2048])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.projection_head.1.running_var	torch.Size([2048])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.projection_head.1.num_batches_tracked	torch.Size([])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.projection_head.3.weight	torch.Size([128, 2048])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.projection_head.3.bias	torch.Size([128])
INFO - 12/15/22 16:52:16 - 0:02:07 - module.prototypes.weight	torch.Size([3000, 128])
INFO - 12/15/22 16:52:16 - 0:02:07 - info.model:
INFO - 12/15/22 16:52:16 - 0:02:07 - DataParallel(
                                       (module): ResNet(
                                         (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)
                                         (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)
                                         (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         (relu): ReLU(inplace=True)
                                         (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
                                         (layer1): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                               (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (layer2): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                             (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                               (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (3): Bottleneck(
                                             (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (layer3): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                             (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                               (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (3): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (4): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (5): Bottleneck(
                                             (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (layer4): Sequential(
                                           (0): Bottleneck(
                                             (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                             (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                             (downsample): Sequential(
                                               (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                               (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             )
                                           )
                                           (1): Bottleneck(
                                             (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                           (2): Bottleneck(
                                             (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                             (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                             (relu): ReLU(inplace=True)
                                           )
                                         )
                                         (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                         (projection_head): Sequential(
                                           (0): Linear(in_features=2048, out_features=2048, bias=True)
                                           (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (2): ReLU(inplace=True)
                                           (3): Linear(in_features=2048, out_features=128, bias=True)
                                         )
                                         (prototypes): Linear(in_features=128, out_features=3000, bias=False)
                                       )
                                     )
INFO - 12/15/22 16:52:25 - 0:02:15 - Epoch: [0][0]	Time 37.241 (37.241)	Data 27.676 (27.676)	Loss 8.3823 (8.3823)	Lr: 0.3000
INFO - 12/15/22 16:52:55 - 0:02:45 - Epoch: [0][50]	Time 0.599 (1.320)	Data 0.000 (0.543)	Loss 8.2425 (8.2553)	Lr: 0.3010
INFO - 12/15/22 16:53:25 - 0:03:16 - Epoch: [0][100]	Time 0.600 (0.964)	Data 0.000 (0.274)	Loss 8.2316 (8.2462)	Lr: 0.3020
INFO - 12/15/22 16:53:55 - 0:03:46 - Epoch: [0][150]	Time 0.602 (0.844)	Data 0.000 (0.183)	Loss 8.2202 (8.2405)	Lr: 0.3030
INFO - 12/15/22 16:54:25 - 0:04:16 - Epoch: [0][200]	Time 0.599 (0.784)	Data 0.000 (0.138)	Loss 8.2078 (8.2357)	Lr: 0.3040
INFO - 12/15/22 16:54:55 - 0:04:46 - Epoch: [0][250]	Time 0.601 (0.747)	Data 0.000 (0.110)	Loss 8.2044 (8.2308)	Lr: 0.3050
INFO - 12/15/22 16:55:26 - 0:05:16 - Epoch: [0][300]	Time 0.599 (0.723)	Data 0.000 (0.092)	Loss 8.2139 (8.2284)	Lr: 0.3060
INFO - 12/15/22 16:55:56 - 0:05:46 - Epoch: [0][350]	Time 0.601 (0.706)	Data 0.000 (0.079)	Loss 8.0106 (8.2110)	Lr: 0.3070
INFO - 12/15/22 16:56:26 - 0:06:16 - Epoch: [0][400]	Time 0.599 (0.693)	Data 0.000 (0.069)	Loss 8.0077 (8.1857)	Lr: 0.3080
INFO - 12/15/22 16:56:56 - 0:06:46 - Epoch: [0][450]	Time 0.605 (0.683)	Data 0.000 (0.061)	Loss 8.0081 (8.1659)	Lr: 0.3091
INFO - 12/15/22 16:57:26 - 0:07:16 - Epoch: [0][500]	Time 0.604 (0.675)	Data 0.000 (0.055)	Loss 8.0075 (8.1501)	Lr: 0.3101
INFO - 12/15/22 16:57:56 - 0:07:47 - Epoch: [0][550]	Time 0.600 (0.669)	Data 0.000 (0.050)	Loss 8.0065 (8.1371)	Lr: 0.3111
INFO - 12/15/22 16:58:26 - 0:08:17 - Epoch: [0][600]	Time 0.601 (0.663)	Data 0.000 (0.046)	Loss 8.0065 (8.1262)	Lr: 0.3121
INFO - 12/15/22 16:58:57 - 0:08:47 - Epoch: [0][650]	Time 0.601 (0.659)	Data 0.000 (0.043)	Loss 8.0077 (8.1170)	Lr: 0.3131
INFO - 12/15/22 16:59:27 - 0:09:17 - Epoch: [0][700]	Time 0.596 (0.655)	Data 0.000 (0.040)	Loss 8.0073 (8.1092)	Lr: 0.3141
INFO - 12/15/22 16:59:57 - 0:09:47 - Epoch: [0][750]	Time 0.608 (0.651)	Data 0.000 (0.037)	Loss 8.0068 (8.1024)	Lr: 0.3151
INFO - 12/15/22 17:00:27 - 0:10:17 - Epoch: [0][800]	Time 0.607 (0.648)	Data 0.000 (0.035)	Loss 8.0067 (8.0964)	Lr: 0.3161
INFO - 12/15/22 17:00:57 - 0:10:48 - Epoch: [0][850]	Time 0.600 (0.646)	Data 0.000 (0.033)	Loss 8.0070 (8.0911)	Lr: 0.3171
INFO - 12/15/22 17:01:27 - 0:11:18 - Epoch: [0][900]	Time 0.610 (0.643)	Data 0.000 (0.031)	Loss 8.0080 (8.0865)	Lr: 0.3181
INFO - 12/15/22 17:01:58 - 0:11:48 - Epoch: [0][950]	Time 0.596 (0.641)	Data 0.000 (0.029)	Loss 8.0068 (8.0823)	Lr: 0.3191
INFO - 12/15/22 17:02:28 - 0:12:18 - Epoch: [0][1000]	Time 0.599 (0.639)	Data 0.000 (0.028)	Loss 8.0082 (8.0785)	Lr: 0.3201
INFO - 12/15/22 17:02:58 - 0:12:48 - Epoch: [0][1050]	Time 0.604 (0.638)	Data 0.000 (0.027)	Loss 8.0067 (8.0751)	Lr: 0.3211
INFO - 12/15/22 17:03:28 - 0:13:19 - Epoch: [0][1100]	Time 0.602 (0.636)	Data 0.000 (0.025)	Loss 8.0065 (8.0720)	Lr: 0.3221
INFO - 12/15/22 17:03:58 - 0:13:49 - Epoch: [0][1150]	Time 0.602 (0.635)	Data 0.000 (0.024)	Loss 8.0065 (8.0692)	Lr: 0.3231
INFO - 12/15/22 17:04:29 - 0:14:19 - Epoch: [0][1200]	Time 0.600 (0.633)	Data 0.000 (0.023)	Loss 8.0064 (8.0666)	Lr: 0.3241
INFO - 12/15/22 17:04:59 - 0:14:49 - Epoch: [0][1250]	Time 0.600 (0.632)	Data 0.000 (0.022)	Loss 8.0064 (8.0642)	Lr: 0.3252
INFO - 12/15/22 17:05:29 - 0:15:19 - Epoch: [0][1300]	Time 0.598 (0.631)	Data 0.000 (0.021)	Loss 8.0068 (8.0620)	Lr: 0.3262
INFO - 12/15/22 17:05:59 - 0:15:49 - Epoch: [0][1350]	Time 0.600 (0.630)	Data 0.000 (0.021)	Loss 8.0064 (8.0599)	Lr: 0.3272
INFO - 12/15/22 17:06:29 - 0:16:20 - Epoch: [0][1400]	Time 0.603 (0.629)	Data 0.000 (0.020)	Loss 8.0064 (8.0580)	Lr: 0.3282
INFO - 12/15/22 17:06:59 - 0:16:50 - Epoch: [0][1450]	Time 0.616 (0.628)	Data 0.000 (0.019)	Loss 8.0065 (8.0562)	Lr: 0.3292
INFO - 12/15/22 17:07:30 - 0:17:20 - Epoch: [0][1500]	Time 0.600 (0.627)	Data 0.000 (0.019)	Loss 8.0066 (8.0546)	Lr: 0.3302
INFO - 12/15/22 17:08:00 - 0:17:50 - Epoch: [0][1550]	Time 0.601 (0.627)	Data 0.000 (0.018)	Loss 8.0067 (8.0530)	Lr: 0.3312
INFO - 12/15/22 17:08:30 - 0:18:20 - Epoch: [0][1600]	Time 0.603 (0.626)	Data 0.000 (0.017)	Loss 8.0067 (8.0516)	Lr: 0.3322
INFO - 12/15/22 17:09:00 - 0:18:51 - Epoch: [0][1650]	Time 0.598 (0.625)	Data 0.000 (0.017)	Loss 8.0064 (8.0502)	Lr: 0.3332
INFO - 12/15/22 17:09:30 - 0:19:21 - Epoch: [0][1700]	Time 0.601 (0.625)	Data 0.000 (0.016)	Loss 8.0069 (8.0489)	Lr: 0.3342
INFO - 12/15/22 17:10:01 - 0:19:51 - Epoch: [0][1750]	Time 0.600 (0.624)	Data 0.000 (0.016)	Loss 8.0064 (8.0477)	Lr: 0.3352
INFO - 12/15/22 17:10:31 - 0:20:21 - Epoch: [0][1800]	Time 0.600 (0.624)	Data 0.000 (0.016)	Loss 8.0064 (8.0466)	Lr: 0.3362
INFO - 12/15/22 17:11:01 - 0:20:51 - Epoch: [0][1850]	Time 0.609 (0.623)	Data 0.000 (0.015)	Loss 8.0064 (8.0455)	Lr: 0.3372
INFO - 12/15/22 17:11:31 - 0:21:21 - Epoch: [0][1900]	Time 0.606 (0.622)	Data 0.000 (0.015)	Loss 8.0068 (8.0445)	Lr: 0.3382
INFO - 12/15/22 17:12:01 - 0:21:52 - Epoch: [0][1950]	Time 0.615 (0.622)	Data 0.000 (0.014)	Loss 8.0064 (8.0435)	Lr: 0.3392
INFO - 12/15/22 17:12:31 - 0:22:22 - Epoch: [0][2000]	Time 0.612 (0.622)	Data 0.000 (0.014)	Loss 8.0064 (8.0426)	Lr: 0.3402
INFO - 12/15/22 17:13:02 - 0:22:52 - Epoch: [0][2050]	Time 0.596 (0.621)	Data 0.000 (0.014)	Loss 8.0073 (8.0417)	Lr: 0.3413
INFO - 12/15/22 17:13:32 - 0:23:22 - Epoch: [0][2100]	Time 0.591 (0.621)	Data 0.000 (0.013)	Loss 8.0064 (8.0409)	Lr: 0.3423
INFO - 12/15/22 17:14:02 - 0:23:52 - Epoch: [0][2150]	Time 0.606 (0.620)	Data 0.000 (0.013)	Loss 8.0066 (8.0401)	Lr: 0.3433
INFO - 12/15/22 17:14:32 - 0:24:23 - Epoch: [0][2200]	Time 0.601 (0.620)	Data 0.000 (0.013)	Loss 8.0064 (8.0393)	Lr: 0.3443
INFO - 12/15/22 17:15:02 - 0:24:53 - Epoch: [0][2250]	Time 0.610 (0.620)	Data 0.000 (0.013)	Loss 8.0065 (8.0386)	Lr: 0.3453
INFO - 12/15/22 17:15:33 - 0:25:23 - Epoch: [0][2300]	Time 0.595 (0.619)	Data 0.000 (0.012)	Loss 8.0064 (8.0379)	Lr: 0.3463
INFO - 12/15/22 17:16:03 - 0:25:53 - Epoch: [0][2350]	Time 0.601 (0.619)	Data 0.000 (0.012)	Loss 8.0064 (8.0372)	Lr: 0.3473
INFO - 12/15/22 17:16:33 - 0:26:23 - Epoch: [0][2400]	Time 0.598 (0.619)	Data 0.000 (0.012)	Loss 8.0064 (8.0366)	Lr: 0.3483
INFO - 12/15/22 17:17:03 - 0:26:53 - Epoch: [0][2450]	Time 0.653 (0.618)	Data 0.000 (0.012)	Loss 8.0064 (8.0359)	Lr: 0.3493
INFO - 12/15/22 17:17:33 - 0:27:24 - Epoch: [0][2500]	Time 0.600 (0.618)	Data 0.000 (0.011)	Loss 8.0066 (8.0354)	Lr: 0.3503
INFO - 12/15/22 17:18:03 - 0:27:54 - Epoch: [0][2550]	Time 0.600 (0.618)	Data 0.000 (0.011)	Loss 8.0072 (8.0348)	Lr: 0.3513
INFO - 12/15/22 17:18:34 - 0:28:24 - Epoch: [0][2600]	Time 0.601 (0.617)	Data 0.000 (0.011)	Loss 8.0067 (8.0343)	Lr: 0.3523
INFO - 12/15/22 17:19:04 - 0:28:54 - Epoch: [0][2650]	Time 0.601 (0.617)	Data 0.000 (0.011)	Loss 8.0064 (8.0337)	Lr: 0.3533
INFO - 12/15/22 17:19:34 - 0:29:24 - Epoch: [0][2700]	Time 0.601 (0.617)	Data 0.000 (0.011)	Loss 8.0065 (8.0332)	Lr: 0.3543
INFO - 12/15/22 17:20:04 - 0:29:54 - Epoch: [0][2750]	Time 0.604 (0.617)	Data 0.000 (0.010)	Loss 8.0067 (8.0327)	Lr: 0.3553
INFO - 12/15/22 17:20:34 - 0:30:25 - Epoch: [0][2800]	Time 0.616 (0.616)	Data 0.000 (0.010)	Loss 8.0064 (8.0323)	Lr: 0.3563
INFO - 12/15/22 17:21:05 - 0:30:55 - Epoch: [0][2850]	Time 0.602 (0.616)	Data 0.000 (0.010)	Loss 8.0064 (8.0318)	Lr: 0.3574
INFO - 12/15/22 17:21:35 - 0:31:25 - Epoch: [0][2900]	Time 0.599 (0.616)	Data 0.000 (0.010)	Loss 8.0064 (8.0314)	Lr: 0.3584
INFO - 12/15/22 17:22:05 - 0:31:55 - Epoch: [0][2950]	Time 0.601 (0.616)	Data 0.000 (0.010)	Loss 8.0064 (8.0310)	Lr: 0.3594
INFO - 12/15/22 17:22:35 - 0:32:26 - Epoch: [0][3000]	Time 0.600 (0.616)	Data 0.000 (0.009)	Loss 8.0064 (8.0306)	Lr: 0.3604
INFO - 12/15/22 17:23:05 - 0:32:56 - Epoch: [0][3050]	Time 0.601 (0.615)	Data 0.000 (0.009)	Loss 8.0068 (8.0302)	Lr: 0.3614
INFO - 12/15/22 17:23:36 - 0:33:26 - Epoch: [0][3100]	Time 0.617 (0.615)	Data 0.000 (0.009)	Loss 8.0065 (8.0298)	Lr: 0.3624
INFO - 12/15/22 17:24:06 - 0:33:56 - Epoch: [0][3150]	Time 0.614 (0.615)	Data 0.000 (0.009)	Loss 8.0065 (8.0294)	Lr: 0.3634
INFO - 12/15/22 17:24:36 - 0:34:26 - Epoch: [0][3200]	Time 0.606 (0.615)	Data 0.000 (0.009)	Loss 8.0064 (8.0291)	Lr: 0.3644
INFO - 12/15/22 17:25:06 - 0:34:56 - Epoch: [0][3250]	Time 0.600 (0.615)	Data 0.000 (0.009)	Loss 8.0065 (8.0287)	Lr: 0.3654
INFO - 12/15/22 17:25:36 - 0:35:27 - Epoch: [0][3300]	Time 0.615 (0.615)	Data 0.000 (0.009)	Loss 8.0064 (8.0284)	Lr: 0.3664
INFO - 12/15/22 17:26:07 - 0:35:57 - Epoch: [0][3350]	Time 0.613 (0.614)	Data 0.000 (0.009)	Loss 8.0064 (8.0280)	Lr: 0.3674
INFO - 12/15/22 17:26:37 - 0:36:27 - Epoch: [0][3400]	Time 0.611 (0.614)	Data 0.000 (0.008)	Loss 8.0064 (8.0277)	Lr: 0.3684
INFO - 12/15/22 17:27:07 - 0:36:57 - Epoch: [0][3450]	Time 0.608 (0.614)	Data 0.000 (0.008)	Loss 8.0064 (8.0274)	Lr: 0.3694
INFO - 12/15/22 17:27:37 - 0:37:27 - Epoch: [0][3500]	Time 0.609 (0.614)	Data 0.000 (0.008)	Loss 8.0064 (8.0271)	Lr: 0.3704
INFO - 12/15/22 17:28:07 - 0:37:58 - Epoch: [0][3550]	Time 0.601 (0.614)	Data 0.000 (0.008)	Loss 8.0067 (8.0268)	Lr: 0.3714
INFO - 12/15/22 17:28:37 - 0:38:28 - Epoch: [0][3600]	Time 0.613 (0.614)	Data 0.000 (0.008)	Loss 8.0073 (8.0266)	Lr: 0.3724
INFO - 12/15/22 17:29:08 - 0:38:58 - Epoch: [0][3650]	Time 0.598 (0.613)	Data 0.000 (0.008)	Loss 8.0068 (8.0263)	Lr: 0.3735
INFO - 12/15/22 17:29:38 - 0:39:28 - Epoch: [0][3700]	Time 0.601 (0.613)	Data 0.000 (0.008)	Loss 8.0072 (8.0260)	Lr: 0.3745
INFO - 12/15/22 17:30:08 - 0:39:58 - Epoch: [0][3750]	Time 0.600 (0.613)	Data 0.000 (0.008)	Loss 8.0068 (8.0258)	Lr: 0.3755
INFO - 12/15/22 17:30:38 - 0:40:29 - Epoch: [0][3800]	Time 0.616 (0.613)	Data 0.000 (0.008)	Loss 8.0064 (8.0255)	Lr: 0.3765
INFO - 12/15/22 17:31:08 - 0:40:59 - Epoch: [0][3850]	Time 0.602 (0.613)	Data 0.000 (0.007)	Loss 8.0065 (8.0253)	Lr: 0.3775
INFO - 12/15/22 17:31:38 - 0:41:29 - Epoch: [0][3900]	Time 0.602 (0.613)	Data 0.000 (0.007)	Loss 8.0064 (8.0250)	Lr: 0.3785
INFO - 12/15/22 17:32:09 - 0:41:59 - Epoch: [0][3950]	Time 0.601 (0.613)	Data 0.000 (0.007)	Loss 8.0064 (8.0248)	Lr: 0.3795
INFO - 12/15/22 17:32:39 - 0:42:29 - Epoch: [0][4000]	Time 0.602 (0.613)	Data 0.000 (0.007)	Loss 8.0070 (8.0246)	Lr: 0.3805
INFO - 12/15/22 17:33:09 - 0:42:59 - Epoch: [0][4050]	Time 0.617 (0.612)	Data 0.000 (0.007)	Loss 8.0076 (8.0244)	Lr: 0.3815
INFO - 12/15/22 17:33:39 - 0:43:30 - Epoch: [0][4100]	Time 0.601 (0.612)	Data 0.000 (0.007)	Loss 8.0065 (8.0242)	Lr: 0.3825
INFO - 12/15/22 17:34:09 - 0:44:00 - Epoch: [0][4150]	Time 0.603 (0.612)	Data 0.000 (0.007)	Loss 8.0068 (8.0239)	Lr: 0.3835
INFO - 12/15/22 17:34:40 - 0:44:30 - Epoch: [0][4200]	Time 0.601 (0.612)	Data 0.000 (0.007)	Loss 8.0064 (8.0237)	Lr: 0.3845
INFO - 12/15/22 17:35:10 - 0:45:00 - Epoch: [0][4250]	Time 0.600 (0.612)	Data 0.000 (0.007)	Loss 8.0066 (8.0235)	Lr: 0.3855
INFO - 12/15/22 17:35:40 - 0:45:30 - Epoch: [0][4300]	Time 0.601 (0.612)	Data 0.000 (0.007)	Loss 8.0064 (8.0233)	Lr: 0.3865
INFO - 12/15/22 17:36:10 - 0:46:00 - Epoch: [0][4350]	Time 0.600 (0.612)	Data 0.000 (0.007)	Loss 8.0064 (8.0231)	Lr: 0.3875
INFO - 12/15/22 17:36:40 - 0:46:31 - Epoch: [0][4400]	Time 0.597 (0.612)	Data 0.000 (0.007)	Loss 8.0068 (8.0230)	Lr: 0.3885
INFO - 12/15/22 17:37:10 - 0:47:01 - Epoch: [0][4450]	Time 0.614 (0.612)	Data 0.000 (0.007)	Loss 8.0067 (8.0228)	Lr: 0.3896
INFO - 12/15/22 17:37:41 - 0:47:31 - Epoch: [0][4500]	Time 0.617 (0.612)	Data 0.000 (0.006)	Loss 8.0069 (8.0226)	Lr: 0.3906
INFO - 12/15/22 17:38:11 - 0:48:01 - Epoch: [0][4550]	Time 0.606 (0.612)	Data 0.000 (0.006)	Loss 8.0071 (8.0224)	Lr: 0.3916
INFO - 12/15/22 17:38:41 - 0:48:31 - Epoch: [0][4600]	Time 0.606 (0.611)	Data 0.000 (0.006)	Loss 8.0065 (8.0223)	Lr: 0.3926
INFO - 12/15/22 17:39:11 - 0:49:02 - Epoch: [0][4650]	Time 0.602 (0.611)	Data 0.000 (0.006)	Loss 8.0064 (8.0221)	Lr: 0.3936
INFO - 12/15/22 17:39:41 - 0:49:32 - Epoch: [0][4700]	Time 0.596 (0.611)	Data 0.000 (0.006)	Loss 8.0069 (8.0219)	Lr: 0.3946
INFO - 12/15/22 17:40:12 - 0:50:02 - Epoch: [0][4750]	Time 0.596 (0.611)	Data 0.000 (0.006)	Loss 8.0065 (8.0218)	Lr: 0.3956
INFO - 12/15/22 17:40:42 - 0:50:32 - Epoch: [0][4800]	Time 0.590 (0.611)	Data 0.000 (0.006)	Loss 8.0065 (8.0216)	Lr: 0.3966
INFO - 12/15/22 17:41:12 - 0:51:02 - Epoch: [0][4850]	Time 0.607 (0.611)	Data 0.000 (0.006)	Loss 8.0068 (8.0215)	Lr: 0.3976
INFO - 12/15/22 17:41:42 - 0:51:33 - Epoch: [0][4900]	Time 0.601 (0.611)	Data 0.000 (0.006)	Loss 8.0067 (8.0213)	Lr: 0.3986
INFO - 12/15/22 17:42:12 - 0:52:03 - Epoch: [0][4950]	Time 0.611 (0.611)	Data 0.000 (0.006)	Loss 8.0064 (8.0212)	Lr: 0.3996
INFO - 12/15/22 17:42:43 - 0:52:33 - Epoch: [0][5000]	Time 0.611 (0.611)	Data 0.000 (0.006)	Loss 8.0064 (8.0210)	Lr: 0.4006
INFO - 12/15/22 17:43:13 - 0:53:03 - Epoch: [0][5050]	Time 0.601 (0.611)	Data 0.000 (0.006)	Loss 8.0065 (8.0209)	Lr: 0.4016
INFO - 12/15/22 17:43:43 - 0:53:33 - Epoch: [0][5100]	Time 0.601 (0.611)	Data 0.000 (0.006)	Loss 8.0072 (8.0207)	Lr: 0.4026
INFO - 12/15/22 17:44:13 - 0:54:04 - Epoch: [0][5150]	Time 0.615 (0.611)	Data 0.000 (0.006)	Loss 8.0066 (8.0206)	Lr: 0.4036
INFO - 12/15/22 17:44:43 - 0:54:34 - Epoch: [0][5200]	Time 0.603 (0.611)	Data 0.000 (0.006)	Loss 8.0064 (8.0205)	Lr: 0.4046
INFO - 12/15/22 17:45:14 - 0:55:04 - Epoch: [0][5250]	Time 0.601 (0.610)	Data 0.000 (0.006)	Loss 8.0065 (8.0203)	Lr: 0.4057
INFO - 12/15/22 17:45:44 - 0:55:34 - Epoch: [0][5300]	Time 0.603 (0.610)	Data 0.000 (0.006)	Loss 8.0064 (8.0202)	Lr: 0.4067
INFO - 12/15/22 17:46:14 - 0:56:04 - Epoch: [0][5350]	Time 0.599 (0.610)	Data 0.000 (0.005)	Loss 8.0065 (8.0201)	Lr: 0.4077
INFO - 12/15/22 17:46:44 - 0:56:34 - Epoch: [0][5400]	Time 0.599 (0.610)	Data 0.000 (0.005)	Loss 8.0066 (8.0199)	Lr: 0.4087
INFO - 12/15/22 17:47:14 - 0:57:05 - Epoch: [0][5450]	Time 0.602 (0.610)	Data 0.000 (0.005)	Loss 8.0067 (8.0198)	Lr: 0.4097
INFO - 12/15/22 17:47:45 - 0:57:35 - Epoch: [0][5500]	Time 0.598 (0.610)	Data 0.000 (0.005)	Loss 8.0068 (8.0197)	Lr: 0.4107
INFO - 12/15/22 17:48:15 - 0:58:05 - Epoch: [0][5550]	Time 0.601 (0.610)	Data 0.000 (0.005)	Loss 8.0067 (8.0196)	Lr: 0.4117
INFO - 12/15/22 17:48:45 - 0:58:35 - Epoch: [0][5600]	Time 0.598 (0.610)	Data 0.000 (0.005)	Loss 8.0064 (8.0195)	Lr: 0.4127
INFO - 12/15/22 17:49:15 - 0:59:06 - Epoch: [0][5650]	Time 0.601 (0.610)	Data 0.000 (0.005)	Loss 8.0066 (8.0194)	Lr: 0.4137
INFO - 12/15/22 17:49:45 - 0:59:36 - Epoch: [0][5700]	Time 0.600 (0.610)	Data 0.000 (0.005)	Loss 8.0076 (8.0192)	Lr: 0.4147
INFO - 12/15/22 17:50:15 - 1:00:06 - Epoch: [0][5750]	Time 0.601 (0.610)	Data 0.000 (0.005)	Loss 8.0068 (8.0191)	Lr: 0.4157
INFO - 12/15/22 17:50:46 - 1:00:36 - Epoch: [0][5800]	Time 0.602 (0.610)	Data 0.000 (0.005)	Loss 8.0073 (8.0190)	Lr: 0.4167
INFO - 12/15/22 17:51:16 - 1:01:06 - Epoch: [0][5850]	Time 0.607 (0.610)	Data 0.000 (0.005)	Loss 8.0066 (8.0189)	Lr: 0.4177
INFO - 12/15/22 17:51:46 - 1:01:36 - Epoch: [0][5900]	Time 0.605 (0.610)	Data 0.000 (0.005)	Loss 8.0073 (8.0188)	Lr: 0.4187
INFO - 12/15/22 17:52:16 - 1:02:07 - Epoch: [0][5950]	Time 0.602 (0.610)	Data 0.000 (0.005)	Loss 8.0071 (8.0187)	Lr: 0.4197
INFO - 12/15/22 17:52:47 - 1:02:37 - Epoch: [0][6000]	Time 0.614 (0.610)	Data 0.000 (0.005)	Loss 8.0065 (8.0186)	Lr: 0.4207
INFO - 12/15/22 17:53:17 - 1:03:07 - Epoch: [0][6050]	Time 0.612 (0.610)	Data 0.000 (0.005)	Loss 8.0071 (8.0185)	Lr: 0.4218
INFO - 12/15/22 17:53:47 - 1:03:37 - Epoch: [0][6100]	Time 0.605 (0.610)	Data 0.000 (0.005)	Loss 8.0064 (8.0184)	Lr: 0.4228
INFO - 12/15/22 17:54:17 - 1:04:07 - Epoch: [0][6150]	Time 0.606 (0.610)	Data 0.000 (0.005)	Loss 8.0064 (8.0183)	Lr: 0.4238
INFO - 12/15/22 17:54:47 - 1:04:38 - Epoch: [0][6200]	Time 0.599 (0.609)	Data 0.000 (0.005)	Loss 8.0066 (8.0182)	Lr: 0.4248
INFO - 12/15/22 17:55:17 - 1:05:08 - Epoch: [0][6250]	Time 0.603 (0.609)	Data 0.000 (0.005)	Loss 8.0070 (8.0181)	Lr: 0.4258
INFO - 12/15/22 17:55:47 - 1:05:38 - Epoch: [0][6300]	Time 0.595 (0.609)	Data 0.000 (0.005)	Loss 8.0064 (8.0181)	Lr: 0.4268
INFO - 12/15/22 17:56:18 - 1:06:08 - Epoch: [0][6350]	Time 0.595 (0.609)	Data 0.000 (0.005)	Loss 8.0064 (8.0180)	Lr: 0.4278
INFO - 12/15/22 17:56:48 - 1:06:38 - Epoch: [0][6400]	Time 0.599 (0.609)	Data 0.000 (0.005)	Loss 8.0070 (8.0179)	Lr: 0.4288
INFO - 12/15/22 17:57:18 - 1:07:08 - Epoch: [0][6450]	Time 0.600 (0.609)	Data 0.000 (0.005)	Loss 8.0068 (8.0178)	Lr: 0.4298
INFO - 12/15/22 17:57:48 - 1:07:39 - Epoch: [0][6500]	Time 0.617 (0.609)	Data 0.000 (0.005)	Loss 8.0074 (8.0177)	Lr: 0.4308
INFO - 12/15/22 17:58:18 - 1:08:09 - Epoch: [0][6550]	Time 0.602 (0.609)	Data 0.000 (0.005)	Loss 8.0067 (8.0176)	Lr: 0.4318
INFO - 12/15/22 17:58:49 - 1:08:39 - Epoch: [0][6600]	Time 0.602 (0.609)	Data 0.000 (0.004)	Loss 8.0073 (8.0175)	Lr: 0.4328
INFO - 12/15/22 17:59:19 - 1:09:09 - Epoch: [0][6650]	Time 0.600 (0.609)	Data 0.000 (0.004)	Loss 8.0076 (8.0175)	Lr: 0.4338
INFO - 12/15/22 17:59:49 - 1:09:39 - Epoch: [0][6700]	Time 0.616 (0.609)	Data 0.000 (0.004)	Loss 8.0064 (8.0174)	Lr: 0.4348
INFO - 12/15/22 18:00:19 - 1:10:09 - Epoch: [0][6750]	Time 0.602 (0.609)	Data 0.000 (0.004)	Loss 8.0064 (8.0173)	Lr: 0.4358
INFO - 12/15/22 18:00:49 - 1:10:40 - Epoch: [0][6800]	Time 0.601 (0.609)	Data 0.000 (0.004)	Loss 8.0064 (8.0172)	Lr: 0.4368
INFO - 12/15/22 18:01:19 - 1:11:10 - Epoch: [0][6850]	Time 0.615 (0.609)	Data 0.000 (0.004)	Loss 8.0076 (8.0171)	Lr: 0.4379
INFO - 12/15/22 18:01:49 - 1:11:40 - Epoch: [0][6900]	Time 0.614 (0.609)	Data 0.000 (0.004)	Loss 8.0064 (8.0171)	Lr: 0.4389
INFO - 12/15/22 18:02:20 - 1:12:10 - Epoch: [0][6950]	Time 0.601 (0.609)	Data 0.000 (0.004)	Loss 8.0064 (8.0170)	Lr: 0.4399
INFO - 12/15/22 18:02:50 - 1:12:40 - Epoch: [0][7000]	Time 0.616 (0.609)	Data 0.016 (0.004)	Loss 8.0064 (8.0169)	Lr: 0.4409
INFO - 12/15/22 18:03:20 - 1:13:10 - Epoch: [0][7050]	Time 0.601 (0.609)	Data 0.000 (0.004)	Loss 8.0064 (8.0168)	Lr: 0.4419
INFO - 12/15/22 18:03:50 - 1:13:40 - Epoch: [0][7100]	Time 0.616 (0.609)	Data 0.000 (0.004)	Loss 8.0064 (8.0168)	Lr: 0.4429
INFO - 12/15/22 18:04:20 - 1:14:11 - Epoch: [0][7150]	Time 0.597 (0.609)	Data 0.000 (0.004)	Loss 8.0064 (8.0167)	Lr: 0.4439
INFO - 12/15/22 18:04:50 - 1:14:41 - Epoch: [0][7200]	Time 0.601 (0.609)	Data 0.000 (0.004)	Loss 8.0064 (8.0166)	Lr: 0.4449
INFO - 12/15/22 18:05:21 - 1:15:11 - Epoch: [0][7250]	Time 0.602 (0.609)	Data 0.000 (0.004)	Loss 8.0064 (8.0166)	Lr: 0.4459
INFO - 12/15/22 18:05:51 - 1:15:41 - Epoch: [0][7300]	Time 0.600 (0.609)	Data 0.000 (0.004)	Loss 8.0064 (8.0165)	Lr: 0.4469
INFO - 12/15/22 18:06:21 - 1:16:11 - Epoch: [0][7350]	Time 0.593 (0.608)	Data 0.000 (0.004)	Loss 8.0064 (8.0164)	Lr: 0.4479
INFO - 12/15/22 18:06:51 - 1:16:41 - Epoch: [0][7400]	Time 0.607 (0.608)	Data 0.000 (0.004)	Loss 8.0064 (8.0163)	Lr: 0.4489
INFO - 12/15/22 18:07:21 - 1:17:12 - Epoch: [0][7450]	Time 0.615 (0.608)	Data 0.000 (0.004)	Loss 8.0064 (8.0163)	Lr: 0.4499
INFO - 12/15/22 18:07:51 - 1:17:42 - Epoch: [0][7500]	Time 0.602 (0.608)	Data 0.000 (0.004)	Loss 8.0064 (8.0162)	Lr: 0.4509
INFO - 12/15/22 18:08:21 - 1:18:12 - Epoch: [0][7550]	Time 0.597 (0.608)	Data 0.000 (0.004)	Loss 8.0064 (8.0161)	Lr: 0.4519
INFO - 12/15/22 18:08:52 - 1:18:42 - Epoch: [0][7600]	Time 0.595 (0.608)	Data 0.000 (0.004)	Loss 8.0064 (8.0161)	Lr: 0.4529
INFO - 12/15/22 18:09:22 - 1:19:12 - Epoch: [0][7650]	Time 0.596 (0.608)	Data 0.000 (0.004)	Loss 8.0064 (8.0160)	Lr: 0.4540
INFO - 12/15/22 18:09:52 - 1:19:42 - Epoch: [0][7700]	Time 0.607 (0.608)	Data 0.000 (0.004)	Loss 8.0064 (8.0160)	Lr: 0.4550
INFO - 12/15/22 18:10:22 - 1:20:12 - Epoch: [0][7750]	Time 0.607 (0.608)	Data 0.000 (0.004)	Loss 8.0064 (8.0159)	Lr: 0.4560
INFO - 12/15/22 18:10:52 - 1:20:42 - Epoch: [0][7800]	Time 0.617 (0.608)	Data 0.016 (0.004)	Loss 8.0064 (8.0158)	Lr: 0.4570
INFO - 12/15/22 18:11:22 - 1:21:13 - Epoch: [0][7850]	Time 0.614 (0.608)	Data 0.000 (0.004)	Loss 8.0064 (8.0158)	Lr: 0.4580
INFO - 12/15/22 18:11:52 - 1:21:43 - Epoch: [0][7900]	Time 0.595 (0.608)	Data 0.000 (0.004)	Loss 8.0064 (8.0157)	Lr: 0.4590
INFO - 12/15/22 18:12:23 - 1:22:13 - Epoch: [0][7950]	Time 0.592 (0.608)	Data 0.000 (0.004)	Loss 8.0064 (8.0157)	Lr: 0.4600
INFO - 12/15/22 18:12:53 - 1:22:43 - Epoch: [0][8000]	Time 0.595 (0.608)	Data 0.000 (0.004)	Loss 8.0064 (8.0156)	Lr: 0.4610
INFO - 12/15/22 18:13:23 - 1:23:13 - Epoch: [0][8050]	Time 0.600 (0.608)	Data 0.000 (0.004)	Loss 8.0066 (8.0155)	Lr: 0.4620
INFO - 12/15/22 18:13:53 - 1:23:43 - Epoch: [0][8100]	Time 0.601 (0.608)	Data 0.000 (0.004)	Loss 8.0065 (8.0155)	Lr: 0.4630
INFO - 12/15/22 18:14:23 - 1:24:13 - Epoch: [0][8150]	Time 0.599 (0.608)	Data 0.000 (0.004)	Loss 8.0065 (8.0154)	Lr: 0.4640
INFO - 12/15/22 18:14:53 - 1:24:44 - Epoch: [0][8200]	Time 0.601 (0.608)	Data 0.000 (0.004)	Loss 8.0064 (8.0154)	Lr: 0.4650
INFO - 12/15/22 18:15:23 - 1:25:14 - Epoch: [0][8250]	Time 0.601 (0.608)	Data 0.000 (0.004)	Loss 8.0064 (8.0153)	Lr: 0.4660
INFO - 12/15/22 18:15:53 - 1:25:44 - Epoch: [0][8300]	Time 0.603 (0.608)	Data 0.000 (0.004)	Loss 8.0064 (8.0153)	Lr: 0.4670
INFO - 12/15/22 18:16:24 - 1:26:14 - Epoch: [0][8350]	Time 0.615 (0.608)	Data 0.000 (0.004)	Loss 8.0067 (8.0152)	Lr: 0.4680
INFO - 12/15/22 18:16:54 - 1:26:44 - Epoch: [0][8400]	Time 0.615 (0.608)	Data 0.000 (0.004)	Loss 8.0064 (8.0152)	Lr: 0.4690
INFO - 12/15/22 18:17:24 - 1:27:14 - Epoch: [0][8450]	Time 0.599 (0.608)	Data 0.000 (0.004)	Loss 8.0064 (8.0151)	Lr: 0.4701
INFO - 12/15/22 18:17:54 - 1:27:44 - Epoch: [0][8500]	Time 0.601 (0.608)	Data 0.000 (0.004)	Loss 8.0064 (8.0151)	Lr: 0.4711
INFO - 12/15/22 18:18:24 - 1:28:15 - Epoch: [0][8550]	Time 0.602 (0.608)	Data 0.000 (0.004)	Loss 8.0064 (8.0150)	Lr: 0.4721
INFO - 12/15/22 18:18:55 - 1:28:45 - Epoch: [0][8600]	Time 0.602 (0.608)	Data 0.000 (0.004)	Loss 8.0073 (8.0150)	Lr: 0.4731
INFO - 12/15/22 18:19:25 - 1:29:15 - Epoch: [0][8650]	Time 0.599 (0.608)	Data 0.000 (0.003)	Loss 8.0064 (8.0149)	Lr: 0.4741
INFO - 12/15/22 18:19:55 - 1:29:45 - Epoch: [0][8700]	Time 0.598 (0.608)	Data 0.000 (0.003)	Loss 8.0064 (8.0149)	Lr: 0.4751
INFO - 12/15/22 18:20:25 - 1:30:15 - Epoch: [0][8750]	Time 0.601 (0.608)	Data 0.000 (0.003)	Loss 8.0064 (8.0148)	Lr: 0.4761
INFO - 12/15/22 18:20:55 - 1:30:46 - Epoch: [0][8800]	Time 0.603 (0.608)	Data 0.000 (0.003)	Loss 8.0065 (8.0148)	Lr: 0.4771
INFO - 12/15/22 18:21:25 - 1:31:16 - Epoch: [0][8850]	Time 0.615 (0.608)	Data 0.000 (0.003)	Loss 8.0065 (8.0147)	Lr: 0.4781
INFO - 12/15/22 18:21:55 - 1:31:46 - Epoch: [0][8900]	Time 0.602 (0.608)	Data 0.000 (0.003)	Loss 8.0064 (8.0147)	Lr: 0.4791
INFO - 12/15/22 18:22:26 - 1:32:16 - Epoch: [0][8950]	Time 0.601 (0.608)	Data 0.000 (0.003)	Loss 8.0065 (8.0146)	Lr: 0.4801
INFO - 12/15/22 18:22:56 - 1:32:46 - Epoch: [0][9000]	Time 0.605 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0146)	Lr: 0.4811
INFO - 12/15/22 18:23:26 - 1:33:16 - Epoch: [0][9050]	Time 0.607 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0146)	Lr: 0.4821
INFO - 12/15/22 18:23:56 - 1:33:46 - Epoch: [0][9100]	Time 0.607 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0145)	Lr: 0.4831
INFO - 12/15/22 18:24:26 - 1:34:17 - Epoch: [0][9150]	Time 0.614 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0145)	Lr: 0.4841
INFO - 12/15/22 18:24:57 - 1:34:47 - Epoch: [0][9200]	Time 0.595 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0144)	Lr: 0.4851
INFO - 12/15/22 18:25:27 - 1:35:17 - Epoch: [0][9250]	Time 0.593 (0.607)	Data 0.000 (0.003)	Loss 8.0071 (8.0144)	Lr: 0.4862
INFO - 12/15/22 18:25:57 - 1:35:47 - Epoch: [0][9300]	Time 0.607 (0.607)	Data 0.000 (0.003)	Loss 8.0074 (8.0143)	Lr: 0.4872
INFO - 12/15/22 18:26:27 - 1:36:17 - Epoch: [0][9350]	Time 0.592 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0143)	Lr: 0.4882
INFO - 12/15/22 18:26:57 - 1:36:47 - Epoch: [0][9400]	Time 0.606 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0143)	Lr: 0.4892
INFO - 12/15/22 18:27:27 - 1:37:18 - Epoch: [0][9450]	Time 0.600 (0.607)	Data 0.000 (0.003)	Loss 8.0072 (8.0142)	Lr: 0.4902
INFO - 12/15/22 18:27:57 - 1:37:48 - Epoch: [0][9500]	Time 0.616 (0.607)	Data 0.000 (0.003)	Loss 8.0068 (8.0142)	Lr: 0.4912
INFO - 12/15/22 18:28:28 - 1:38:18 - Epoch: [0][9550]	Time 0.593 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0141)	Lr: 0.4922
INFO - 12/15/22 18:28:58 - 1:38:48 - Epoch: [0][9600]	Time 0.595 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0141)	Lr: 0.4932
INFO - 12/15/22 18:29:28 - 1:39:18 - Epoch: [0][9650]	Time 0.599 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0141)	Lr: 0.4942
INFO - 12/15/22 18:29:58 - 1:39:48 - Epoch: [0][9700]	Time 0.601 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0140)	Lr: 0.4952
INFO - 12/15/22 18:30:28 - 1:40:18 - Epoch: [0][9750]	Time 0.600 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0140)	Lr: 0.4962
INFO - 12/15/22 18:30:58 - 1:40:49 - Epoch: [0][9800]	Time 0.602 (0.607)	Data 0.000 (0.003)	Loss 8.0066 (8.0139)	Lr: 0.4972
INFO - 12/15/22 18:31:28 - 1:41:19 - Epoch: [0][9850]	Time 0.602 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0139)	Lr: 0.4982
INFO - 12/15/22 18:31:58 - 1:41:49 - Epoch: [0][9900]	Time 0.609 (0.607)	Data 0.000 (0.003)	Loss 8.0065 (8.0139)	Lr: 0.4992
INFO - 12/15/22 18:32:29 - 1:42:19 - Epoch: [0][9950]	Time 0.600 (0.607)	Data 0.000 (0.003)	Loss 8.0067 (8.0138)	Lr: 0.5002
INFO - 12/15/22 18:32:59 - 1:42:49 - Epoch: [0][10000]	Time 0.602 (0.607)	Data 0.000 (0.003)	Loss 8.0065 (8.0138)	Lr: 0.5012
INFO - 12/15/22 18:33:29 - 1:43:19 - Epoch: [0][10050]	Time 0.602 (0.607)	Data 0.000 (0.003)	Loss 8.0065 (8.0138)	Lr: 0.5023
INFO - 12/15/22 18:33:59 - 1:43:50 - Epoch: [0][10100]	Time 0.602 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0137)	Lr: 0.5033
INFO - 12/15/22 18:34:29 - 1:44:20 - Epoch: [0][10150]	Time 0.600 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0137)	Lr: 0.5043
INFO - 12/15/22 18:34:59 - 1:44:50 - Epoch: [0][10200]	Time 0.599 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0137)	Lr: 0.5053
INFO - 12/15/22 18:35:30 - 1:45:20 - Epoch: [0][10250]	Time 0.615 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0136)	Lr: 0.5063
INFO - 12/15/22 18:36:00 - 1:45:50 - Epoch: [0][10300]	Time 0.599 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0136)	Lr: 0.5073
INFO - 12/15/22 18:36:30 - 1:46:20 - Epoch: [0][10350]	Time 0.601 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0135)	Lr: 0.5083
INFO - 12/15/22 18:37:00 - 1:46:50 - Epoch: [0][10400]	Time 0.615 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0135)	Lr: 0.5093
INFO - 12/15/22 18:37:30 - 1:47:20 - Epoch: [0][10450]	Time 0.602 (0.607)	Data 0.000 (0.003)	Loss 8.0073 (8.0135)	Lr: 0.5103
INFO - 12/15/22 18:38:00 - 1:47:50 - Epoch: [0][10500]	Time 0.602 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0134)	Lr: 0.5113
INFO - 12/15/22 18:38:30 - 1:48:21 - Epoch: [0][10550]	Time 0.599 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0134)	Lr: 0.5123
INFO - 12/15/22 18:39:00 - 1:48:51 - Epoch: [0][10600]	Time 0.615 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0134)	Lr: 0.5133
INFO - 12/15/22 18:39:31 - 1:49:21 - Epoch: [0][10650]	Time 0.599 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0133)	Lr: 0.5143
INFO - 12/15/22 18:40:01 - 1:49:51 - Epoch: [0][10700]	Time 0.601 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0133)	Lr: 0.5153
INFO - 12/15/22 18:40:31 - 1:50:21 - Epoch: [0][10750]	Time 0.604 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0133)	Lr: 0.5163
INFO - 12/15/22 18:41:01 - 1:50:51 - Epoch: [0][10800]	Time 0.605 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0133)	Lr: 0.5173
INFO - 12/15/22 18:41:31 - 1:51:21 - Epoch: [0][10850]	Time 0.589 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0132)	Lr: 0.5183
INFO - 12/15/22 18:42:01 - 1:51:52 - Epoch: [0][10900]	Time 0.601 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0132)	Lr: 0.5194
INFO - 12/15/22 18:42:31 - 1:52:22 - Epoch: [0][10950]	Time 0.603 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0132)	Lr: 0.5204
INFO - 12/15/22 18:43:01 - 1:52:52 - Epoch: [0][11000]	Time 0.610 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0131)	Lr: 0.5214
INFO - 12/15/22 18:43:31 - 1:53:22 - Epoch: [0][11050]	Time 0.596 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0131)	Lr: 0.5224
INFO - 12/15/22 18:44:02 - 1:53:52 - Epoch: [0][11100]	Time 0.595 (0.607)	Data 0.000 (0.003)	Loss 8.0065 (8.0131)	Lr: 0.5234
INFO - 12/15/22 18:44:32 - 1:54:22 - Epoch: [0][11150]	Time 0.595 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0130)	Lr: 0.5244
INFO - 12/15/22 18:45:02 - 1:54:52 - Epoch: [0][11200]	Time 0.606 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0130)	Lr: 0.5254
INFO - 12/15/22 18:45:32 - 1:55:22 - Epoch: [0][11250]	Time 0.622 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0130)	Lr: 0.5264
INFO - 12/15/22 18:46:02 - 1:55:53 - Epoch: [0][11300]	Time 0.598 (0.607)	Data 0.000 (0.003)	Loss 8.0064 (8.0130)	Lr: 0.5274
INFO - 12/15/22 18:46:32 - 1:56:23 - Epoch: [0][11350]	Time 0.597 (0.607)	Data 0.000 (0.003)	Loss 8.0071 (8.0129)	Lr: 0.5284
INFO - 12/15/22 18:47:02 - 1:56:53 - Epoch: [0][11400]	Time 0.596 (0.606)	Data 0.000 (0.003)	Loss 8.0064 (8.0129)	Lr: 0.5294
INFO - 12/15/22 18:47:33 - 1:57:23 - Epoch: [0][11450]	Time 0.594 (0.606)	Data 0.000 (0.003)	Loss 8.0072 (8.0129)	Lr: 0.5304
INFO - 12/15/22 18:48:03 - 1:57:53 - Epoch: [0][11500]	Time 0.603 (0.606)	Data 0.000 (0.003)	Loss 8.0064 (8.0128)	Lr: 0.5314
INFO - 12/15/22 18:48:33 - 1:58:23 - Epoch: [0][11550]	Time 0.600 (0.606)	Data 0.000 (0.003)	Loss 8.0067 (8.0128)	Lr: 0.5324
INFO - 12/15/22 18:49:03 - 1:58:53 - Epoch: [0][11600]	Time 0.599 (0.606)	Data 0.000 (0.003)	Loss 8.0066 (8.0128)	Lr: 0.5334
INFO - 12/15/22 18:49:33 - 1:59:24 - Epoch: [0][11650]	Time 0.602 (0.606)	Data 0.000 (0.003)	Loss 8.0064 (8.0128)	Lr: 0.5344
INFO - 12/15/22 18:50:03 - 1:59:54 - Epoch: [0][11700]	Time 0.600 (0.606)	Data 0.000 (0.003)	Loss 8.0070 (8.0127)	Lr: 0.5355
INFO - 12/15/22 18:50:33 - 2:00:24 - Epoch: [0][11750]	Time 0.615 (0.606)	Data 0.000 (0.003)	Loss 8.0073 (8.0127)	Lr: 0.5365
INFO - 12/15/22 18:51:04 - 2:00:54 - Epoch: [0][11800]	Time 0.631 (0.606)	Data 0.000 (0.003)	Loss 8.0064 (8.0127)	Lr: 0.5375
INFO - 12/15/22 18:51:34 - 2:01:24 - Epoch: [0][11850]	Time 0.599 (0.606)	Data 0.000 (0.003)	Loss 8.0066 (8.0127)	Lr: 0.5385
INFO - 12/15/22 18:52:04 - 2:01:54 - Epoch: [0][11900]	Time 0.599 (0.606)	Data 0.000 (0.003)	Loss 8.0070 (8.0126)	Lr: 0.5395
INFO - 12/15/22 18:52:34 - 2:02:24 - Epoch: [0][11950]	Time 0.602 (0.606)	Data 0.000 (0.003)	Loss 8.0064 (8.0126)	Lr: 0.5405
INFO - 12/15/22 18:53:04 - 2:02:54 - Epoch: [0][12000]	Time 0.615 (0.606)	Data 0.016 (0.003)	Loss 8.0064 (8.0126)	Lr: 0.5415
INFO - 12/15/22 18:53:34 - 2:03:25 - Epoch: [0][12050]	Time 0.601 (0.606)	Data 0.000 (0.003)	Loss 8.0064 (8.0126)	Lr: 0.5425
INFO - 12/15/22 18:54:04 - 2:03:55 - Epoch: [0][12100]	Time 0.600 (0.606)	Data 0.000 (0.003)	Loss 8.0064 (8.0125)	Lr: 0.5435
INFO - 12/15/22 18:54:34 - 2:04:25 - Epoch: [0][12150]	Time 0.599 (0.606)	Data 0.000 (0.003)	Loss 8.0064 (8.0125)	Lr: 0.5445
INFO - 12/15/22 18:55:05 - 2:04:55 - Epoch: [0][12200]	Time 0.601 (0.606)	Data 0.000 (0.003)	Loss 8.0064 (8.0125)	Lr: 0.5455
INFO - 12/15/22 18:55:35 - 2:05:25 - Epoch: [0][12250]	Time 0.599 (0.606)	Data 0.000 (0.003)	Loss 8.0077 (8.0125)	Lr: 0.5465
INFO - 12/15/22 18:56:05 - 2:05:55 - Epoch: [0][12300]	Time 0.600 (0.606)	Data 0.000 (0.003)	Loss 8.0077 (8.0124)	Lr: 0.5475
INFO - 12/15/22 18:56:35 - 2:06:25 - Epoch: [0][12350]	Time 0.604 (0.606)	Data 0.000 (0.003)	Loss 8.0066 (8.0124)	Lr: 0.5485
INFO - 12/15/22 18:57:05 - 2:06:55 - Epoch: [0][12400]	Time 0.601 (0.606)	Data 0.000 (0.003)	Loss 8.0065 (8.0124)	Lr: 0.5495
INFO - 12/15/22 18:57:35 - 2:07:26 - Epoch: [0][12450]	Time 0.599 (0.606)	Data 0.000 (0.003)	Loss 8.0064 (8.0124)	Lr: 0.5505
INFO - 12/15/22 18:58:05 - 2:07:56 - Epoch: [0][12500]	Time 0.600 (0.606)	Data 0.000 (0.003)	Loss 8.0069 (8.0123)	Lr: 0.5516
INFO - 12/15/22 18:58:35 - 2:08:26 - Epoch: [0][12550]	Time 0.599 (0.606)	Data 0.000 (0.003)	Loss 8.0110 (8.0123)	Lr: 0.5526
INFO - 12/15/22 18:59:06 - 2:08:56 - Epoch: [0][12600]	Time 0.600 (0.606)	Data 0.000 (0.003)	Loss 8.0066 (8.0123)	Lr: 0.5536
INFO - 12/15/22 18:59:36 - 2:09:26 - Epoch: [0][12650]	Time 0.602 (0.606)	Data 0.000 (0.002)	Loss 8.0067 (8.0123)	Lr: 0.5546
INFO - 12/15/22 19:00:06 - 2:09:56 - Epoch: [0][12700]	Time 0.607 (0.606)	Data 0.000 (0.002)	Loss 8.0077 (8.0123)	Lr: 0.5556
INFO - 12/15/22 19:00:36 - 2:10:26 - Epoch: [0][12750]	Time 0.607 (0.606)	Data 0.000 (0.002)	Loss 8.0067 (8.0123)	Lr: 0.5566
INFO - 12/15/22 19:01:06 - 2:10:57 - Epoch: [0][12800]	Time 0.602 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0122)	Lr: 0.5576
INFO - 12/15/22 19:01:36 - 2:11:27 - Epoch: [0][12850]	Time 0.601 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0122)	Lr: 0.5586
INFO - 12/15/22 19:02:06 - 2:11:57 - Epoch: [0][12900]	Time 0.595 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0122)	Lr: 0.5596
INFO - 12/15/22 19:02:37 - 2:12:27 - Epoch: [0][12950]	Time 0.595 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0122)	Lr: 0.5606
INFO - 12/15/22 19:03:07 - 2:12:57 - Epoch: [0][13000]	Time 0.613 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0121)	Lr: 0.5616
INFO - 12/15/22 19:03:37 - 2:13:27 - Epoch: [0][13050]	Time 0.606 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0121)	Lr: 0.5626
INFO - 12/15/22 19:04:07 - 2:13:57 - Epoch: [0][13100]	Time 0.590 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0121)	Lr: 0.5636
INFO - 12/15/22 19:04:37 - 2:14:27 - Epoch: [0][13150]	Time 0.607 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0121)	Lr: 0.5646
INFO - 12/15/22 19:05:07 - 2:14:58 - Epoch: [0][13200]	Time 0.601 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0121)	Lr: 0.5656
INFO - 12/15/22 19:05:37 - 2:15:28 - Epoch: [0][13250]	Time 0.612 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0120)	Lr: 0.5666
INFO - 12/15/22 19:06:08 - 2:15:58 - Epoch: [0][13300]	Time 0.609 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0120)	Lr: 0.5677
INFO - 12/15/22 19:06:38 - 2:16:28 - Epoch: [0][13350]	Time 0.608 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0120)	Lr: 0.5687
INFO - 12/15/22 19:07:08 - 2:16:58 - Epoch: [0][13400]	Time 0.600 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0120)	Lr: 0.5697
INFO - 12/15/22 19:07:38 - 2:17:28 - Epoch: [0][13450]	Time 0.601 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0119)	Lr: 0.5707
INFO - 12/15/22 19:08:08 - 2:17:58 - Epoch: [0][13500]	Time 0.600 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0119)	Lr: 0.5717
INFO - 12/15/22 19:08:38 - 2:18:28 - Epoch: [0][13550]	Time 0.602 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0119)	Lr: 0.5727
INFO - 12/15/22 19:09:08 - 2:18:59 - Epoch: [0][13600]	Time 0.610 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0119)	Lr: 0.5737
INFO - 12/15/22 19:09:38 - 2:19:29 - Epoch: [0][13650]	Time 0.601 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0119)	Lr: 0.5747
INFO - 12/15/22 19:10:09 - 2:19:59 - Epoch: [0][13700]	Time 0.599 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0118)	Lr: 0.5757
INFO - 12/15/22 19:10:39 - 2:20:29 - Epoch: [0][13750]	Time 0.601 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0118)	Lr: 0.5767
INFO - 12/15/22 19:11:09 - 2:20:59 - Epoch: [0][13800]	Time 0.599 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0118)	Lr: 0.5777
INFO - 12/15/22 19:11:39 - 2:21:29 - Epoch: [0][13850]	Time 0.600 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0118)	Lr: 0.5787
INFO - 12/15/22 19:12:09 - 2:21:59 - Epoch: [0][13900]	Time 0.602 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0118)	Lr: 0.5797
INFO - 12/15/22 19:12:39 - 2:22:29 - Epoch: [0][13950]	Time 0.598 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0117)	Lr: 0.5807
INFO - 12/15/22 19:13:09 - 2:23:00 - Epoch: [0][14000]	Time 0.600 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0117)	Lr: 0.5817
INFO - 12/15/22 19:13:39 - 2:23:30 - Epoch: [0][14050]	Time 0.602 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0117)	Lr: 0.5827
INFO - 12/15/22 19:14:09 - 2:24:00 - Epoch: [0][14100]	Time 0.601 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0117)	Lr: 0.5838
INFO - 12/15/22 19:14:40 - 2:24:30 - Epoch: [0][14150]	Time 0.600 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0117)	Lr: 0.5848
INFO - 12/15/22 19:15:10 - 2:25:00 - Epoch: [0][14200]	Time 0.615 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0117)	Lr: 0.5858
INFO - 12/15/22 19:15:40 - 2:25:30 - Epoch: [0][14250]	Time 0.599 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0116)	Lr: 0.5868
INFO - 12/15/22 19:16:10 - 2:26:00 - Epoch: [0][14300]	Time 0.601 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0116)	Lr: 0.5878
INFO - 12/15/22 19:16:40 - 2:26:30 - Epoch: [0][14350]	Time 0.600 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0116)	Lr: 0.5888
INFO - 12/15/22 19:17:10 - 2:27:01 - Epoch: [0][14400]	Time 0.600 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0116)	Lr: 0.5898
INFO - 12/15/22 19:17:40 - 2:27:31 - Epoch: [0][14450]	Time 0.600 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0116)	Lr: 0.5908
INFO - 12/15/22 19:18:10 - 2:28:01 - Epoch: [0][14500]	Time 0.600 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0115)	Lr: 0.5918
INFO - 12/15/22 19:18:41 - 2:28:31 - Epoch: [0][14550]	Time 0.600 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0115)	Lr: 0.5928
INFO - 12/15/22 19:19:11 - 2:29:01 - Epoch: [0][14600]	Time 0.607 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0115)	Lr: 0.5938
INFO - 12/15/22 19:19:41 - 2:29:31 - Epoch: [0][14650]	Time 0.589 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0115)	Lr: 0.5948
INFO - 12/15/22 19:20:11 - 2:30:01 - Epoch: [0][14700]	Time 0.589 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0115)	Lr: 0.5958
INFO - 12/15/22 19:20:41 - 2:30:32 - Epoch: [0][14750]	Time 0.602 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0115)	Lr: 0.5968
INFO - 12/15/22 19:21:11 - 2:31:02 - Epoch: [0][14800]	Time 0.595 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0114)	Lr: 0.5978
INFO - 12/15/22 19:21:42 - 2:31:32 - Epoch: [0][14850]	Time 0.744 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0114)	Lr: 0.5988
INFO - 12/15/22 19:22:12 - 2:32:02 - Epoch: [0][14900]	Time 0.604 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0114)	Lr: 0.5999
INFO - 12/15/22 19:22:42 - 2:32:32 - Epoch: [0][14950]	Time 0.605 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0114)	Lr: 0.6009
INFO - 12/15/22 19:23:12 - 2:33:02 - Epoch: [0][15000]	Time 0.604 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0114)	Lr: 0.6019
INFO - 12/15/22 19:23:42 - 2:33:33 - Epoch: [0][15050]	Time 0.599 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0114)	Lr: 0.6029
INFO - 12/15/22 19:24:12 - 2:34:03 - Epoch: [0][15100]	Time 0.599 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0113)	Lr: 0.6039
INFO - 12/15/22 19:24:42 - 2:34:33 - Epoch: [0][15150]	Time 0.610 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0113)	Lr: 0.6049
INFO - 12/15/22 19:25:13 - 2:35:03 - Epoch: [0][15200]	Time 0.596 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0113)	Lr: 0.6059
INFO - 12/15/22 19:25:43 - 2:35:33 - Epoch: [0][15250]	Time 0.599 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0113)	Lr: 0.6069
INFO - 12/15/22 19:26:13 - 2:36:03 - Epoch: [0][15300]	Time 0.603 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0113)	Lr: 0.6079
INFO - 12/15/22 19:26:43 - 2:36:33 - Epoch: [0][15350]	Time 0.599 (0.606)	Data 0.000 (0.002)	Loss 8.0064 (8.0113)	Lr: 0.6089
INFO - 12/15/22 19:27:13 - 2:37:03 - Epoch: [0][15400]	Time 0.600 (0.605)	Data 0.000 (0.002)	Loss 8.0064 (8.0112)	Lr: 0.6099
INFO - 12/15/22 19:27:43 - 2:37:34 - Epoch: [0][15450]	Time 0.600 (0.605)	Data 0.000 (0.002)	Loss 8.0064 (8.0112)	Lr: 0.6109
INFO - 12/15/22 19:28:13 - 2:38:04 - Epoch: [0][15500]	Time 0.601 (0.605)	Data 0.000 (0.002)	Loss 8.0064 (8.0112)	Lr: 0.6119
INFO - 12/15/22 19:28:43 - 2:38:34 - Epoch: [0][15550]	Time 0.602 (0.605)	Data 0.000 (0.002)	Loss 8.0064 (8.0112)	Lr: 0.6129
INFO - 12/15/22 19:29:14 - 2:39:04 - Epoch: [0][15600]	Time 0.599 (0.605)	Data 0.000 (0.002)	Loss 8.0064 (8.0112)	Lr: 0.6139
INFO - 12/15/22 19:29:44 - 2:39:34 - Epoch: [0][15650]	Time 0.599 (0.605)	Data 0.000 (0.002)	Loss 8.0064 (8.0112)	Lr: 0.6149
INFO - 12/15/22 19:30:14 - 2:40:04 - Epoch: [0][15700]	Time 0.599 (0.605)	Data 0.000 (0.002)	Loss 8.0064 (8.0111)	Lr: 0.6160
INFO - 12/15/22 19:30:44 - 2:40:35 - Epoch: [0][15750]	Time 0.616 (0.605)	Data 0.000 (0.002)	Loss 8.0064 (8.0111)	Lr: 0.6170
